{
  "total": 9,
  "documents": [
    {
      "chunk_text": "desirable is perhaps the quintessential idea of the Enlightenment. It motivates all traditions of criticism, as well as the principle of seeking good explanations. But it can be interpreted in two almost opposite ways, both of which, confusingly, are known as ‘perfectibility’. One is that humans, or human societies, are capable of attaining a state of supposed perfection – such as the Buddhist or Hindu ‘nirvana’, or various political utopias. The other is that every attainable state can be indefinitely improved. Fallibilism rules out that first position in favour of the second. Neither the human condition in particular nor our explanatory knowledge in general will ever be perfect, nor even approximately perfect. We shall always be at the beginning of infinity. These two interpretations of human progress and perfectibility have historically inspired two broad branches of the Enlightenment which, though they share attributes such as their rejection of authority, are so different in important respects in that it is most unfortunate that they share the same name. The utopian ‘Enlightenment’ is sometimes called the Continental (European) Enlightenment to distinguish it from the more fallibilist British Enlightenment, which began a little earlier and 65 the beginning of infinity took a very different course. (See, for instance, the historian Roy Porter’s book Enlightenment.) In my terminology, the Continental Enlightenment understood that problems are soluble but not that they are inevitable, while the British Enlightenment understood both equally. Note that this is a classification of ideas, not of nations or even individual thinkers: not all Enlightenment thinkers belong wholly to one branch or the other; nor were all thinkers of the respective Enlighten ments born in the eponymous part of the world. The mathematician and philosopher Nicholas de Condorcet, for instance, was French yet belonged more to what I am calling the ‘British’ Enlightenment, while Karl Popper, the twentieth century’s foremost proponent of the British Enlightenment, was born in Austria. The Continental Enlightenment was impatient for the perfected state – which led to intellectual dogmatism, political violence and new forms of tyranny. The French Revolution of 1789 and the Reign of Terror that followed it are the archetypal examples. The British Enlightenment, which was evolutionary and cognizant of human fallibility, was im - patient for institutions that did not stifle gradual, continuing change. It was also enthusiastic for small improvements, unbounded in the future. (See, for instance, the historian Jenny Uglow’s book Lunar Men.) This is, I believe, the movement that was successful in its pursuit of progress, so in this book when I refer to ‘the’ Enlightenment I mean the ‘British’ one. To investigate the ultimate reach of humans (or of people, or of progress), we should not be considering places like the Earth and the moon, which are unusually rich in resources. Let us go back to that typical place. While the Earth is inundated with matter, energy and evidence, out there in intergalactic space all three are at their lowest possible supply. There is no rich supply of minerals, no vast nuclear reactor overhead delivering free energy, no lights in the sky or diverse local events to provide evidence of the laws of nature. It is empty, cold and dark. Or is it? Actually, that is yet another parochial misconception. Intergalactic space is indeed very empty by human standards. But each of those solar-system-sized cubes still contains over a billion tonnes of matter – mostly in the form of ionized hydrogen. A billion tonnes is more than enough mass to build, say, a space station and a colony of 66 The Spark scientists creating an open-ended stream of knowledge – if anyone were present who knew how to do that. No human today knows how. For instance, one would first have to transmute some of the hydrogen into other elements. Collecting it from such a diffuse source would be far beyond us at present. And, although some types of transmutation are already routine in the nuclear industry, we do not know how to transmute hydrogen into other elements on an industrial scale. Even a simple nuclear-fusion reactor is currently beyond our technology. But physicists are confident that it is not forbidden by any laws of physics, in which case, as always, it can only be a matter of knowing how. No doubt a billion-tonne space station is not large enough to thrive in the very long run. The inhabitants will want to enlarge it. But that presents no problem of principle. As soon as they started to trawl their cube for hydrogen, more would drift in from the surrounding space, supplying the cube with millions of tonnes of hydrogen per year. (There is also believed to be an even greater mass of ‘dark matter’ in the cube, but we do not know how to do anything useful with it, so let us ignore it in this thought experiment.) As for the cold, and the lack of available energy – as I said, the transmutation of hydrogen releases the energy of nuclear fusion. That would be a sizeable power supply, orders of magnitude more than the combined power consumption of everyone on Earth today. So the cube is not as lacking in resources as a parochial first glance would suggest. How would the space station get its vital supply of evidence? Using the elements created by transmutation, one could construct scientific laboratories, as in the projected moon base. On Earth, when chemistry was in its infancy, making discoveries often depended on travelling all over the planet to find materials to experiment on. But transmutation makes that irrelevant; and chemical laboratories on the space station would be able to synthesize arbitrary compounds of arbitrary elements. The same is true of elementary particle physics: in that field, almost anything will do as a source of evidence, because every atom is poten- tially a cornucopia of particles just waiting to display themselves if one hits the atom hard enough (using a particle accelerator) and observes with the right instruments. In biology, DNA and all",
      "$id": "670238f8a95f9af93494",
      "$createdAt": "2024-10-06T07:15:04.698+00:00",
      "$updatedAt": "2024-10-06T07:15:04.698+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "moderately significant in the cosmic scheme of things. But it seems that one can explain everything about supernovae, and almost everything else, without ever mentioning people or knowledge at all. However, that is merely another parochial error, due to our current, untypical, vantage point in an Enlightenment that is mere centuries old. In the longer run, humans may colonize other solar systems and, by increasing their knowledge, control ever more powerful physical processes. If people ever choose to live near a star that is capable of exploding, they may well wish to prevent such an explosion – probably by removing some of the material from the star. Such a project would use many orders of magnitude more energy than humans currently control, and more advanced technology as well. But it is a fundament- ally simple task, not requiring any steps that are even close to limits imposed by the laws of physics. So, with the right knowledge, it could be achieved. Indeed, for all we know, engineers elsewhere in the universe are already achieving it routinely. And consequently it is not true that the attributes of supernovae in general are independent of the presence or absence of people, or of what those people know and intend. More generally, if we want to predict what a star will do, we first have to guess whether there are any people near it, and, if so, what knowledge they may have and what they may want to achieve. Outside our parochial perspective, astrophysics is incomplete without a theory of people, just as it is incomplete without a theory of gravity or nuclear reactions. Note that this conclusion does not depend on the assumption that humans, or anyone, will colonize the galaxy and take control of 70 The Spark any supernovae: the assumption that they will not is equally a theory about the future behaviour of knowledge. Knowledge is a significant phenomenon in the universe, because to make almost any prediction about astrophysics one must take a position about what types of knowledge will or will not be present near the phenomena in question. So all explanations of what is out there in the physical world mention knowledge and people, if only implicitly. But knowledge is more significant even than that. Consider any physical object – for instance, a solar system, or a microscopic chip of silicon – and then consider all the transformations that it is physically possible for it to undergo. For instance, the silicon chip might be melted and solidify in a different shape, or be transformed into a chip with different functionality. The solar system might be devastated when its star becomes a supernova, or life might evolve on one of its planets, or it might be transformed, using transmutation and other futuristic technologies, into microprocessors. In all cases, the class of transform- ations that could happen spontaneously – in the absence of knowledge – is negligibly small compared with the class that could be effected artificially by intelligent beings who wanted those transformations to happen. So the explanations of almost all physically possible phenomena are about how knowledge would be applied to bring these phenomena about. If you want to explain how an object might possibly reach a temperature of ten degrees or a million, you can refer to spontaneous processes and can avoid mentioning people explicitly (even though most processes at those temperatures can be brought about only by people). But if you want to explain how an object might possibly cool down to a millionth of a degree above absolute zero, you cannot avoid explaining in detail what people would do. And that is still only the least of it. In your mind’s eye, continue your journey from that point in intergalactic space to another, at least ten times as far away. Our destination this time is inside one of the jets of a quasar. What would it be like in one of those jets? Language is barely capable of expressing it: it would be rather like facing a supernova explosion at point-blank range, but for millions of years at a time. The survival time for a human body would be measured in picoseconds. As I said, it is unclear whether the laws of physics permit any knowledge to grow there, let alone a life-support system for humans. It is about 71 the beginning of infinity as different from our ancestral environment as it could possibly be. The laws of physics that explain it bear no resemblance to any rules of thumb that were ever in our ancestors’ genes or in their culture. Yet human brains today know in considerable detail what is happening there. Somehow that jet happens in such a way that billions of years later, on the other side of the universe, a chemical scum can know and predict what the jet will do, and can understand why. That means that one physical system – say, an astrophysicist’s brain – contains an accurate working model of the other, the jet. Not just a superficial image (though it contains that as well), but an explanatory theory that embodies the same mathematical relationships and causal structure. That is scientific knowledge. Furthermore, the faithfulness with which the one structure resembles the other is steadily increasing. That constitutes the creation of knowledge. Here we have physical objects very unlike each other, and whose behaviour is dominated by different laws of physics, embodying the same mathematical and causal structures – and doing so ever more accurately over time. Of all the physical processes that can occur in nature, only the creation of knowledge exhibits that underlying unity. In Arecibo, Puerto Rico, there is a giant radio telescope, one of whose many uses is in the Search For Extraterrestrial Intelligence (SETI). In an office in a building near the telescope there is a small domestic refrigerator. Inside that refrigerator is a bottle of champagne, sealed by a cork. Consider that cork. It is going to be removed from the bottle",
      "$id": "670238fa013d33de7310",
      "$createdAt": "2024-10-06T07:15:06.007+00:00",
      "$updatedAt": "2024-10-06T07:15:06.007+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "question of the sources of our knowledge by the entirely different question: ‘How can we hope to detect and eliminate error?’ ‘Knowledge without Authority’ (1960) The question ‘How can we hope to detect and eliminate error?’ is echoed by Feynman’s remark that ‘science is what we have learned about how to keep from fooling ourselves’. And the answer is basically the same for human decision-making as it is for science: it requires a tradition of criticism, in which good explanations are sought – for example, explanations of what has gone wrong, what would be better, what effect various policies have had in the past and would have in the future. But what use are explanations if they cannot make predictions and so cannot be tested through experience, as they can be in science? This is really the question: how is progress possible in philosophy? As I discussed in Chapter 5, it is obtained by seeking good explanations. The misconception that evidence can play no legitimate role in philo- sophy is a relic of empiricism. Objective progress is indeed possible in politics just as it is in morality generally and in science. Political philosophy traditionally centred on a collection of issues that Popper called the ‘who should rule?’ question. Who should wield power? Should it be a monarch or aristocrats, or priests, or a dictator, or a small group, or ‘the people’, or their delegates? And that leads to 209 the beginning of infinity derivative questions such as ‘How should a king be educated?’ ‘Who should be enfranchised in a democracy?’ ‘How does one ensure an informed and responsible electorate?’ Popper pointed out that this class of questions is rooted in the same misconception as the question ‘How are scientific theories derived from sensory data?’ which defines empiricism. It is seeking a system that derives or justifies the right choice of leader or government, from existing data – such as inherited entitlements, the opinion of the majority, the manner in which a person has been educated, and so on. The same misconception also underlies blind optimism and pessimism: they both expect progress to be made by applying a simple rule to existing knowledge, to establish which future possibilities to ignore and which to rely on. Induction, instrumentalism and even Lamarckism all make the same mistake: they expect explanationless progress. They expect knowledge to be created by fiat with few errors, and not by a process of variation and selection that is making a continual stream of errors and correcting them. The defenders of hereditary monarchy doubted that any method of selection of a leader by means of rational thought and debate could improve upon a fixed, mechanical criterion. That was the precautionary principle in action, and it gave rise to the usual ironies. For instance, whenever pretenders to a throne claimed to have a better hereditary entitlement than the incumbent, they were in effect citing the precaution- ary principle as a justification for sudden, violent, unpredictable change – in other words, for blind optimism. The same was true whenever monarchs happened to favour radical change themselves. Consider also the revolutionary utopians, who typically achieve only destruction and stagnation. Though they are blind optimists, what defines them as utopians is their pessimism that their supposed utopia, or their violent proposals for achieving and entrenching it, could ever be improved upon. Additionally, they are revolutionaries in the first place because they are pessimistic that many other people can be persuaded of the final truth that they think they know. Ideas have consequences, and the ‘who should rule?’ approach to political philosophy is not just a mistake of academic analysis: it has been part of practically every bad political doctrine in history. If the political process is seen as an engine for putting the right rulers in 210 Optimism power, then it justifies violence, for until that right system is in place, no ruler is legitimate; and once it is in place, and its designated rulers are ruling, opposition to them is opposition to rightness. The problem then becomes how to thwart anyone who is working against the rulers or their policies. By the same logic, everyone who thinks that existing rulers or policies are bad must infer that the ‘who should rule?’ question has been answered wrongly, and therefore that the power of the rulers is not legitimate, and that opposing it is legitimate, by force if necessary. Thus the very question ‘Who should rule?’ begs for violent, authoritarian answers, and has often received them. It leads those in power into tyranny, and to the entrenchment of bad rulers and bad policies; it leads their opponents to violent destructiveness and revolution. Advocates of violence usually have in mind that none of those things need happen if only everyone agreed on who should rule. But that means agreeing about what is right, and, given agreement on that, rulers would then have nothing to do. And, in any case, such agreement is neither possible nor desirable: people are different, and have unique ideas; problems are inevitable, and progress consists of solving them. Popper therefore applies his basic ‘how can we detect and eliminate errors?’ to political philosophy in the form how can we rid ourselves of bad governments without violence? Just as science seeks explanations that are experimentally testable, so a rational political system makes it as easy as possible to detect, and persuade others, that a leader or policy is bad, and to remove them without violence if they are. Just as the institutions of science are structured so as to avoid entrenching theories, but instead to expose them to criticism and testing, so political institutions should not make it hard to oppose rulers and policies, non-violently, and should embody traditions of peaceful, critical dis- cussion of them and of the institutions themselves and everything else. Thus, systems of government are to be judged not for their prophetic ability to choose and install good leaders and policies, but for their ability to remove bad",
      "$id": "6702391be9b3908e76d8",
      "$createdAt": "2024-10-06T07:15:39.960+00:00",
      "$updatedAt": "2024-10-06T07:15:39.960+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "though the situations themselves are quite straightforward. Dawkins gives an example in his book Unweaving the Rainbow, analysing the claim that a television psychic was making accurate predictions: There are about 100,000 five-minute periods in a year. The probability that any given watch, say mine, will stop in a designated five-minute period is about 1 in 100,000. Low odds, but there are 10 million people watching the [television psychic’s] show. If only half of them are wearing watches, we could expect about 25 of those watches to stop in any given minute. If only a quarter of these ring in to the studio, that is 6 calls, more than enough to dumbfound a naive audience. Especially when you add in the calls from people whose watches stopped the day before, people whose watches didn’t stop but whose grandfather clocks did, people who died of heart attacks and their bereaved relatives phoned in to say that their ‘ticker’ gave out, and so on. As this example shows, the fact that certain circumstances can explain other events without being in any way involved in causing them is very familiar despite being counter-intuitive. The ‘naive’ audience’s mistake is a form of parochialism: they observe a phenomenon – people phoning in because their watches stopped – but they are failing to understand 279 the beginning of infinity it as part of a wider phenomenon, most of which they do not observe. Though the unobserved parts of that wider phenomenon have in no way affected what we, the viewers, observe, they are essential to its explanation. Similarly, common sense and classical physics contain the parochial error that only one history exists. This error, built into our language and conceptual framework, makes it sound odd to say that an event can be in one sense extremely unlikely and in another certain to happen. But there is nothing odd about it in reality. We are now seeing the interior of the spaceship as an overwhelmingly complex jumble of superposed objects. Most locations on board are packed with people, some of them on very unusual errands, and all unable to perceive each other. The spaceship itself is on many slightly different courses, due to slightly different behaviours of the crew. Of course we are ‘seeing’ this only in our mind’s eye. Our fictional laws of physics ensure that no observer in the multiverse itself would see anything like that. Consequently, on closer inspection (in our mind’s eye), we also see that there is great order and regularity in that apparent chaos. For instance, although there is a flurry of human figures in the Captain’s chair, we see that most of them are the Captain; and although there is a flurry of human figures in the Navigator’s chair, we see that few of them are the Captain. Regularities of that kind are ultimately due to the fact that all the universes, despite their differences, obey the same laws of physics (including their initial conditions). We also see that any particular instance of the Captain only ever interacts with one instance of the Navigator, and one instance of the First Officer; and those instances of the Navigator and First Officer are precisely the ones that interact with each other. These regularities are due to the fact that the histories are nearly autonomous: what happens in each of them depends almost entirely on previous events in that history alone – with transporter-induced voltage surges being the only exceptions. In the story so far, this autonomy of the histories is rather a trivial fact, since we began by making the universes autonomous. But it is going to be worth becoming even more pedantic for a moment: what exactly is the difference between the instance of you that I can interact with and the ones that are imperceptible to me? The latter are ‘in other universes’ – but, remember, universes consist only of the objects in them, so that amounts only to saying I can see 280 The Multiverse the ones that I can see. The upshot is that our laws of physics must also say that every object carries within it information about which instances of it could interact with which instances of other objects (except when the instances are fungible, when there is no such thing as ‘which’). Quantum theory describes such information. It is known as entanglement information.* So far in the story we have set up a vast, complex world which looks very unfamiliar in our mind’s eye, but to the overwhelming majority of the inhabitants looks almost exactly like the single universe of our everyday experience and of classical physics, plus some apparently random jiggling whenever the transporter operates. A tiny minority of the histories have been significantly affected by very ‘unlikely’ events, but even in those the information flow – what affects what – is still very tame and familiar. For instance, a version of the ship’s log that contains records of bizarre coincidences will be perceptible to people who remember those coincidences, but not to other instances of those people. Thus the information in the fictional multiverse flows along a branching tree, whose branches – histories – have different thicknesses (measures) and never rejoin once they have separated. Each behaves exactly as if the others did not exist. If that were the whole story, that multiverse’s imaginary laws of physics would still be fatally flawed as explanations in the same way that they have been all along: there would be no difference between their predictions and those of much more straightforward laws saying that there is only one universe – one history – in which the transporter randomly introduces a change in the objects that it teleports. Under those laws, instead of branching into two autonomous histories on such occasions, the single history randomly does or does not undergo such a change. Thus the entire stupendously complicated multiverse that we have imagined – with its multiplicity of entities including people walking through each other and its",
      "$id": "6702392cb412f18f5205",
      "$createdAt": "2024-10-06T07:15:56.739+00:00",
      "$updatedAt": "2024-10-06T07:15:56.739+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "effects typically continue indefinitely, as I have described, with a wave of differentiation entangling more and more objects. If the differential effects can all be undone, then interference between those original values becomes possible again; but the laws of quantum mechanics dictate that undoing them requires fine control of all the affected objects, and that rapidly becomes infeasible. The process of its becoming infeasible is known as decoherence. In most situations, decoherence is very rapid, which is why splitting typically predominates over interference, and why interference – though ubiquitous on microscopic scales – is quite hard to demonstrate unambiguously in the laboratory. Nevertheless, it can be done, and quantum interference phenomena constitute our main evidence of the existence of the multiverse, and of what its laws are. A real-life analogue of the above experiment is standard in quantum optics laboratories. Instead of experimenting on voltmeters (whose many interactions with their environment quickly cause decoherence), one uses individual photons, and the variable being acted upon is not voltage but which of two possible paths the photon is on. Instead of the transporter, one uses a simple device called a semi- silvered mirror (represented by the grey sloping bars in the diagrams below). When a photon strikes such a mirror, it bounces off in half the universes, and passes straight through in the other half, as shown on next page: 285 the beginning of infinity Semi-silvered mirror The attributes of travelling in the X or Y directions behave analogously to the two voltages X and Y in our fictitious multiverse. So passing through the semi-silvered mirror is the analogue of the transformation above. And when the two instances of a single photon, travelling in directions X and Y, strike the second semi-silvered mirror at the same time, they undergo the transformation , which means that both instances emerge in the direction X: the two histories rejoin. To demonstrate this, one can use a set-up known as a ‘Mach– Zehnder interferometer’, which performs those two transfor mations (splitting and interference) in quick succession: Mach–Zehnder interferometer 286 The Multiverse The two ordinary mirrors (the black sloping bars) are merely there to steer the photon from the first to the second semi-silvered mirror. If a photon is introduced travelling rightwards (X) after the first mirror instead of before as shown, then it appears to emerge randomly, rightwards or downwards, from the last mirror (because then, happens there). The same is true of a photon introduced travelling downwards (Y) after the first mirror. But a photon introduced as shown in the diagram invariably emerges rightwards, never downwards. By doing the experiment repeatedly with and without detectors on the paths, one can verify that only one photon is ever present per history, because only one of those detectors is ever observed to fire during such an experiment. Then, the fact that the intermediate histories X and Y both contribute to the deterministic final outcome X makes it inescapable that both are happening at the intermediate time. In the real multiverse, there is no need for the transporter or any other special apparatus to cause histories to differentiate and to rejoin. Under the laws of quantum physics, elementary particles are undergoing such processes of their own accord, all the time. Moreover, histories may split into more than two – often into many trillions – each character ized by a slightly different direction of motion or difference in other physical variables of the elementary particle concerned. Also, in general the resulting histories have unequal measures. So let us now dispense with the transporter in the fictional multiverse too. The rate of growth in the number of distinct histories is quite mind- boggling – even though, thanks to interference, there is now a certain amount of spontaneous rejoining as well. Because of this rejoining, the flow of information in the real multiverse is not divided into strictly autonomous subflows – branching, autonomous histories. Although there is still no communication between histories (in the sense of message-sending), they are intimately affecting each other, because the effect of interference on a history depends on what other histories are present. Not only is the multiverse no longer perfectly partitioned into histories, individual particles are not perfectly partitioned into in- stances. For example, consider the following interference phenom enon, 287 the beginning of infinity where X and Y now represent different values of the position of a single particle: X X (cid:3514) X (cid:3514) Y Y How instances of a particle lose their identity during interference. Has the instance of the particle at X stayed at X or moved to Y? Has the instance of the particle at Y returned to Y or moved to X? Because these two groups of instances of the particle, initially at different positions, have gone through a moment of being fungible, there is no such thing as which of them has ended up at which final position. This sort of interference is going on all the time, even for a single particle in a region of otherwise empty space. So there is in general no such thing as the ‘same’ instance of a particle at different times. Even within the same history, particles in general do not retain their identities over time. For example, during a collision between two atoms, the histories of the event split into something like this and something like this 288 The Multiverse So, for each particle individually, the event is rather like a collision with a semi-silvered mirror. Each atom plays the role of the mirror for the other atom. But the multiversal view of both particles looks like this where at the end of the collision some of the instances of each atom have become fungible with what was originally a different atom. For the same reason, there is no such thing as the speed of one instance of the particle at a given location. Speed is defined as distance travelled divided by time taken, but that is not meaningful in situations",
      "$id": "6702392e1e82dd8055fd",
      "$createdAt": "2024-10-06T07:15:58.127+00:00",
      "$updatedAt": "2024-10-06T07:15:58.127+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "Mach–Zehnder interfero- meter, shown earlier, two instances of a single photon travel on two different paths. On the way, they strike two different mirrors. Interference will happen only if the photon does not become entangled with the mirrors – but it will become entangled if either mirror retains the slightest record that it has been struck (for that would be a differential effect of the instances on the two different paths). Even a single quantum of change in the amplitude of the mirror’s vibration on its supports, for 296 … Y splitting interference (cid:3514) 2 (cid:3514) Y (many) The Multiverse instance, would be enough to prevent the interference (the subsequent merging of the photon’s two instances). When one of the instances of the photon bounces off either mirror, its momentum changes, and hence by the principle of the conservation of momentum (which holds universally in quantum physics, just as in classical physics), the mirror’s momentum must change by an equal and opposite amount. Hence it seems that, in each history, one mirror but not the other must be left vibrating with slightly more or less energy after the photon has struck it. That energy change would be a record of which path the photon took, and hence the mirrors would be entangled with the photon. Fortunately, that is not what happens. Remember that, at a sufficiently fine level of detail, what we crudely see as a single history of the mirror, resting passively or vibrating gently on its supports, is actually a vast number of histories with instances of all its atoms continually splitting and rejoining. In particular, the total energy of the mirror takes a vast number of possible values around the average, ‘classical’ one. Now, what happens when a photon strikes the mirror, changing that total energy by one quantum? Oversimplifying for a moment, imagine just five of those countless instances of the mirror, with each instance having a different vibrational energy ranging from two quanta below the average to two quanta above it. Each instance of the photon strikes one instance of the mirror and imparts one additional quantum of energy to it. So, after that impact, the average energy of the instances of the mirror will have increased by one quantum, and there will now be instances with energies ranging from one quantum below the old average to three above. But since, at this fine level of detail, there is no autonomous history associated with any of those values of the energy, it is not meaningful to ask whether an instance of the mirror with a particular energy after the impact is the same one that previously had that energy. The objective physical fact is only that, of the five instances of the mirror, four have energies that were present before, and one does not. Hence, only that one – whose energy is three quanta higher than the previous average – carries any record of the impact of the photon. And that means that in only one-fifth of the universes in which the photon struck has the wave of differentiation spread to the mirror, and only 297 the beginning of infinity in those will subsequent interference between instances of that photon that have or have not hit the mirror be suppressed. With realistic numbers, that is more like one in a trillion trillion – which means that there is only a probability of one in a trillion trillion that interference will be suppressed. This is considerably lower than the probability that the experiment will give inaccurate results due to imperfect measuring instruments, or that it will be spoiled by a lightning strike. Now let us look at the arrival of that single quantum of energy, to see how that discrete change can possibly happen without any dis - continuity. Consider the simplest possible case: an atom absorbs a photon, including all its energy. This energy transfer does not take place instantaneously. (Forget anything that you may have read about ‘quantum jumps’: they are a myth.) There are many ways in which it can happen but the simplest is this. At the beginning of the process, the atom is in (say) its ‘ground state’, in which its electrons have the least possible energy allowed by quantum theory. That means that all its instances (within the relevant coarse-grained history) have that energy. Assume that they are also fungible. At the end of the process, all those instances are still fungible, but now they are in the ‘excited state’, which has one additional quantum of energy. What is the atom like halfway through the process? Its instances are still fungible, but now half of them are in the ground state and half in the excited state. It is as if a continuously variable amount of money changed ownership gradually from one discrete owner to another. This mechanism is ubiquitous in quantum physics, and is the general means by which transitions between discrete states happen in a continu- ous way. In classical physics, a ‘tiny effect’ always means a tiny change in some measurable quantities. In quantum physics, physical variables are typically discrete and so cannot undergo tiny changes. Instead, a ‘tiny effect’ means a tiny change in the proportions that have the various discrete attributes. This also raises the issue of whether time itself is a continuous variable. In this discussion I am assuming that it is. However, the quantum mechanics of time is not yet fully understood, and will not be until we have a quantum theory of gravity (the unification of quantum theory with the general theory of relativity), so it may turn 298 The Multiverse out that things are not as simple as that. One thing we can be fairly sure of, though, is that, in that theory, different times are a special case of different universes. In other words, time is an entanglement phenomenon, which places all equal clock readings (of correctly prepared clocks – or of any objects usable as clocks) into the same",
      "$id": "67023930baa7550e41a1",
      "$createdAt": "2024-10-06T07:16:00.766+00:00",
      "$updatedAt": "2024-10-06T07:16:00.766+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "perverse. For instance, it was susceptible to what came to be called the population paradox: a state whose population has increased since the last census can lose a seat to one whose population has decreased. So, ‘why didn’t they just’ create new seats and assign them to states that lose out under a population paradox? They did so. But unfortunately that can bring the allocation outside quota. It can also introduce another historically important apportionment paradox: the Alabama 330 Choices paradox. That happens when increasing the total number of seats in the House results in some state losing a seat. And there were other paradoxes. These were not necessarily unfair in the sense of being biased or disproportionate. They are called ‘paradoxes’ because an apparently reasonable rule makes apparently unreasonable changes between one apportionment and the next. Such changes are effectively random, being due to the vagaries of round ing errors, not to any bias, and in the long run they cancel out. But impartiality in the long run does not achieve the intended purpose of representative government. Perfect ‘fairness in the long run’ could be achieved even without elections, by selecting the legislature randomly from the electorate as a whole. But, just as a coin tossed randomly one hundred times is unlikely to produce exactly fifty heads and fifty tails, so a randomly chosen legislature of 435 would in practice never be representative on any one occasion: statistically, the typical deviation from representativeness would be about eight seats. There would also be large fluctuations in how those seats were distributed among states. The apportionment paradoxes that I have described have similar effects. The number of seats involved is usually small, but that does not make it unimportant. Politicians worry about this because votes in the House of Representatives are often very close. Bills quite often pass or fail by one vote, and political deals often depend on whether individual representatives join one faction or another. So, whenever apportion- ment paradoxes have caused political discord, people have tried to invent an apportionment rule that is mathematically incapable of causing that particular paradox. Particular paradoxes always make it look as though everything would be fine if only ‘they’ made some simple change or other. Yet the paradoxes as a whole have the infuriat- ing property that, no matter how firmly they are kicked out of the front door, they instantly come in again at the back. After Hamilton’s rule was adopted, in 1851, Webster’s still enjoyed substantial support. So Congress tried, on at least two occasions, a trick that seemed to provide a judicious compromise: adjust the number of seats in the House until the two rules agree. Surely that would please everyone! Yet the upshot was that in 1871 some states considered the result to be so unfair, and the ensuing compromise legislation was so 331 the beginning of infinity chaotic, that it was unclear what allocation rule, if any, had been decided upon. The apportionment that was implemented – which in - cluded the last-minute creation of several additional seats for no apparent reason – satisfied neither Hamilton’s rule nor Webster’s. Many considered it unconstitutional. For the next few decades after 1871, every census saw either the adoption of a new apportionment rule or a change in the number of seats, designed to compromise between different rules. In 1921 no apportionment was made at all: they kept the old one (a course of action that may well have been unconstitutional again), because Congress could not agree on a rule. The apportionment issue has been referred several times to eminent mathematicians, including twice to the National Academy of Sciences, and on each occasion these authorities have made different recom- mendations. Yet none of them ever accused their predecessors of making errors in mathematics. This ought to have warned everyone that this problem is not really about mathematics. And on each occasion, when the experts’ recommendations were implemented, paradoxes and dis - putes kept on happening. In 1901 the Census Bureau published a table showing what the apportionments would be for every number of seats between 350 and 400 using Hamilton’s rule. By a quirk of arithmetic of a kind that is common in apportionment, Colorado would get three seats for each of these numbers except 357, when it would get only two seats. The chairman of the House Committee on Apportionment (who was from Illinois: I do not know whether he had anything against Colorado) proposed that the number of seats be changed to 357 and that Hamilton’s rule be used. This proposal was regarded with suspicion, and Congress eventually rejected it, adopting a 386-member apportion- ment and Webster’s rule, which also gave Colorado its ‘rightful’ three seats. But was that apportionment really any more rightful than Hamilton’s rule with 357 seats? By what criterion? Majority voting among apportionment rules? What exactly would be wrong with working out what a large number of rival apportionment rules would do, and then allocating to each state the number of representatives that the majority of the schemes would allocate? The main thing is that that is itself an apportionment 332 Choices rule. Similarly, combining Hamilton’s and Webster’s schemes as they tried to do in 1871 just constituted adopting a third scheme. And what does such a scheme have going for it? Each of its constituent schemes was presumably designed to have some desirable properties. A com - bined scheme that was not designed to have those properties will not have them, except by coincidence. So it will not necessarily inherit the good features of its constituents. It will inherit some good ones and some bad ones, and have additional good and bad features of its own – but if it was not designed to be good, why should it be? A devil’s advocate might now ask: if majority voting among ap - portionment rules is such a bad idea, why is majority voting among voters a good idea? It would be disastrous to",
      "$id": "67023938cc0496d990af",
      "$createdAt": "2024-10-06T07:16:08.838+00:00",
      "$updatedAt": "2024-10-06T07:16:08.838+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "use it in, say, science. There are more astrologers than astronomers, and believers in ‘paranormal’ phenomena often point out that purported witnesses of such phenomena outnumber the witnesses of most scientific experiments by a large factor. So they demand proportionate credence. Yet science refuses to judge evidence in that way: it sticks with the criterion of good explanation. So if it would be wrong for science to adopt that ‘democratic’ principle, why is it right for politics? Is it just because, as Churchill put it, ‘Many forms of Government have been tried and will be tried in this world of sin and woe. No one pretends that democracy is perfect or all-wise. Indeed, it has been said that democracy is the worst form of government except all those other forms that have been tried from time to time.’ That would indeed be a sufficient reason. But there are cogent positive reasons as well, and they too are about explanation, as I shall explain. Sometimes politicians have been so perplexed by the sheer perverse- ness of apportionment paradoxes that they have been reduced to denouncing mathematics itself. Representative Roger Q. Mills of Texas complained in 1882, ‘I thought . . . that mathematics was a divine science. I thought that mathematics was the only science that spoke to inspiration and was infallible in its utterances [but] here is a new system of mathematics that demonstrates the truth to be false.’ In 1901 Representative John E. Littlefield, whose own seat in Maine was under threat from the Alabama paradox, said, ‘God help the State of Maine when mathematics reach for her and undertake to strike her down.’ As a matter of fact, there is no such thing as mathematical ‘in - spiration’ (mathematical knowledge coming from an infallible source, 333 the beginning of infinity traditionally God): as I explained in Chapter 8, our knowledge of mathematics is not infallible. But if Representative Mills meant that mathematicians are, or somehow ought to be, society’s best judges of fairness, then he was simply mistaken.* The National Academy of Sciences panel that reported to Congress in 1948 included the mathematician and physicist John von Neumann. It decided that a rule invented by the statistician Joseph Adna Hill (which is the one in use today) is the most impartial between states. But the mathematicians Michel Balinski and Peyton Young have since concluded that it favours smaller states. This illustrates again that different criteria of ‘impartiality’ favour different apportionment rules, and which of them is the right criterion cannot be determined by mathematics. Indeed, if Representative Mills intended his complaint ironically – if he really meant that mathematics alone could not possibly be causing injustice and that mathematics alone could not cure it – then he was right. However, there is a mathematical discovery that has changed for ever the nature of the apportionment debate: we now know that the quest for an apportionment rule that is both proportional and free from paradoxes can never succeed. Balinski and Young proved this in 1975. Balinski and Young’s Theorem Every apportionment rule that stays within the quota suffers from the population paradox. This powerful ‘no-go’ theorem explains the long string of historical failures to solve the apportionment problem. Never mind the various other conditions that may seem essential for an apportionment to be fair: no apportionment rule can meet even the bare-bones requirements of proportionality and the avoidance of the population paradox. Balinski and Young also proved no-go theorems involving other classic paradoxes. This work had a much broader context than the apportionment problem. During the twentieth century, and especially following the Second World War, a consensus had emerged among most major *It should of course be physicists. 334 Choices political movements that the future welfare of humankind would depend on an increase in society-wide (preferably worldwide) plan - ning and decision-making. The Western consensus differed from its totalitarian counterparts in that it expected the object of the exercise to be the satisfaction of individual citizens’ preferences. So Western advocates of society-wide planning were forced to address a fundamental question that totalitarians do not encounter: when society as a whole faces a choice, and citizens differ in their preferences among the options, which option is it best for society to choose? If people are unanimous, there is no problem – but no need for a planner either. If they are not, which option can be rationally defended as being ‘the will of the people’ – the option that society ‘wants’? And that raises a second question: how should society organize its decision-making so that it does indeed choose the options that it ‘wants’? These two questions had been present, at least implicitly, from the beginning of modern democracy. For instance, the US Declaration of Independence and the US Con- stitution both speak of the right of ‘the people’ to do certain things such as remove governments. Now they became the central questions of a branch of mathematical game theory known as social-choice theory. Thus game theory – formerly an obscure and somewhat whimsical branch of mathematics – was suddenly thrust to the centre of human affairs, just as rocketry and nuclear physics had been. Many of the world’s finest mathematical minds, including von Neumann, rose to the challenge of developing the theory to support the needs of the countless institutions of collective decision-making that were being set up. They would create new mathematical tools which, given what all the individuals in a society want or need, or prefer, would distil what that society ‘wants’ to do, thus implementing the aspiration of ‘the will of the people’. They would also determine what systems of voting and legislating would give society what it wants. Some interesting mathematics was discovered. But little, if any, of it ever met those aspirations. On the contrary, time and again the assumptions behind social-choice theory were proved to be incoherent or inconsistent by ‘no-go’ theorems like that of Balinski and Young. Thus it turned out that",
      "$id": "6702393962238c6460c4",
      "$createdAt": "2024-10-06T07:16:09.405+00:00",
      "$updatedAt": "2024-10-06T07:16:09.405+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    },
    {
      "chunk_text": "– had already been discovered during the twentieth century. 447 the beginning of infinity Horgan wrote that he had originally believed science to be ‘open- ended, even infinite’. But he became convinced of the contrary by (what I would call) a series of misconceptions and bad arguments. His basic misconception was empiricism. He believed that what distinguishes science from unscientific fields such as literary criticism, philosophy or art is that science has the ability to ‘resolve questions’ objectively (by comparing theories with reality), while other fields can produce only multiple, mutually incompatible interpretations of any issue. He was mistaken in both respects. As I have explained throughout this book, there is objective truth to be found in all those fields, while finality or infallibility cannot be found anywhere. Horgan accepts from the bad philosophy of ‘postmodern’ literary criticism its wilful confusion between two kinds of ‘ambiguity’ that can exist in philosophy and art. The first is the ‘ambiguity’ of multiple true meanings, either intended by the author or existing because of the reach of the ideas. The second is the ambiguity of deliberate vagueness, confusion, equivocation or self-contradiction. The first is an attribute of deep ideas, the second an attribute of deep silliness. By confusing them, one ascribes to the best art and philosophy the qualities of the worst. Since, in that view, readers, viewers and critics can attribute any meaning they choose to the second kind of ambiguity, bad philosophy declares the same to be true of all knowledge: all meanings are equal, and none of them is objectively true. One then has a choice between complete nihilism or regarding all ‘ambiguity’ as a good thing in those fields. Horgan chooses the latter option: he classifies art and philosophy as ‘ironic’ fields, irony being the presence of multiple conflicting mean- ings in a statement. However, unlike the postmodernists, Horgan thinks that science and mathematics are the shining exceptions to all that. They alone are capable of non-ironic knowledge. But there is also, he concludes, such a thing as ironic science – the kind of science that cannot ‘resolve questions’ because, essentially, it is just philosophy or art. Ironic science can continue indefinitely, but that is precisely because it never resolves anything; it never discovers objective truth. Its only value is in the eye of the beholder. So the future, according to Horgan, belongs to ironic knowledge. Objective knowledge has already reached its ultimate bounds. 448 The Beginning Horgan surveys some of the open questions of fundamental science, and judges them all either ‘ironic’ or non-fundamental, in support of his thesis. But that conclusion was made inevitable by his premises alone. For consider the prospect of any future discovery that would constitute fundamental progress. We cannot know what it is, but bad philosophy can already split it, on principle, into a new rule of thumb and a new ‘interpretation’ (or explanation). The new rule of thumb cannot possibly be fundamental: it will just be another equation. Only a trained expert could tell the difference between it and the old equation. The new ‘interpretation’ will by definition be pure philosophy, and hence must be ‘ironic’. By this method, any potential progress can be pre-emptively reinterpreted as non-progress. Horgan rightly points out that his prophecy cannot be proved false by placing it in the context of previous failed prophecies. The fact that Michelson was wrong about the achievements of the nineteenth century, and Lagrange about those of the seventeenth, does not imply that Horgan was wrong about those of the twentieth. However, it so happens that our current scientific knowledge includes a historically unusual number of deep, fundamental problems. Never before in the history of human thought has it been so obvious that our knowledge is tiny and our ignorance vast. And so, unusually, Horgan’s pessimism contradicts existing knowledge as well as being a prophetic fallacy. For example, the problem-situation of fundamental physics today has a radically different structure from that of 1894. Although physicists then were aware of some phenomena and theoretical issues which we now recognize as harbingers of the revolutionary explanations to come, their importance was unclear at the time. It was hard to distinguish those harbingers from anomalies that would eventually be cleared up with existing explanations plus the tweaking of the ‘sixth place of decimals’ or minor terms in a formula. But today there is no such excuse for denying that some of our problems are fundamental. Our best theories are telling us of profound mismatches between themselves and the reality that they are supposed to explain. One of the most blatant examples of that is that physics currently has two fundamental ‘systems of the world’ – quantum theory and the general theory of relativity – and they are radically inconsistent. There are many ways of characterizing this inconsistency – known as the 449 the beginning of infinity problem of quantum gravity – corresponding to the many proposals for solving it that have been tried without success. One aspect is the ancient tension between the discrete and the continuous. The resolution that I described in Chapter 11, in terms of continuous clouds of fungible instances of a particle with diverse discrete attributes, works only if the spacetime in which this happens is itself continuous. But if spacetime is affected by the gravitation of the cloud, then it would acquire discrete attributes. In cosmology, there has been revolutionary progress even in the few years since The End of Science was written – and also since I wrote The Fabric of Reality soon afterwards. At the time, all viable cosmo- logical theories had the expansion of the universe gradually slowing down, due to gravity, ever since the initial explosion at the Big Bang and for ever in the future. Cosmologists were trying to determine whether, despite slowing down, its expansion rate was sufficient to make the universe expand for ever (like a projectile that has exceeded escape velocity) or whether it would eventually recollapse in a ‘Big Crunch’. Those",
      "$id": "670239556b5a60ce1e7a",
      "$createdAt": "2024-10-06T07:16:37.442+00:00",
      "$updatedAt": "2024-10-06T07:16:37.442+00:00",
      "$permissions": [],
      "books": {
        "book_name": "'The Beginning of Infinity",
        "book_image": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238d3c21fa2774b2c/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "pdf_link": "https://cloud.appwrite.io/v1/storage/buckets/6700e87a00391724d5a6/files/670238:d21f03f18d1ebd/view?project=66dbf6d3002ec04e3664&project=66dbf6d3002ec04e3664&mode=admin",
        "$id": "670238d4cb1f7722bd99",
        "$createdAt": "2024-10-06T07:14:28.833+00:00",
        "$updatedAt": "2024-10-06T07:14:28.833+00:00",
        "$permissions": [],
        "$databaseId": "66e19d1d001c2f82d920",
        "$collectionId": "6700e10f0005b5d2e535"
      },
      "$databaseId": "66e19d1d001c2f82d920",
      "$collectionId": "6700e1b700380f51b3eb"
    }
  ]
}
