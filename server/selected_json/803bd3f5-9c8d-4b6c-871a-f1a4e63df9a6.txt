growth physics 96–103, 104, 105, 106, see under unpredictability 111, 113, 294, 434 won’t resemble the past 5–7, 29, 31 problems with anthropic explanation see also prophecy of 177–80, 195, 452, 453 galaxies 2–3, 28, 34–40, 44–5, 58, 68, finitism 165–6 101, 275, 281, 302 fire 12, 50, 111, 202, 207, 400 clusters of 34–6 see also elements, ancient theory of effects of dark energy on 451 first-past-the-post (plurality) voting effects of dark matter on 46 system 346–50, 352 Milky Way 1, 2, 47, 70–71, 101, flagellants 385 202–3 Flew, Antony 97 space between see space, intergalactic Florence 218–21, 386 Galileo Galilei 14, 219–20, 390 flowers, and the objectivity of beauty gambler’s prophecy see prophecy 360–64 game theory see social-choice theory food gamma rays 68 and co-evolution 360 bursts of 2, 208 production 205, 206, 208 Gauss, Carl Friedrich 183 supply 11, 48, 89, 206, 400, 408 generation ship 44, 69 see also agriculture genes 29, 43, 56–7, 58, 59, 78, 80, fooling ourselves, keep from 22, 209, 89–92, 105–6, 142, 158, 315, 316, 301, 317 364, 371, 378, 399 forests and co-evolution 360–64, 414–15 deforestation 418, 420–21, 422 of endangered species 95 management 423, 424–5, 430 genetic code and the jump to Forward, Robert: Dragon’s Egg 97 universality 142–6, 162–3, 458 fossils 51, 95–6, 121, 292, 315–16 genetic engineering see biotechnology Free Democratic Party (FDP, Germany) genetic evidence 49, 56, 206 339–40 genetic explanations of individual freedom 51, 217, 250, 343, 369, 392, human attributes 317–19, 323, 405, 457 356, 359, 401, 410, 429 French Revolution 66 knowledge implicit in 29, 50, 56–7, Freyr myth 20, 21, 25 59, 60, 72, 88, 111, 114, 366, 400 Friedman, David 444 and memes 372–97, 404, 405, 407, fun 35, 36–7, 41, 115, 149 408, 413, 414 fundamental theory or phenomenon see and neo-Darwinism 89–96 significance see also DNA; genomes; replicators fungibility 265–9, 270, 272–305, 450 genomes 56–7, 144, 362, 364, 378, 379, difficulty of imagining 269 411 diversity within 268, 278, 289 geocentric theory 8, 42 future see also celestial sphere theory anthropic reasoning about the future geography 452–6 biogeography 425–31 472 index of Mars 5 291, 303–4 of the universe 443 heliocentric theory 8, 26–7 geometry 7, 23, 24, 42, 113, 119, 161, helium 1, 47, 96 183–4, 188, 230, 233, 240, 252 helots 218, 247 see also space, Euclidean; space, Heraclitus 7 curvature of spacetime Hermes, and ‘a dream of Socrates’ Gibson, William: The Difference Engine 223–43 137 Herodotus 216 giraffes, evolution of the neck 88, 362 high-level phenomena 108–10, 114, 160, global warming 437–41 300–301, 371 God 52, 80–81, 87 Hilbert, David 186, 189 argument from design for existence Infinity Hotel thought experiment of 83–7 167–77, 181, 185–6, 195 creationism and 81 Hill, Joseph Adna 334 and mathematical infinities 166 historians of science 256 gods 21, 26, 42, 43, 60, 64, 79, 80, 81, histories (sequences of events in a 97, 104, 203, 217, 243 multiverse) Gödel, Kurt 184–5 coarse-grained 293, 298 gold 1–2, 30 definition 265 golden age differentiation/splitting of 273–5, of Athens 216–17, 254, 386 276–9, 285–8, 293–4 of Florence 218, 386 distinguished from universes 265 Islamic 220 and entanglement information 281, myths 52, 63 289–90 Grace, Fall from 52 and explicability 301 grammatical rules 374–5 and fungibility see fungibility gravity 29, 107, 112–13 and interference 283–8, 291, 293 gravitational effects of dark matter 46 measurement and 307 gravitational energy 3 multiplicity of histories between quantum 178, 449–50 observations 308 see also space, curvature of spacetime; rate of growth of distinct histories relativity 288 Great Rift Valley 48, 50, 58, 69 rejoining of split histories 282–5 guessing see conjecture and strata 293 Gutenberg, Johannes 134 history 265, 429 alternative-history fiction 259, 294 Hades 19 distinguished from ‘world’, ‘universe’ Haldane, John 53, 56, 59, 81, 95 and ‘multiverse’ 265 hallucination 301 of ideas 4, 5, 43, 216, 305–16, 428, see also mirages 442 see also philosophy Hamilton, Alexander 330 of life 68, 92, 95, 379–80 Hamilton’s rule 330, 331, 332 of optimism 216 Hanson, Norwood Russell 10n pessimism in 216 Hanson, Robin 457 of philosophy 255 happiness 316–19 see also civilization; prehistory Harris, Robert: Fatherland 259 Hofstadter, Douglas 115–18, 138, Harris, Roger 321 149–50 Hawking, Stephen 44, 45, 63, 175, 202, holism 110, 123–4 203, 204, 208 Homo erectus 400 Heisenberg, Werner 255, 289, 306–7, Horgan, John 447–9 309 House of Representatives, US 326, 330, Heisenberg uncertainty principle 289, 331, 349–50 473 index humanism 219 indiscernibles, Leibniz’s doctrine of humans 265–6 anthropocentrism see induction see inductivism anthropocentrism inductivism 5–7, 9, 27, 30, 210, 220, not supported by the biosphere 48–50 318, 340, 403 as channels of information flow 302 and Lamarckism 89, 106, 210, as chemical scum 44–8, 51, 72, 73 411–12 and the doomsday argument 455–6 principle of induction 5, 7, 28, 31 escapes from extinction 49, 196–7, inexplicability 53–4, 104, 103, 264–5, 204–5, 206–7 281–2, 445–6 as glowing 46 see also supernatural human appearance 365 inexplicit knowledge 365, 367, 369, and matter 46 374, 375, 380, 403–5, 408, 412, as problem-solvers 435; see also 414 problem solving infinity 164–95 the reach of human adaptations Cantor’s definition 167, 181 56–65 and confusions of abstract attributes significance of knowledge and 70–75, with physical ones of the same 76 name 182–6 as spark for knowledge creation 75 of the continuum 164, 170, 195 survival of civilization/species 49, countable 171, 172, 194 62–3, 196–7, 202, 204–5, 206–8 ideas with infinite reach 167–93 as universal constructors 58–60, 62, our infinite ignorance 447 429 infinite ignorance and potential for see also people knowledge 447 Hume, David 118, 120 the infinite reach of ideas 167–93 humour 150, 151, 156–7, 174, 310, infinite regress 174–5, 178, 190, 194, 355, 372–3, 374 226, 341 origin and evolution of jokes 93, infinite sets 102, 118, 122, 164, 167– 372–3, 374, 388 80, 277, 453 Hunt, Terry 418 Infinity Hotel thought experiment Huxley, Thomas 355 167–77, 181, 185–6, 195 hydrogen 47, 56, 66, 73, 75, 96, 145, introduction to concept of beginning 290–91 of vii–viii bombs
================================================================================desirable is perhaps the quintessential idea of the Enlightenment. It motivates all traditions of criticism, as well as the principle of seeking good explanations. But it can be interpreted in two almost opposite ways, both of which, confusingly, are known as ‘perfectibility’. One is that humans, or human societies, are capable of attaining a state of supposed perfection – such as the Buddhist or Hindu ‘nirvana’, or various political utopias. The other is that every attainable state can be indefinitely improved. Fallibilism rules out that first position in favour of the second. Neither the human condition in particular nor our explanatory knowledge in general will ever be perfect, nor even approximately perfect. We shall always be at the beginning of infinity. These two interpretations of human progress and perfectibility have historically inspired two broad branches of the Enlightenment which, though they share attributes such as their rejection of authority, are so different in important respects in that it is most unfortunate that they share the same name. The utopian ‘Enlightenment’ is sometimes called the Continental (European) Enlightenment to distinguish it from the more fallibilist British Enlightenment, which began a little earlier and 65 the beginning of infinity took a very different course. (See, for instance, the historian Roy Porter’s book Enlightenment.) In my terminology, the Continental Enlightenment understood that problems are soluble but not that they are inevitable, while the British Enlightenment understood both equally. Note that this is a classification of ideas, not of nations or even individual thinkers: not all Enlightenment thinkers belong wholly to one branch or the other; nor were all thinkers of the respective Enlighten ments born in the eponymous part of the world. The mathematician and philosopher Nicholas de Condorcet, for instance, was French yet belonged more to what I am calling the ‘British’ Enlightenment, while Karl Popper, the twentieth century’s foremost proponent of the British Enlightenment, was born in Austria. The Continental Enlightenment was impatient for the perfected state – which led to intellectual dogmatism, political violence and new forms of tyranny. The French Revolution of 1789 and the Reign of Terror that followed it are the archetypal examples. The British Enlightenment, which was evolutionary and cognizant of human fallibility, was im - patient for institutions that did not stifle gradual, continuing change. It was also enthusiastic for small improvements, unbounded in the future. (See, for instance, the historian Jenny Uglow’s book Lunar Men.) This is, I believe, the movement that was successful in its pursuit of progress, so in this book when I refer to ‘the’ Enlightenment I mean the ‘British’ one. To investigate the ultimate reach of humans (or of people, or of progress), we should not be considering places like the Earth and the moon, which are unusually rich in resources. Let us go back to that typical place. While the Earth is inundated with matter, energy and evidence, out there in intergalactic space all three are at their lowest possible supply. There is no rich supply of minerals, no vast nuclear reactor overhead delivering free energy, no lights in the sky or diverse local events to provide evidence of the laws of nature. It is empty, cold and dark. Or is it? Actually, that is yet another parochial misconception. Intergalactic space is indeed very empty by human standards. But each of those solar-system-sized cubes still contains over a billion tonnes of matter – mostly in the form of ionized hydrogen. A billion tonnes is more than enough mass to build, say, a space station and a colony of 66 The Spark scientists creating an open-ended stream of knowledge – if anyone were present who knew how to do that. No human today knows how. For instance, one would first have to transmute some of the hydrogen into other elements. Collecting it from such a diffuse source would be far beyond us at present. And, although some types of transmutation are already routine in the nuclear industry, we do not know how to transmute hydrogen into other elements on an industrial scale. Even a simple nuclear-fusion reactor is currently beyond our technology. But physicists are confident that it is not forbidden by any laws of physics, in which case, as always, it can only be a matter of knowing how. No doubt a billion-tonne space station is not large enough to thrive in the very long run. The inhabitants will want to enlarge it. But that presents no problem of principle. As soon as they started to trawl their cube for hydrogen, more would drift in from the surrounding space, supplying the cube with millions of tonnes of hydrogen per year. (There is also believed to be an even greater mass of ‘dark matter’ in the cube, but we do not know how to do anything useful with it, so let us ignore it in this thought experiment.) As for the cold, and the lack of available energy – as I said, the transmutation of hydrogen releases the energy of nuclear fusion. That would be a sizeable power supply, orders of magnitude more than the combined power consumption of everyone on Earth today. So the cube is not as lacking in resources as a parochial first glance would suggest. How would the space station get its vital supply of evidence? Using the elements created by transmutation, one could construct scientific laboratories, as in the projected moon base. On Earth, when chemistry was in its infancy, making discoveries often depended on travelling all over the planet to find materials to experiment on. But transmutation makes that irrelevant; and chemical laboratories on the space station would be able to synthesize arbitrary compounds of arbitrary elements. The same is true of elementary particle physics: in that field, almost anything will do as a source of evidence, because every atom is poten- tially a cornucopia of particles just waiting to display themselves if one hits the atom hard enough (using a particle accelerator) and observes with the right instruments. In biology, DNA and all
================================================================================novelty. Because we are universal explainers, we are not simply obeying our genes. For instance, humans often act in ways that are contrary to any preferences that might plausibly have been built into our genes. People fast – sometimes for aesthetic reasons. Some abstain from sex. People act in very diverse ways for religious reasons or for any number of other reasons, philosophical or scientific, practical or whimsical. We have an inborn aversion to heights and to falling, yet people go skydiving – not in spite of this feeling, but because of it. It is that very feeling of inborn aversion that humans can reinterpret into a larger picture which to them is attractive – they want more of it; they want to appreciate it more deeply. To a skydiver, the vista from which we were born to recoil is beautiful. The whole activity of skydiving is beautiful, and part of that beauty is in the very sensations that evolved to deter us from trying it. The conclusion is inescapable: that attraction is not inborn, just as the contents of a newly discovered law of physics or mathematical theorem are not inborn. Could it be purely cultural? We pursue beauty as well as truth, and in both cases we can be fooled. Perhaps we see a face as beautiful because it really is, or perhaps it is only because of a combination of our genes and our culture. A beetle is attracted to another beetle that you and I may see as hideous. But not if you are an entomologist. People can learn to see many things as beautiful or ugly. But, there again, people can also learn to see false scientific theories as true, and true ones as false, yet there is such a thing as objective scientific truth. So that still does not tell us whether there is such a thing as objective beauty. 359 the beginning of infinity Now, why is a flower the shape that it is? Because the relevant genes evolved to make it attractive to insects. Why would they do this? Because when insects visit a flower they are dusted with pollen, which they then deposit in other flowers of the same species, and so the genes in the DNA in that pollen are spread far and wide. This is the reproductive mechanism that flowering plants evolved and which most still use today: before there were insects, there were no flowers on Earth. But the mechanism could work only because insects, at the same time, evolved genes that attracted them to flowers. Why did they? Because flowers provide nectar, which is food. Just as there is co-evolution between the genes to coordinate mating behaviours in males and females of the same species, so genes for making flowers and giving them their shapes and colours co-evolved with genes in insects for recognizing flowers with the best nectar. During that biological co-evolution, just as in the history of art, criteria evolved, and means of meeting those criteria co-evolved with them. That is what gave flowers the knowledge of how to attract insects, and insects the knowledge of how to recognize those flowers and the propensity to fly towards them. But what is surprising is that these same flowers also attract humans. This is so familiar a fact that it is hard to see how amazing it is. But think of all the countless hideous animals in nature, and think also that all of them who find their mates by sight have evolved to find that appearance attractive. And therefore it is not surprising that we do not. With predators and prey there is a similar co-evolution, but in a 360 Why are Flowers Beautiful? competitive sense rather than a cooperative one: each has genes that evolved to enable it to recognize the other and to make it run towards or away from it respectively, while other genes evolve to make their organism hard to recognize against the relevant background. That is why tigers are striped. Occasionally it happens by chance that the parochial criteria of attractiveness that evolved within a species produce something that looks beautiful to us: the peacock’s tail is an example. But that is a rare anomaly: in the overwhelming majority of species, we do not share any of their criteria for finding something attractive. Yet with flowers – most flowers – we do. Sometimes a leaf can be beautiful; even a puddle of water can. But, again, only by rare chance. With flowers it is reliable. It is another regularity in nature. What is the explanation? Why are flowers beautiful? Given the prevailing assumptions in the scientific community – which are still rather empiricist and reductionist – it may seem plausible that flowers are not objectively beautiful, and that their attractiveness is merely a cultural phenomenon. But I think that that fails closer inspec- tion. We find flowers beautiful that we have never seen before, and which have not been known to our culture before – and quite reliably, for most humans in most cultures. The same is not true of the roots of plants, or the leaves. Why only the flowers? One unusual aspect of the flower–insect co-evolution is that it involved the creation of a complex code, or language, for signalling information between species. It had to be complex because the genes were facing a difficult communication problem. The code had to be, on the one hand, easily recognizable by the right insects, and, on the other, difficult to forge by other species of flower – for if other species could cause their pollen to be spread by the same insects without having to manufacture nectar for them, which requires energy, they would have a selective advantage. So the criterion that was evolving in the insects had to be discriminating enough to pick the right flowers and not crude imitations; and the flowers’ design had to be such that no design that other flower species could easily evolve could be
================================================================================theory that this gives information about which checkbox the respondents will choose in the election itself. That theory is then tested at the election. There is no analogue of such a test in the case of happiness: there is no independent way of measuring it. Another example of bona-fide science would be a clinical trial to test a drug purported to alleviate (particular identifiable types of) unhappiness. In that case, the objective of the study is, again, to determine whether the drug causes behaviour such as saying that one is happier (without also experiencing adverse side effects). If a drug passes that test, the issue of whether it really makes the patients happier, or merely alters their 317 the beginning of infinity personality to have lower standards or something of that sort, is in - accessible to science until such time as there is a testable explanatory theory of what happiness is In explanationless science, one may acknowledge that actual happi- ness and the proxy one is measuring are not necessarily equal. But one nevertheless calls the proxy ‘happiness’ and moves on. One chooses a large number of people, ostensibly at random (though in real life one is restricted to small minorities such as university students, in a particular country, seeking additional income), and one excludes those who have detectable extrinsic reasons for happiness or unhappiness (such as recent lottery wins or bereavement). So one’s subjects are just ‘typical people’ – though in fact one cannot tell whether they are statistically representative without an explanatory theory. Next, one defines the ‘heritability’ of a trait as its degree of statistical correlation with how genetically related the people are. Again, that is a non- explanatory definition: according to it, whether one was a slave or not was once a highly ‘heritable’ trait in America: it ran in families. More generally, one acknowledges that statistical correlations do not imply anything about what causes what. But one adds the inductivist equivo- cation that ‘they can be suggestive, though.’ Then one does the study and finds that ‘happiness’ is, say, 50 per cent ‘heritable’. This asserts nothing about happiness itself, until the relevant explanatory theories are discovered (at some time in the future – perhaps after consciousness is understood and AIs are commonplace technology). Yet people find the result interesting, because they interpret it via everyday meanings of the words ‘happiness’ and ‘heritable’. Under that interpretation – which the authors of the study, if they are scrupulous, will nowhere have endorsed – the result is a profound contribution to a wide class of philosophical and scientific debates about the nature of the human mind. Press reports of the discovery will reflect this. The headline will say, ‘New Study Shows Happiness 50% Genetically Determined’ – without quotation marks around the technical terms. So will subsequent bad philosophy. For, suppose that someone now does dare to seek explanatory theories about the cause of human happiness. Happiness is a state of continually solving one’s problems, they conjecture. Unhappiness is caused by being chronically baulked in one’s attempts to do that. And solving problems itself depends on 318 A Physicist’s History of Bad Philosophy knowing how; so, external factors aside, unhappiness is caused by not knowing how. (Readers may recognize this as a special case of the principle of optimism.) Interpreters of the study say that it has refuted that theory of happi- ness. At most 50 per cent of unhappiness can be caused by not knowing how, they say. The other 50 per cent is beyond our control: genetically determined, and hence independent of what we know or believe, pending the relevant genetic engineering. (Using the same logic on the slavery example, one could have concluded in 1860 that, say, 95 per cent of slavery is genetically determined and therefore beyond the power of political action to remedy.) At this point – taking the step from ‘heritable’ to ‘genetically deter- mined’ – the explanationless psychological study has transformed its correct but uninteresting result into something very exciting. For it has weighed in on a substantive philosophical issue (optimism) and a scientific issue about how the brain gives rise to mental states such as qualia. But it has done so without knowing anything about them. But wait, say the interpreters. Admittedly we can’t tell whether any genes code for happiness (or part of it). But who cares how the genes cause the effect – whether by conferring good looks or otherwise? The effect itself is real. The effect is real, but the experiment cannot detect how much of it one can alter without genetic engineering, just by knowing how. That is because the way in which those genes affect happiness may itself depend on knowledge. For instance, a cultural change may affect what people deem to be ‘good looks’, and that would then change whether people tend to be made happier by virtue of having particular genes. Nothing in the study can detect whether such a change is about to happen. Similarly, it cannot detect whether a book will be written one day which will persuade some proportion of the population that all evils are due to lack of knowledge, and that knowledge is created by seeking good explanations. If some of those people consequently create more knowledge than they otherwise would have, and become happier than they otherwise would have been, then part of the 50 per cent of happiness that was ‘genetically determined’ in all previous studies will no longer be so. The interpreters of the study may respond that it has proved that 319 the beginning of infinity there can be no such book! Certainly none of them will write such a book, or arrive at such a thesis. And so the bad philosophy will have caused bad science, which will have stifled the growth of knowledge. Notice that this is a form of bad science that may well have conformed to all the best practices of scientific method – proper randomizing, proper controls, proper statistical
================================================================================our knowledge will always be infinitely far from complete. Some problems are hard, but it is a mistake to confuse hard problems with problems unlikely to be solved. Problems are soluble, and each particular evil is a problem that can be solved. An optimistic civilization is open and not afraid to innovate, and is based on traditions of criticism. Its institutions keep improving, and the most important knowledge that they embody is knowledge of how to detect and eliminate errors. There may have been many short-lived enlightenments in history. Ours has been uniquely long-lived. 222 10 A Dream of Socrates socrates is staying at an inn near the Temple of the Oracle at Delphi. Together with his friend chaerephon, he has today asked the Oracle who the wisest man in the world is,* so that they might go and learn from him. But, to their annoyance, the priestess (who provides the Oracle’s voice on behalf of the god Apollo) merely announced, ‘No one is wiser than Socrates.’ Sleeping now on an uncomfortable bed in a tiny and exorbitantly expensive room, socrates hears a deep, melodious voice intoning his name. hermes: Greetings, Socrates. socrates: [Draws the blanket over his head.] Go away. I’ve already made too many offerings today and you’re not going to wring any more out of me. I am too ‘wise’ for that, hadn’t you heard? hermes: I seek no offering. socrates: Then what do you want? [He turns and sees hermes, who is naked.] Well, I’m sure that some of my associates camped outside will be glad to – hermes: It is not them I seek, but you, O Socrates. socrates: Then you shall be disappointed, stranger. Now kindly leave me to my hard-earned rest. hermes: Very well. [He makes towards the door.] socrates: Wait. hermes: [Turns and raises a quizzical eyebrow.] *In the story as told by Plato in his Apology, Chaerophon asks the Oracle whether there is anyone wiser than Socrates, and is told no. But would he really have wasted this expensive and solemn privilege on a question with only two possible answers, one flattering, the other frustrating, and neither very interesting? 223 the beginning of infinity socrates: [slowly and deliberately] I am asleep. Dreaming. And you are the god Apollo. hermes: What makes you think so? socrates: These precincts are sacred to you. It is night-time and there is no lamp, yet I see you clearly. This is not possible in real life. So you must be coming to me in a dream. hermes: You reason coolly. Are you not afraid? socrates: Bah! I ask you in return: are you a benevolent or a malevolent god? If benevolent, then what do I have to fear? If malevolent, then I disdain to fear you. We Athenians are a proud people – and protected by our goddess, as you surely know. Twice we defeated the Persian Empire against overwhelming odds,* and now we are defying Sparta. It is our custom to defy anyone who seeks our submission. hermes: Even a god? socrates: A benevolent god would not seek it. On the other hand, it is also our custom to give a hearing to anyone who offers us honest criticism, seeking to persuade us freely to change our minds. For we want to do what is right. hermes: Those two customs are two sides of the same valuable coin, Socrates. I give you Athenians great credit for honouring them. socrates: My city is surely deserving of your favour. But why would an immortal want to converse with such a confused and ignorant person as me? I think I can guess your reason: you have repented of your little joke via the Oracle, haven’t you? Indeed, it was rather cruel of you to send us only a mocking answer, considering the distance we have come and the offerings we have made. So please tell me the truth this time, O fount of wisdom: who is really the wisest man in the world? hermes: I reveal no facts. socrates: [Sighs.] Then I beg you – I have always wanted to know this: what is the nature of virtue? hermes: I reveal no moral truths either. *In this dialogue, Socrates sometimes exaggerates the attributes and achievements of his beloved home city-state, Athens. In this case he is ignoring the contributions of other Greek city-states to the defeats of two invasion attempts by the Persian Empire, both of them before he was born. 224 A Dream of Socrates socrates: Yet, as a benevolent god, you must have come here to impart some sort of knowledge. What sort will you deign to grant me? hermes: Knowledge about knowledge, Socrates. Epistemology. I have already mentioned some. socrates: You have? Oh – you said that you honour Athenians for our openness to persuasion. And for our defiance of bullies. But it is well known that those are virtues! Surely telling me what I already know doesn’t count as a ‘revelation’. hermes: Most Athenians would indeed call those virtues. But how many really believe it? How many are willing to criticize a god by the standards of reason and justice? socrates: [Ponders.] All who are just, I suppose. For how can anyone be just if he follows a god of whose moral rightness he is not persuaded? And how is it possible to be persuaded of someone’s moral rightness without first forming a view about which qualities are morally right? hermes: Your associates out there on the lawn – are they unjust? socrates: No. hermes: And are they aware of the connections you have just described between reason, morality and the reluctance to defer to gods? socrates: Perhaps not sufficiently aware – yet. hermes: So it is not true that every just person knows these things. socrates: Agreed. Perhaps it is only every wise person. hermes: Everyone who is at least as wise as you, then. Who else is in that exalted category? socrates: Is there some high purpose in your continuing to mock
================================================================================the age of the universe could not solve the equations that predict what all those water molecules will do – even if we could somehow determine their initial state and that of all the outside influences on them, which is itself an intractable task. Fortunately, some of that complexity resolves itself into a higher-level 107 the beginning of infinity simplicity. For example, we can predict with some accuracy how long the water will take to boil. To do so, we need know only a few physical quantities that are quite easy to measure, such as its mass, the power of the heating element, and so on. For greater accuracy we may also need information about subtler properties, such as the number and type of nucleation sites for bubbles. But those are still relatively ‘high-level’ phenomena, composed of intractably large numbers of interacting atomic-level phenomena. Thus there is a class of high-level phenomena – including the liquidity of water and the relation s hip between con tainers, heating elements, boiling and bubbles – that can be well explained in terms of each other alone, with no direct reference to anything at the atomic level or below. In other words, the behaviour of that whole class of high-level phenomena is quasi-autonomous – almost self-contained. This resolution into explicability at a higher, quasi- autonomous level is known as emergence. Emergent phenomena are a tiny minority. We can predict when the water will boil, and that bubbles will form when it does, but if you wanted to predict where each bubble will go (or, to be precise, what the probabilities of its various possible motions are – see Chapter 11), you would be out of luck. Still less is it feasible to predict the countless microscopically defined properties of the water, such as whether an odd or an even number of its electrons will be affected by the heating during a given period. Fortunately, we are uninterested in predicting or explaining most of those properties, despite the fact that they are the overwhelming majority. That is because none of them has any bearing on what we want to do with the water – such as understand what it is made of, or make tea. To make tea, we want the water to be boiling, but we do not care what the pattern of bubbles was. We want its volume to be between a certain minimum and maximum, but we do not care how many molecules that is. We can make progress in achieving those purposes because we can express them in terms of those quasi- autonomous emergent properties about which we have good high-level explanations. Nor do we need most of the microscopic details in order to understand the role of water in the cosmic scheme of things, because nearly all of those details are parochial. The behaviour of high-level physical quantities consists of nothing 108 The Reality of Abstractions but the behaviour of their low-level constituents with most of the details ignored. This has given rise to a widespread misconception about emergence and explanation, known as reductionism: the doctrine that science always explains and predicts things reductively, i.e. by analysing them into components. Often it does, as when we use the fact that inter-atomic forces obey the law of conservation of energy to make and explain a high-level prediction that the kettle cannot boil water without a power supply. But reductionism requires the relationship between different levels of explanation always to be like that, and often it is not. For example, as I wrote in The Fabric of Reality: Consider one particular copper atom at the tip of the nose of the statue of Sir Winston Churchill that stands in Parliament Square in London. Let me try to explain why that copper atom is there. It is because Churchill served as prime minister in the House of Commons nearby; and because his ideas and leadership contributed to the Allied victory in the Second World War; and because it is customary to honour such people by putting up statues of them; and because bronze, a traditional material for such statues, contains copper, and so on. Thus we explain a low-level physical observation – the presence of a copper atom at a particular location – through extremely high-level theories about emergent phenomena such as ideas, leadership, war and tradition. There is no reason why there should exist, even in principle, any lower- level explanation of the presence of that copper atom than the one I have just given. Presumably a reductive ‘theory of everything’ would in principle make a low-level prediction of the probability that such a statue will exist, given the condition of (say) the solar system at some earlier date. It would also in principle describe how the statue probably got there. But such descriptions and predictions (wildly infeasible, of course) would explain nothing. They would merely describe the trajectory that each copper atom followed from the copper mine, through the smelter and the sculptor’s studio and so on . . . In fact such a prediction would have to refer to atoms all over the planet, engaged in the complex motion we call the Second World War, among other things. But even if you had the superhuman capacity to follow such lengthy predictions of the copper atom’s being there, you would still not be able to say ‘Ah yes, now I understand why they are there’. [You] would have to inquire into what it was about that configuration of atoms, and those trajectories, that gave 109 the beginning of infinity them the propensity to deposit a copper atom at this location. Pursuing that inquiry would be a creative task, as discovering new explanations always is. You would have to discover that certain atomic configurations support emergent phenomena such as leadership and war, which are related to one another by high-level explanatory theories. Only when you knew those theories could you understand why that copper atom is where it is. Even in physics,
================================================================================will stand for longer than the pyramids have so far. Surprising scientific discoveries will be made, some of which will change the standard textbooks for ever. All these consequences of creativity make for an ever-changing way of life, 398 The Evolution of Creativity which is possible only in a long-lived dynamic society – itself a phenomenon that nothing other than creative thought could possibly bring about. However, as I pointed out in the previous chapter and Chapter 1, it was only recently in the history of our species that creativity has had any of those effects. In prehistoric times it would not have been obvious to a casual observer (say, an explorer from an extraterrestrial civil- ization) that humans were capable of creative thought at all. It would have seemed that we were doing no more than endlessly repeating the lifestyle to which we were genetically adapted, just like all the other billions of species in the biosphere. Clearly, we were tool-users – but so were many other species. We were communicating using symbolic language – but, again, that was not unusual: even bees do that. We were domesticating other species – but so do ants. Closer observation would have revealed that human languages and the knowledge for human tool use were being transmitted through memes and not genes. That made us fairly unusual, but still not obviously creative: several other species have memes. But what they do not have is the means of improving them other than through random trial and error. Nor are they capable of sustained improvement over many generations. Today, the creativity that humans use to improve ideas is what pre-eminently sets us apart from other species. Yet for most of the time that humans have existed it was not noticeably in use. Creativity would have been even less noticeable in the predecessor of our species. Yet it must already have been evolving in that species, or ours would never have been the result. In fact the advantage con - ferred by successive mutations that gave our predecessors’ brains slightly more creativity (or, more precisely, more of the ability that we now think of as creativity) must have been quite large, for by all accounts modern humans evolved from ape-like ancestors very rapidly by gene-evolution standards. Our ancestors must have been continually out-breeding their cousins who had slightly less ability to create new knowledge. Why? What were they using this knowledge for? If we did not know better, the natural answer would be that they were using it as we do today, for innovation and for understanding the world, in order to improve their lives. For instance, individuals who could improve stone tools would have ended up with better tools, 399 the beginning of infinity and hence with better food and more surviving offspring. They would also have been able to make better weapons, thus denying the holders of rival genes access to food and mates – and so on. Yet if that had happened, the palaeontological record would show those improvements happening on a timescale of generations. But it does not. Moreover, during the period when creativity was evolving, the ability to replicate memes was evolving too. It is believed that some members of the species Homo erectus living 500,000 years ago knew how to make camp fires. That knowledge was in their memes, not in their genes. And, once creativity and meme transmission are both present, they greatly enhance each other’s evolutionary value, for then anyone who improves something also has the means to bequeath the innovation to all future generations, thus multiplying the benefit to the relevant genes. And memes can be improved much faster by creativity than by random trial and error. Since there is no upper limit to the value of ideas, the conditions would have been there for a runaway co-evolution between the two adaptations: creativity and the ability to use memes. Yet, again, there is something wrong with that scenario. The two adaptations presumably did co-evolve, but the driving force behind that evolution cannot have been that people were improving on ideas and passing the improvements on to their children, because, again, if they had been, they would have been making cumulative improvements on a timescale of generations. Before the beginning of agriculture, about 12,000 years ago, many thousands of years passed between noticeable changes. It is as though each small genetic improvement in creativity produced just one noticeable innovation and then nothing more – rather like today’s experiments in ‘artificial evolution’. But how can that be? Unlike present-day artificial-evolution and AI research, our ancestors were evolving real creativity, which is the capacity to create an endless stream of innovations. Their ability to innovate was increasing rapidly, but they were barely innovating. This is a puzzle not because it is odd behaviour, but because, if innovation was that rare, how could there have been a differential effect on the reproduction of individuals with more or less ability to innovate? That there were thousands of years between noticeable changes presumably means that in most generations even the most creative individuals in the population would not have been making 400 The Evolution of Creativity any innovations. Hence their greater ability to innovate would have caused no selection pressure in their favour. Why did tiny improvements in that ability keep spreading rapidly through the population? Our ancestors must have been using their creativity – and using it to its limits, and frequently – for something. But evidently not for innovation. What else could it have been used for? One theory is that it did not evolve to provide any functional advantage, but merely through sexual selection: people used it to create displays to attract mates – colourful clothing, decorations, story-telling, wit and the like. A preference to mate with the individuals with the most creative displays co-evolved with the creativity to meet that preference in an evolutionary spiral – so the theory goes – just like peahens’ preferences and peacocks’ tails. But
================================================================================descent from empiricism (merely false) to positivism, logical positivism, instrumentalism, Wittgenstein, linguistic philosophy, and the ‘post- modernist’ and related movements. In science, the main impact of bad philosophy has been through the idea of separating a scientific theory into (explanationless) predictions and (arbitrary) interpretation. This has helped to legitimize de - humanizing explanations of human thought and behaviour. In quantum theory, bad philosophy manifested itself mainly as the Copenhagen interpretation and its many variants, and as the ‘shut-up-and-calculate’ interpretation. These appealed to doctrines such as logical positivism to justify systematic equivocation and to immunize themselves from criticism. 325 13 Choices In March 1792 George Washington exercised the first presidential veto in the history of the United States of America. Unless you already know what he and Congress were quarrelling about, I doubt that you will be able to guess, yet the issue remains controversial to this day. With hindsight, one may even perceive a certain inevitability in it, for, as I shall explain, it is rooted in a far-reaching misconception about the nature of human choice, which is still prevalent. On the face of it, the issue seems no more than a technicality: in the US House of Representatives, how many seats should each state be allotted? This is known as the apportionment problem, because the US Constitution requires seats to be ‘apportioned among the several States . . . according to their respective Numbers [i.e. their populations]’. So, if your state contained 1 per cent of the US population, it would be entitled to 1 per cent of the seats in the House. This was intended to implement the principle of representative government – that the legislature should represent the people. It was, after all, about the House of Representatives. (The US Senate, in contrast, represents the states of the Union, and hence each state, regardless of population, has two senators.) At present there are 435 seats in the House of Representatives; so, if 1 per cent of the US population did live in your state, then by strict proportionality the number of representatives to which it would be entitled – known as its quota – would be 4.35. When the quotas are not whole numbers, which of course they hardly ever are, they have to be rounded somehow. The method of rounding is known as an apportionment rule. The Constitution did not specify an apportionment rule; it left such details to Congress, and that is where the centuries of controversy began. 326 Choices An apportionment rule is said to ‘stay within the quota’ if the number of seats that it allocates to each state never differs from the state’s quota by as much as a whole seat. For instance, if a state’s quota is 4.35 seats, then to ‘stay within the quota’ a rule must assign that state either four seats or five. It may take all sorts of information into account in choosing between four and five, but if it is capable of assigning any other number it is said to ‘violate quota’. When one first hears of the apportionment problem, compromises that seem to solve it at a stroke spring easily to mind. Everyone asks, ‘Why couldn’t they just . . . ?’ Here is what I asked: Why couldn’t they just round each state’s quota to the nearest whole number? Under that rule, a quota of 4.35 seats would be rounded down to four; 4.6 seats would be rounded up to five. It seemed to me that, since this sort of rounding can never add or subtract more than half a seat, it would keep each state within half a seat of its quota, thus ‘staying within the quota’ with room to spare. I was wrong: my rule violates quota. This is easy to demonstrate by applying it to an imaginary House of Representatives with ten seats, in a nation of four states. Suppose that one of the states has just under 85 per cent of the total population, and the other three have just over 5 per cent each. The large state therefore has a quota of just under 8.5, which my rule rounds down to eight. Each of the three small states has a quota of just over half a seat, which my rule rounds up to one. But now we have allocated eleven seats, not ten. In itself that hardly matters: the nation merely has one more legislator to feed than planned. The real problem is that this apportionment is no longer representative: 85 per cent of eleven is not 8.5 but 9.35. So the large state, with only eight seats, is in fact short of its quota by well over one seat. My rule under-represents 85 per cent of the population. Because we intended to allocate ten seats, the exact quotas necessarily add up to ten; but the rounded ones add up to eleven. And if there are going to be eleven seats in the House, the principle of representative government – and the Constitution – requires each state to receive its fair share of those, not of the ten that we merely intended. Again, many ‘why don’t they just . . . ?’ ideas spring to mind. Why don’t they just create three additional seats and give them to the large state, thus bringing the allocation within the quota? (Curious readers 327 the beginning of infinity may check that no fewer than three additional seats are needed to achieve this.) Alternatively, why don’t they just transfer a seat from one of the small states to the large state? Perhaps it should be from the state with the smallest population, so as to disadvantage as few people as possible. That would not only bring all the allocations within the quota, but also restore the number of seats to the originally intended ten. Such strategies are known as reallocation schemes. They are indeed capable of staying within the quota. So, what is wrong with them? In the jargon of the subject, the
================================================================================However, in regard to these more sophisticated applications, the system was not universal. Since there was no higher-valued symbol than (cid:4)(cid:5) (one thousand), the numerals from two thousand onwards all began with a string of (cid:4)(cid:5)’s, which therefore became nothing more than tally marks for thousands. The more of them there were in a numeral, the more one would have to fall back on tallying (examining many instances of the symbol one by one) in order to do arithmetic. Just as one could upgrade the vocabulary of an ancient writing system by adding pictograms, so one could add symbols to a system of numerals to increase its range. And this was done. But the resulting system would still always have a highest-valued symbol, and hence 130 The Jump to Universality would not be universal for doing arithmetic without tallying. The only way to emancipate arithmetic from tallying is with rules of universal reach. As with alphabets, a small set of basic rules and symbols is sufficient. The universal system in general use today has ten symbols, the digits 0 to 9, and its universality is due to a rule that the value of a digit depends on its position in the number. For instance, the digit 2 means two when written by itself, but means two hundred in the numeral 204. Such ‘positional’ systems require ‘placeholders’, such as the digit 0 in 204, whose only function is to place the 2 into the position where it means two hundred. This system originated in India, but it is not known when. It might have been as late as the ninth century, since before that only a few ambiguous documents seem to show it in use. At any rate, its tremen- dous potential in science, mathematics, engineering and trade was not widely realized. At approximately that time it was embraced by Arab scholars, yet was not generally used in the Arab world until a thousand years later. This curious lack of enthusiasm for universality was repeated in medieval Europe: a few scholars adopted Indian numerals from the Arabs in the tenth century (resulting in the misnomer ‘Arabic numerals’), but again these numerals did not come into everyday use for centuries. As early as 1900 bce the ancient Babylonians had invented what was in effect a universal system of numerals, but they too may not have cared about its universality – nor even been aware of it. It was a positional system, but very cumbersome compared with the Indian one. It had 59 ‘digits’, each of which was itself written as a numeral in a Roman-numeral-like system. So using it for arithmetic with numbers occurring in everyday life was actually more complicated than using Roman numerals. It also had no symbol for zero, so it used spaces as placeholders. It had no way of representing trailing zeros, and no equivalent of the decimal point (as if, in our system, the numbers 200, 20, 2, 0.2 and so on were all written as 2, and were distinguished only by context). All this suggests that universality was not the system’s main design objective, and that it was not greatly valued when it was achieved. Perhaps an insight into this recurring oddity is provided by a re - markable episode in the third century bce involving the ancient Greek 131 the beginning of infinity scientist and mathematician Archimedes. His research in astronomy and pure mathematics led him to a need to do arithmetic with some rather large numbers, so he had to invent his own system of numerals. His starting point was a Greek system with which he was familiar, similar to the Roman one but with a highest-valued symbol Μ for 10,000 (one myriad). The range of the system had already been ex - tended with the rule that digits written above an Μ would be multiplied by a myriad. For instance, the symbol for twenty was κ and the symbol for four was δ, so they could write twenty-four myriad (240,000) as Μκδ. If only they had allowed that rule to generate multi-tier numerals, so κδ that MΜ would mean twenty-four myriad myriad, the system would have been universal. But apparently they never did. Even more surprisingly, nor did Archimedes. His system used a different idea, similar to modern ‘scientific notation’ (in which, say, two million is written 2 × 106), except that instead of powers of ten it used powers of a myriad myriad. But, again, he then required the exponent (the power to which the myriad myriad was raised) to be an existing Greek numeral – that is to say, it could not easily exceed a myriad myriad or so. Hence this construction petered out after the number that we call 10800,000,000. If only he had not imposed that additional rule, he would have had a universal system, albeit an unnecessarily awkward one. Even today, only mathematicians ever need numbers above 10800,000,000, and only rarely at that. But that cannot be why Archimedes imposed the restriction, for he did not stop there. Exploring the concept of numbers further, he set up yet another extension, this time amounting to an even more unwieldy system with base 10800,000,000. Yet, once again, he allowed this number to be raised only to powers not exceeding 800,000,000, thus imposing an arbitrary limit somewhere in excess of 106.4 × 1017. Why? Today it seems very perverse of Archimedes to have placed limits on which symbols could be used at which positions in his numerals. There is no mathematical justification for them. But, if Archimedes had been willing to allow his rules to be applied without arbitrary limits, he could have invented a much better universal system just by removing the arbitrary limits from the existing Greek system. A few years later the mathematician Apollonius invented yet another 132 The Jump to Universality system of numerals which fell short of universality for the same reason. It is as though everyone in the ancient world was avoiding universality on purpose.
================================================================================of an open society. The end of pessimism is potentially a beginning of infinity. Yet I also guess that in every case – with the single, tremendous exception (so far) of our own Enlightenment – this process was soon brought to an end and the reign of pessimism was restored. The best-known mini-enlightenment was the intellectual and political tradition of criticism in ancient Greece which culminated in the so- called ‘Golden Age’ of the city-state of Athens in the fifth century bce. Athens was one of the first democracies, and was home to an astonish- ing number of people who are regarded to this day as major figures in the history of ideas, such as the philosophers Socrates, Plato and Aristotle, the playwrights Aeschylus, Aristophanes, Euripides and Sophocles, and the historians Herodotus, Thucydides and Xenophon. The Athenian philosophical tradition continued a tradition of criticism dating back to Thales of Miletus over a century earlier and which had included Xenophanes of Colophon (570–480 bce), one of the first to 216 Optimism question anthropocentric theories of the gods. Athens grew wealthy through trade, attracted creative people from all over the known world, became one of the foremost military powers of the age, and built a structure, the Parthenon, which is to this day regarded as one of the great architectural achievements of all time. At the height of the Golden Age, the Athenian leader Pericles tried to explain what made Athens successful. Though he no doubt believed that the city’s patron goddess, Athena, was on their side, he evidently did not consider ‘the goddess did it’ to be a sufficient explanation for the Athenians’ success. Instead, he listed specific attributes of Athenian civilization. We do not know exactly how much of what he described was flattery or wishful thinking, but, in assessing the optimism of a civilization, what that civilization aspired to be must be even more important than what it had yet succeeded in becoming. The first attribute that Pericles cited was Athens’ democracy. And he explained why. Not because ‘the people should rule’, but because it promotes ‘wise action’. It involves continual discussion, which is a necessary condition for discovering the right answer, which is in turn a necessary condition for progress: Instead of looking upon discussion as a stumbling-block in the way of action, we think it an indispensable preliminary to any wise action at all. Pericles, ‘Funeral Oration’, c. 431 bce He also mentioned freedom as a cause of success. A pessimistic civil- ization considers it immoral to behave in ways that have not been tried many times before, because it is blind to the possibility that the benefits of doing so might offset the risks. So it is intolerant and conformist. But Athens took the opposite view. Pericles also contrasted his city’s openness to foreign visitors with the closed, defensive attitude of rival cities: again, he expected that Athens would benefit from contact with new, unforeseeable ideas, even though, as he acknowledged, this policy gave enemy spies access to the city too. He even seems to have regarded the lenient treatment of children as a source of military strength: In education, where our rivals from their very cradles by a painful discipline seek after manliness, in Athens we live exactly as we please, and yet are just as ready to encounter every legitimate danger. 217 the beginning of infinity A pessimistic civilization prides itself on its children’s conformity to the proper patterns of behaviour, and bemoans every real or imagined novelty. Sparta was, in all the above respects, the opposite of Athens. The epitome of a pessimistic civilization, it was notorious for its citizens’ austere ‘spartan’ lifestyle, for the harshness of its educational system, and for the total militarization of its society. Every male citizen was a full-time soldier, owing absolute obedience to his superiors, who were themselves obliged to follow religious tradition. All other work was done by slaves: Sparta had reduced an entire neighbouring society, the Messenians, to the status of helots (a kind of serf or slave). It had no philosophers, historians, artists, architects, writers – or other knowledge-creating people of any kind apart from the occasional talented general. Thus almost the entire effort of the society was devoted to preserving itself in its existing state – in other words, to preventing improvement. In 404 bce, twenty-seven years after Pericles’ funeral oration, Sparta decisively defeated Athens in war and imposed an authoritarian form of government on it. Although, through the vagaries of international politics, Athens became independent and democratic again soon afterwards, and continued for several gener- ations to produce art, literature and philosophy, it was never again host to rapid, open-ended progress. It became unexceptional. Why? I guess that its optimism was gone. Another short-lived enlightenment happened in the Italian city-state of Florence in the fourteenth century. This was the time of the early Renaissance, a cultural movement that revived the literature, art and science of ancient Greece and Rome after more than a millennium of intellectual stagnation in Europe. It became an enlightenment when the Florentines began to believe that they could improve upon that ancient knowledge. This era of dazzling innovation, known as the Golden Age of Florence, was deliberately fostered by the Medici family, who were in effect the city’s rulers – especially Lorenzo de’ Medici, known as ‘the Magnificent’, who was in charge from 1469 to 1492. Unlike Pericles, the Medici were not devotees of democracy: Florence’s enlightenment began not in politics but in art, and then philosophy, science and technology, and in those fields it involved the same openness to criticism and desire for innovation both in ideas and in action. 218 Optimism Artists, instead of being restricted to traditional themes and styles, became free to depict what they considered beautiful, and to invent new styles. Encouraged by the Medici, the wealthy of Florence competed with each other in the innovativeness of the artists and scholars whom they sponsored – such as Leonardo da Vinci, Michelangelo and Botticelli.
================================================================================perverse. For instance, it was susceptible to what came to be called the population paradox: a state whose population has increased since the last census can lose a seat to one whose population has decreased. So, ‘why didn’t they just’ create new seats and assign them to states that lose out under a population paradox? They did so. But unfortunately that can bring the allocation outside quota. It can also introduce another historically important apportionment paradox: the Alabama 330 Choices paradox. That happens when increasing the total number of seats in the House results in some state losing a seat. And there were other paradoxes. These were not necessarily unfair in the sense of being biased or disproportionate. They are called ‘paradoxes’ because an apparently reasonable rule makes apparently unreasonable changes between one apportionment and the next. Such changes are effectively random, being due to the vagaries of round ing errors, not to any bias, and in the long run they cancel out. But impartiality in the long run does not achieve the intended purpose of representative government. Perfect ‘fairness in the long run’ could be achieved even without elections, by selecting the legislature randomly from the electorate as a whole. But, just as a coin tossed randomly one hundred times is unlikely to produce exactly fifty heads and fifty tails, so a randomly chosen legislature of 435 would in practice never be representative on any one occasion: statistically, the typical deviation from representativeness would be about eight seats. There would also be large fluctuations in how those seats were distributed among states. The apportionment paradoxes that I have described have similar effects. The number of seats involved is usually small, but that does not make it unimportant. Politicians worry about this because votes in the House of Representatives are often very close. Bills quite often pass or fail by one vote, and political deals often depend on whether individual representatives join one faction or another. So, whenever apportion- ment paradoxes have caused political discord, people have tried to invent an apportionment rule that is mathematically incapable of causing that particular paradox. Particular paradoxes always make it look as though everything would be fine if only ‘they’ made some simple change or other. Yet the paradoxes as a whole have the infuriat- ing property that, no matter how firmly they are kicked out of the front door, they instantly come in again at the back. After Hamilton’s rule was adopted, in 1851, Webster’s still enjoyed substantial support. So Congress tried, on at least two occasions, a trick that seemed to provide a judicious compromise: adjust the number of seats in the House until the two rules agree. Surely that would please everyone! Yet the upshot was that in 1871 some states considered the result to be so unfair, and the ensuing compromise legislation was so 331 the beginning of infinity chaotic, that it was unclear what allocation rule, if any, had been decided upon. The apportionment that was implemented – which in - cluded the last-minute creation of several additional seats for no apparent reason – satisfied neither Hamilton’s rule nor Webster’s. Many considered it unconstitutional. For the next few decades after 1871, every census saw either the adoption of a new apportionment rule or a change in the number of seats, designed to compromise between different rules. In 1921 no apportionment was made at all: they kept the old one (a course of action that may well have been unconstitutional again), because Congress could not agree on a rule. The apportionment issue has been referred several times to eminent mathematicians, including twice to the National Academy of Sciences, and on each occasion these authorities have made different recom- mendations. Yet none of them ever accused their predecessors of making errors in mathematics. This ought to have warned everyone that this problem is not really about mathematics. And on each occasion, when the experts’ recommendations were implemented, paradoxes and dis - putes kept on happening. In 1901 the Census Bureau published a table showing what the apportionments would be for every number of seats between 350 and 400 using Hamilton’s rule. By a quirk of arithmetic of a kind that is common in apportionment, Colorado would get three seats for each of these numbers except 357, when it would get only two seats. The chairman of the House Committee on Apportionment (who was from Illinois: I do not know whether he had anything against Colorado) proposed that the number of seats be changed to 357 and that Hamilton’s rule be used. This proposal was regarded with suspicion, and Congress eventually rejected it, adopting a 386-member apportion- ment and Webster’s rule, which also gave Colorado its ‘rightful’ three seats. But was that apportionment really any more rightful than Hamilton’s rule with 357 seats? By what criterion? Majority voting among apportionment rules? What exactly would be wrong with working out what a large number of rival apportionment rules would do, and then allocating to each state the number of representatives that the majority of the schemes would allocate? The main thing is that that is itself an apportionment 332 Choices rule. Similarly, combining Hamilton’s and Webster’s schemes as they tried to do in 1871 just constituted adopting a third scheme. And what does such a scheme have going for it? Each of its constituent schemes was presumably designed to have some desirable properties. A com - bined scheme that was not designed to have those properties will not have them, except by coincidence. So it will not necessarily inherit the good features of its constituents. It will inherit some good ones and some bad ones, and have additional good and bad features of its own – but if it was not designed to be good, why should it be? A devil’s advocate might now ask: if majority voting among ap - portionment rules is such a bad idea, why is majority voting among voters a good idea? It would be disastrous to
================================================================================precautionary principle. Because pessimism needs to counter that argument in order to be at all persuasive, a recurring theme in pessimistic theories throughout history has been that an exceptionally dangerous moment is imminent. Our Final Century makes the case that the period since the mid twentieth century has been the first in which technology has been capable of destroying civilization. But that is not so. Many civilizations in history were destroyed by the simple technologies of fire and the sword. Indeed, of all civilizations in history, the overwhelming major- ity have been destroyed, some intentionally, some as a result of plague or natural disaster. Virtually all of them could have avoided the catastro phes that destroyed them if only they had possessed a little additional knowledge, such as improved agricultural or military technology, better hygiene, or better political or economic institutions. Very few, if any, could have been saved by greater caution about innovation. In fact most had enthusiastically implemented the pre - cautionary principle. More generally, what they lacked was a certain combination of abstract knowledge and knowledge embodied in technological arte- facts, namely sufficient wealth. Let me define that in a non-parochial way as the repertoire of physical transformations that they would be capable of causing. An example of a blindly pessimistic policy is that of trying to make our planet as unobtrusive as possible in the galaxy, for fear of contact with extraterrestrial civilizations. Stephen Hawking recently advised this, in his television series Into the Universe. He argued, ‘If [extra- terrestrials] ever visit us, I think the outcome would be much as when Christopher Columbus first landed in America, which didn’t turn out very well for the Native Americans.’ He warned that there might be nomadic, space-dwelling civilizations who would strip the Earth of its resources, or imperialist civilizations who would colonize it. The science-fiction author Greg Bear has written some exciting novels based 202 Optimism on the premise that the galaxy is full of civilizations that are either predators or prey, and in both cases are hiding. This would solve the mystery of Fermi’s problem. But it is implausible as a serious explan- ation. For one thing, it depends on civilizations becoming convinced of the existence of predator civilizations in space, and totally re - organizing themselves in order to hide from them, before being noticed – which means before they have even invented, say, radio. Hawking’s proposal also overlooks various dangers of not making our existence known to the galaxy, such as being inadvertently wiped out if benign civilizations send robots to our solar system, perhaps to mine what they consider an uninhabited system. And it rests on other misconceptions in addition to that classic flaw of blind pessimism. One is the Spaceship Earth idea on a larger scale: the assumption that progress in a hypothetical rapacious civilization is limited by raw materials rather than by knowledge. What exactly would it come to steal? Gold? Oil? Perhaps our planet’s water? Surely not, since any civilization capable of transporting itself here, or raw materials back across galactic distances, must already have cheap transmutation and hence does not care about the chemical composition of its raw materials. So essentially the only resource of use to it in our solar system would be the sheer mass of matter in the sun. But matter is available in every star. Perhaps it is collecting entire stars wholesale in order to make a giant black hole as part of some titanic engineering project. But in that case it would cost it virtually nothing to omit inhabited solar systems (which are presumably a small minority, otherwise it is pointless for us to hide in any case); so would it casually wipe out billions of people? Would we seem like insects to it? This can seem plausible only if one forgets that there can be only one type of person: universal explainers and constructors. The idea that there could be beings that are to us as we are to animals is a belief in the supernatural. Moreover, there is only one way of making progress: conjecture and criticism. And the only moral values that permit sustained progress are the objective values that the Enlightenment has begun to discover. No doubt the extraterrestrials’ morality is different from ours; but that will not be because it resembles that of the conquistadors. Nor would we be in serious danger of culture shock from contact with an advanced civilization: it will know how to educate its own children (or AIs), so 203 the beginning of infinity it will know how to educate us – and, in particular, to teach us how to use its computers. A further misconception is Hawking’s analogy between our civil- ization and pre-Enlightenment civilizations: as I shall explain in Chapter 15, there is a qualitative difference between those two types of civilization. Culture shock need not be dangerous to a post- Enlightenment one. As we look back on the failed civilizations of the past, we can see that they were so poor, their technology was so feeble, and their explanations of the world so fragmentary and full of misconceptions that their caution about innovation and progress was as perverse as expecting a blindfold to be useful when navigating dangerous waters. Pessimists believe that the present state of our own civilization is an exception to that pattern. But what does the precautionary principle say about that claim? Can we be sure that our present knowledge, too, is not riddled with dangerous gaps and misconceptions? That our present wealth is not pathetically inadequate to deal with unforeseen problems? Since we cannot be sure, would not the precautionary principle require us to confine ourselves to the policy that would always have been salutary in the past – namely innovation and, in emergencies, even blind optimism about the benefits of new knowledge? Also, in the case of our civilization, the precautionary principle rules itself out. Since our civilization has not been following it, a transition to it
================================================================================setting a story there, perhaps what I lose in terms of the familiar ingredients of drama I shall gain in terms of opportunity to explain something that is more astounding than any fiction, yet is the purest and most basic fact we know about the physical world. I had better warn the reader that the account that I shall give – 262 The Multiverse known as the ‘many-universes interpretation’ of quantum theory (rather inadequately, since there is much more to it than ‘universes’) – remains at the time of writing a decidedly minority view among physicists. In the next chapter I shall speculate why that is so despite the fact that many well-studied phenomena have no other known explanation. For the moment, suffice it to say that the very idea of science as explanation, in the sense that I am advocating in this book (namely an account of what is really out there), is itself still a minority view even among theoretical physicists. Let me begin with perhaps the simplest possible ‘parallel-universe’ speculation: a ‘phantom zone’ has existed all along (ever since its own Big Bang). Until our story begins, it has been an exact doppelgänger of the entire universe, atom for atom and event for event. All the flaws that I mentioned in the phantom-zone stories derive from the asymmetry that things in the ordinary world affect things in the phantom zone but not vice versa. So let me eliminate those flaws by imagining, for the moment, that the universes are completely im - perceptible to each other. Since we are heading towards real physics, let me also retain the speed-of-light limit on communication, and let the laws of physics be universal and symmetrical (i.e. they make no distinction between the universes). Moreover, they are deterministic: nothing random ever happens, which is why the universes have remained alike – so far. So how can they ever become different? That is a key question in the theory of the multiverse, which I shall answer below. All these basic properties of my fictional world can be thought of as conditions on the flow of information: one cannot send a message to the other universe; nor can one change anything in one’s own universe sooner than light could reach that thing. Nor can one bring new information – even random information – into the world: everything that happens is determined by laws of physics from what has gone before. However, one can, of course, bring new knowledge into the world. Knowledge consists of explanations, and none of those conditions prevents the creation of new explanations. All this is true of the real world too. We can temporarily think of the two universes as being literally parallel. Suppress the third dimension of space and think of a universe 263 the beginning of infinity as being two-dimensional, like an infinitely flat television. Then place a second such television parallel to it, showing exactly the same pictures (symbolizing the objects in the two universes). Now forget the material of which the televisions are made. Only the pictures exist. This is to stress that a universe is not a receptacle containing physical objects: it is those objects. In real physics, even space is a physical object, capable of warping and affecting matter and being affected by it. So now we have two perfectly parallel, identical universes, each including an instance of our starship, its crew and its transporter, and of the whole of space. Because of the symmetry between them, it is now misleading to call one of them ‘the ordinary universe’ and the other ‘the phantom zone’. So I shall just call them ‘universes’. The two of them together (which comprise the whole of physical reality in the story so far) are the multiverse. Similarly, it is misleading to speak of the ‘original’ object and its ‘doppelgänger’: they are simply the two instances of the object. If our science-fiction speculation were to stop there, the two universes would have to remain identical for ever. There is nothing logically impossible about that. Yet it would make our story fatally flawed both as fiction and as scientific speculation – and for the same reason: it is a story of two universes, but only one history. That is to say, there is only one script about what is really there in both universes. Considered as fiction, therefore, it is really a single-universe story in a pointless disguise. Considered as scientific speculation, it describes a world that would not be explicable to its inhabitants. For how could they ever argue that their history takes place in two universes and not three or thirty? Why not two today and thirty tomorrow? Moreover, since their world has only one history, all their good explanations about nature would be about that history. That single history would be what they meant by their ‘world’ or ‘universe’. Nothing of the underlying two-ness of their reality would be accessible to them, nor would it make any more sense to them as an explanation than would three-ness or thirty- ness – yet they would be factually mistaken. A remark about explanation: Although the story so far would be a bad explanation from the inhabitants’ point of view, it is not necessarily bad from ours. Imagining inexplicable worlds can help us to understand the nature of explicability. I have already imagined some inexplicable 264 The Multiverse worlds for that very reason in previous chapters, and I shall imagine more in this chapter. But, in the end, I want to tell of an explicable world, and it will be ours. A remark about terminology: The world is the whole of physical reality. In classical (pre-quantum) physics, the world was thought to consist of one universe – something like a whole three-dimensional space for the whole of time, and all its contents. According to quantum physics, as I shall explain, the world is a much larger and more com - plicated object, a multiverse, which includes many such universes
================================================================================me, wise Apollo, by asking me the same question that we asked you today? It seems to me that your joke is wearing thin. hermes: Have you, Socrates, never mocked anyone? socrates: [with dignity] If, on occasion, I make fun of someone, it is because I hope he will help me to seek a truth that neither he nor I yet knows. I do not mock from on high, as you do. I want only to goad my fellow mortal into helping me look beyond that which is easy to see. hermes: But what in the world is easy to see? What things are the easiest to see, Socrates? 225 the beginning of infinity socrates: [Shrugs.] Those that are before our eyes. hermes: And what is before your eyes at this moment? socrates: You are. hermes: Are you sure? socrates: Are you going to start asking me how I can be sure of whatever I say? And then, whatever reason I give, are you going to ask how I can be sure of that? hermes: No. Do you think I have come here to play hackneyed debating tricks? socrates: Very well: obviously I can’t be sure of anything. But I don’t want to be. I can think of nothing more boring – no offence meant, wise Apollo – than to attain the state of being perfectly secure in one’s beliefs, which some people seem to yearn for. I see no use for it – other than to provide a semblance of an argument when one doesn’t have a real one. Fortunately that mental state has nothing to do with what I do yearn for, which is to discover the truth of how the world is, and why – and, even more, of how it should be. hermes: Congratulations, Socrates, on your epistemological wisdom. The knowledge that you seek – objective knowledge – is hard to come by, but attainable. That mental state that you do not seek – justified belief – is sought by many people, especially priests and philosophers. But, in truth, beliefs cannot be justified, except in relation to other beliefs, and even then only fallibly. So the quest for their justification can lead only to an infinite regress – each step of which would itself be subject to error. socrates: Again, I know this. hermes: Indeed. And, as you have rightly remarked, it doesn’t count as a ‘revelation’ if I tell you what you already know. Yet – notice that that remark is precisely what people who seek justified belief do not agree with. socrates: What? I’m sorry, but that was too convoluted a comment for my allegedly wise mind to comprehend. Please explain what I am to notice about those people who seek ‘justified belief’. hermes: Merely this. Suppose they just happen to be aware of the explanation of something. You and I would say that they know it. But to them, no matter how good an explanation it is, and no matter how true and important and useful it may be, they still do not 226 A Dream of Socrates consider it to be knowledge. It is only if a god then comes along and reassures them that it is true (or if they imagine such a god or other authority) that they count it as knowledge. So, to them it does count as a revelation if the authority tells them what they are already fully aware of. socrates: I see that. And I see that they are foolish, because, for all they know, the ‘authority’ [gestures at hermes] may be toying with them. Or trying to teach them some important lesson. Or they may be misunderstanding the authority. Or they may be mistaken in their belief that it is an authority – hermes: Yes. So the thing they call ‘knowledge’, namely justified belief, is a chimera. It is unattainable to humans except in the form of self- deception; it is unnecessary for any good purpose; and it is undesired by the wisest among mortals. socrates: I know. hermes: Xenophanes knew it too; but he is no longer among the mortals – socrates: Is that what you meant when you told the Oracle that no one is wiser than I? hermes: [Ignores the question.] Hence, also, I wasn’t referring to justified belief when I asked whether you are sure that I am before your eyes. I was only questioning how you can claim to be ‘seeing clearly’ what is before your eyes when you also claim to be asleep! socrates: Oh! Yes, you have caught me in an error – but surely only a trivial one. Indeed, you may not be literally before my eyes. Perhaps you are at home on Olympus, sending me a mere likeness of yourself. But in that case you are controlling that likeness and I am seeing it, and referring to it as ‘you’, so I am seeing ‘you’. hermes: But that is not what I asked. I asked what is here before your eyes. In reality. socrates: All right. Before my eyes, in reality, there is – a small room. Or, if you want a literal reply, what is before my eyes is – eyelids, since I expect that they are shut. Yet I see from your expression that you want even more precision. Very well: before my eyes are the inside surfaces of my eyelids. hermes: And can you see those? In other words, is it really ‘easy to see’ what is before your eyes? 227 the beginning of infinity socrates: Not at the moment. But that is only because I am dream- ing. hermes: Is it only because you are dreaming? Are you saying that if you were awake you would now be seeing the inside surfaces of your eyelids? socrates: [carefully] If I were awake with my eyes still closed, then yes. hermes: What colour do you see when you close your eyes? socrates: In a room as dimly lit as this one – black. hermes:
================================================================================such thing. Only progress is sustainable. The prophetic approach can see only what one might do to postpone disaster, namely improve sustainability: drastically reduce and disperse the population, make travel difficult, suppress contact between different geographical areas. A society which did this would not be able to afford the kind of scientific research that would lead to new antibiotics. Its 436 Unsustainable members would hope that their lifestyle would protect them instead. But note that this lifestyle did not, when it was tried, prevent the Black Death. Nor would it cure cancer. Prevention and delaying tactics are useful, but they can be no more than a minor part of a viable strategy for the future. Problems are inevitable, and sooner or later survival will depend on being able to cope when prevention and delaying tactics have failed. Obviously we need to work towards cures. But we can do that only for diseases that we already know about. So we need the capacity to deal with unfore- seen, unforeseeable failures. For this we need a large and vibrant research community, interested in explanation and problem-solving. We need the wealth to fund it, and the technological capacity to implement what it discovers. This is also true of the problem of climate change, about which there is currently great controversy. We face the prospect that carbon-dioxide emissions from technology will cause an increase in the average temp- erature of the atmosphere, with harmful effects such as droughts, sea-level rises, disruption to agriculture, and the extinctions of some species. These are forecast to outweigh the beneficial effects, such as an increase in crop yields, a general boost to plant life, and a reduction in the number of people dying of hypothermia in winter. Trillions of dollars, and a great deal of legislation and institutional change, in - tended to reduce those emissions, currently hang on the outcomes of simulations of the planet’s climate by the most powerful supercomputers, and on projections by economists about what those computations imply about the economy in the next century. In the light of the above discussion, we should notice several things about the controversy and about the underlying problem. First, we have been lucky so far. Regardless of how accurate the prevailing climate models are, it is uncontroversial from the laws of physics, without any need for supercomputers or sophisticated model- ling, that such emissions must, eventually, increase the temperature, which must, eventually, be harmful. Consider, therefore: what if the relevant parameters had been just slightly different and the moment of disaster had been in, say, 1902 – Veblen’s time – when carbon- dioxide emissions were already orders of magnitude above their pre-Enlightenment values. Then the disaster would have happened 437 the beginning of infinity before anyone could have predicted it or known what was happening. Sea levels would have risen, agriculture would have been disrupted, millions would have begun to die, with worse to come. And the great issue of the day would have been not how to prevent it but what could be done about it. They had no supercomputers then. Because of Babbage’s failures and the scientific community’s misjudgements – and, perhaps most importantly, their lack of wealth – they lacked the vital technology of automated computing altogether. Mechanical calculators and roomfuls of clerks would have been insufficient. But, much worse: they had almost no atmospheric physicists. In fact the total number of physicists of all kinds was a small fraction of the number who today work on climate change alone. From society’s point of view, physicists were a luxury in 1902, like colour televisions were in the 1970s. Yet, to recover from the disaster, society would have needed more scientific knowledge, and better technology, and more of it – that is to say, more wealth. For instance, in 1900, building a sea wall to protect the coast of a low-lying island would have required resources so enormous that the only islands that could have afforded it would have been those with either large concentrations of cheap labour or exceptional wealth, as in the Nether- lands, much of whose population already lived below sea level thanks to the technology of dyke-building. This is a challenge that is highly susceptible to automation. But people were in no position to address it in that way. All relevant machines were underpowered, unreliable, expensive, and impossible to produce in large numbers. An enormous effort to construct a Panama canal had just failed with the loss of thousands of lives and vast amounts of money, due to inadequate technology and scientific know ledge. And, to compound those problems, the world as a whole had very little wealth by today’s standards. Today, a coastal defence project would be well within the capabilities of almost any coastal nation – and would add decades to the time available to find other solutions to rising sea levels. If none are found, what would we do then? That is a question of a wholly different kind, which brings me to my second observation on the climate-change controversy. It is that, while the supercomputer simulations make (conditional) predictions, the economic forecasts make almost pure prophecies. For we can expect the future of human 438 Unsustainable responses to climate to depend heavily on how successful people are at creating new knowledge to address the problems that arise. So comparing predictions with prophecies is going to lead to that same old mistake. Again, suppose that disaster had already been under way in 1902. Consider what it would have taken for scientists to forecast, say, carbon-dioxide emissions for the twentieth century. On the (shaky) assumption that energy use would continue to increase by roughly the same ex ponential factor as before, they could have estimated the resulting increase in emissions. But that estimate would not have included the effects of nuclear power. It could not have, because radioactivity itself had only just been discovered, and would not be harnessed for power until the middle of the century. But suppose
================================================================================magic 16, 19–21, 53–4, 81, 82, 173, 413 242, 301 generations of 376, 379 476 index and genes 372–97, 404, 405, 407, multiple universes 3, 198, 254, 258–303, 408, 413, 414 303–4, 305–6 living with 394–6 and the Bohm theory 310 long-lived 222, 370, 377, 380, 382–3, close to common sense 266, 299 384, 387, 388, 394, 399 fictional variations on the memeplexes 93, 105, 374, 384 doppelganger idea 258–62, 270 mutual enhancement of creativity and first proposed by Schrödinger 310 meme transmission 400 Everett 310 in pre-humans and early humans 50, inter-universe communication 258, 55, 72, 207, 399, 412–13, 414 262, 270–72, 276 puzzle of how they can possibly be Lyra multiverse thought experiment replicated 402–10 179–80, 181 rational 388–90, 392, 393, 396, 397 account of the theory 262–92 ‘selfish’ 378–9, 387 ‘parallel’ universes 98, 98n, 198, 258, slavery to 130, 383, 384, 392 261–270, 291, 293, 303, 452 Messenians 218 multiverse 3, 98n, 180, 194, 258–304, Michelangelo 219 305, 307, 452n, 460, 461 Michelson, Albert 198–9, 445–6 other than those of the quantum micro-organisms 82, 196, 425, 436 multiverse 98–106, 98n, 177–183, bacteria 82, 145, 162, 436 195, 450–52, 452n microprocessors see computers/ probability, prediction and 99–103, computation 177–80, 195, 276–8 microscopes 34, 37, 38, 39, 220, 312, and the quantum suicide argument 453 324, 355 see also histories microwave background radiation 46, music 93, 136, 353, 354, 355–6, 357, 47, 68 365–6, 369 Milky Way 1, 2, 47, 70–71, 101, 202–3 banning of 219 Mills, Roger Q. 333, 334 notation 142 mind–body problem 117–22, 130 mutations 78, 79, 89, 90, 96, 156, 162, minds, animal 320–21 375, 399 see also memes, in animals simulated 162 mirages 228, 229, 231 myths 12, 15, 19–21, 22, 24, 25, 26, 30, mirror neurons 405–6, 408, 414 32, 54, 60, 228, 314 mirrors, semi-silvered 286–7 of a Golden Age 52, 63 momentum 55, 273–4, 297 moon 24, 55, 57–8, 61–3, 66, 67, 68, Nagel, Thomas 367 74, 143, 215, 366, 373 nanotechnology 144, 196 morality see moral philosophy narratives 314 moral philosophy vii, 51, 64, 120–2, natural numbers 118, 123, 165, 167, 123, 211, 235, 240, 254, 371, 388, 169–70, 171, 172, 176, 177, 184, 405, 428, 441, 455, 459 194, 195 and ‘a dream of Socrates’ 229–32, natural selection 52, 56, 58, 78, 87, 89, 234–5 91–2, 160, 210, 372 moral education 230–31 see also sexual selection moral imperative 235 nature, laws of vii, 5, 7, 18, 43, 56, 59, moral knowledge 63, 229–31, 240, 254 66, 69, 75, 76, 94, 103, 106, 111, more-preferred-less-seats paradox 339 113, 164, 175, 179, 188, 205, 220, Morley, Edward 199 358, 411, 413, 444, 445 motion, quantum-mechanical see Bohr’s 308 quantum theory constants 62, 97–104, 106, 179, 199, Mozart, Wolfgang Amadeus 353, 354, 294, 452–3; see also fine-tuning of 356 the universe/laws of physics 477 index nature, laws of vii (cont.) and empiricism 4–29, 39, 403 Lamarck’s 88 and explanation 26 no barrier to progress 212, 413, 423, and moving closer to reality 34–41 445 and quantum theory 308 regularities in 16, 56–7, 69, 94, 98, role in providing problems 17 111, 183, 355, 361, 411 role in science 4, 32; see also see also physics: laws of experimental testing Nazism 205, 371 theory-free 39 Neanderthals 49, 206 theory-laden 10, 30, 38–41, 165, 199 necessary truths 183 Occam, William of (razor) 25 nectar 360, 361 old age 213, 415 neo-Darwinism 79, 89–92, 95, 103, problem of ageing 213–14 104–5, 374, 446 omega-point universes 450–51 and knowledge 93–6 open society 216, 460 nerves see neurons see also societies, dynamic nesting birds 89–91 optics 7, 39, 54 neurons 10, 80, 114, 138, 269, 405 see also telescopes; microscopes, eyes mirror neurons 405–6, 408, 414 optimism 4, 196–222, 344, 423, 434, neutrinos 2, 52 435, 445 neutron stars 97, 38, 113, 290 blind 201, 221; and blind pessimism neutrons 97 201–4, 208, 210, 216 Newton, Isaac 55, 61, 164, 181, 198–9, duty of 196, 215history of 216, 444, 446, 447 220–21 explanation of planetary motion 112, about knowledge 204, 212–15, 424, 113 447 survival of his laws 388, 390 original use of the term (Leibniz) and time 312 199–200 translation of his laws into English 373 of a society 208–22, 390, 424, 431 nirvana 65 principle of 212–13, 319, 389 no-go theorems 334, 335–6, 339 orbits 23, 28, 44, 73, 112, 113, 290–91 Arrow’s theorem 336–8, 340–41, original sources of theories 255–6 343, 345, 351 oxygen 57, 61 regret over 343 versus creating new options 351 Page, Don 299 nuclear fusion 61, 67 pain 10, 11, 217, 320, 381 nuclear power 1, 44, 66, 67, 198, 439 painting 219, 355, 356, 357, 367, 392 nuclear weapons 2, 6, 139, 196, 205 palaeontology 49, 315–16, 383, 400 nucleus 39, 258, 290 Paley, William 84–7, 91, 92, 96–9, 106, numbers 363 natural see natural numbers see also design, appearance of odd and even 108, 169–70, 176 Palomar Sky Survey 34, 37–8 prime see prime numbers pandemics/epidemics 196, 208, 418, random 161, 162, 197, 269, 283, 436 331, 454 see also Black Death real 170–71 see also continuum parallel universes see multiple universes numerals 128–33 the paranormal 324 a television psychic’s predictions 279 obedience 123, 130, 218, 345, 359, 382, see also magic; the supernatural 391–2, 402 parochialism 29, 39, 44, 46, 55, 66, 67, objective beauty 122, 353–68 70, 76–7, 81, 98, 101, 118, 124, objective knowledge see knowledge, 206, 207, 213, 231–2, 279–80, 428, objective 436, 443 478 index finitism 164, 165–6 perfection 66, 80, 102, 119, 142, 189, the future and the shedding of 444–5, 199, 232, 238, 248, 333, 343–4 459 perfectibility 65, 366, 445 of the Principle of Mediocrity 51–4 perfectly identical see fungible in quantum theory 310 Pericles 217–8 leading to more general concerns 11, Persephone myth 19–21, 22, 24, 25, 56, 69, 108, 114, 127–8, 133–6, 60 140, 146, 199, 299–300, 303, perspiration phase of research see 336–7, 354, 361, 364–6, 387–8, inspiration/perspiration 418, 427–8 pessimism 166–7, 217–18, 316, 350, seen as
================================================================================how to look, and how to interpret what one sees. And he would explain that, therefore, theory has to come first. It has to be conjectured, not derived. Popper could have made the same point by asking his audience to imitate, rather than merely to observe. The logic would have been the same: under what explanatory theory should they ‘imitate’? Whom 403 the beginning of infinity should they imitate? Popper? In that case, should they walk to the podium, push him out of the way, and stand where he had been standing? If not, should they at least turn to face the rear of the room, to imitate where he was facing? Should they imitate his heavy Austrian accent, or should they speak in their normal voices, because he was speaking in his normal voice? Or should they do nothing special at the time, but merely include such demonstrations in their lectures when they themselves became professors of philosophy? There are infinitely many possible interpretations of ‘imitate Popper’, each defining a different behaviour for the imitator. Many of those ways would look very different from each other. Each way corresponds to a different theory of what ideas, in Popper’s mind, were causing the observed behaviour. So there is no such thing as ‘just imitating the behaviour’ – still less, therefore, can one discover those ideas by imitating it. One needs to know the ideas before one can imitate the behaviour. So imitating behaviour cannot be how we acquire memes. The hypothetical genes that caused meme replication by imitation would also have to specify whom to imitate. Blackmore, for instance, suggests that the criterion may be ‘imitate the best imitators’. But this is impossible for the same reason. One can only judge how well someone is imitating if one already knows, or has guessed, what (which aspect of behaviour, and whose) they are imitating, and which of the circumstances they are taking into account and how. The same holds if the behaviour consists of stating the memes. As Popper remarked, ‘It is impossible to speak in such a way that you cannot be misunderstood.’ One can only state the explicit content, which is insufficient to define the meaning of a meme or anything else. Even the most explicit of memes – such as laws – have inexplicit content without which they cannot be enacted. For example, many laws refer to what is ‘reasonable’. But no one can define that attribute accurately enough for, say, a person from a different culture to be able to apply the definition in judging a criminal case. Hence we certainly do not learn what ‘reasonable’ means by hearing its meaning stated. But we do learn it, and the versions of it that are learned by people in the same culture are sufficiently close for laws based on it to be practicable. In any case, as I remarked in the previous chapter, we do not explicitly 404 The Evolution of Creativity know the rules by which we behave. We know the rules, meanings and patterns of speech of our native language largely inexplicitly, yet we pass its rules on with remarkable fidelity to the next generation – including the ability to apply them in situations the new holder has never experienced, and including patterns of speech that people ex - plicitly try to prevent the next generation from replicating. The real situation is that people need inexplicit knowledge to under- stand laws and other explicit statements, not vice versa. Philosophers and psychologists work hard to discover, and to make explicit, the assumptions that our culture tacitly makes about social institutions, human nature, right and wrong, time and space, intention, causality, freedom, necessity and so on. But we do not acquire those assump- tions by reading the results of such research: it is entirely the other way round. If behaviour is impossible to imitate without prior knowledge of the theory causing the behaviour, how it is that apes, famously, can ape? They have memes: they can learn a new way of opening a nut by watching another ape that already knows that way. How is it that apes are not confused by the infinite ambiguity of what it means to imitate? Even parrots, famously, parrot: they can commit to memory dozens of sounds that they have heard, and repeat them later. How do they cope with the ambiguity of which sounds to imitate, and when to repeat them? They cope with it by knowing the relevant inexplicit theories in advance. Or, rather, their genes know them. Evolution has built into the genes of parrots an implicit definition of what ‘imitating’ means: to them, it means recording sequences of sounds that meet some inborn criterion, and later replaying them under conditions that meet some other inborn criterion. An interesting fact follows, about parrot physi- ology: the parrot’s brain must also contain a translation system that analyses incoming nerve signals from the ears and generates outgoing ones that will cause the parrot’s vocal cords to play the same sounds. That translation requires some quite sophisticated computation, which is encoded in genes, not memes. It is thought to be achieved in part by a system based on ‘mirror neurons’. These are neurons that fire when an animal performs a given action, and also when the animal perceives the same action being performed by another. These neurons have been 405 the beginning of infinity identified experimentally in animals that have the capacity to imitate. Scientists who believe that human meme replication is a sophisticated form of imitation tend to believe that mirror neurons are a key to understanding all sorts of functions of the human mind. Unfortunately, that cannot possibly be so. It is not known why parroting evolved. It is a fairly common adap- tation in birds, and may play more than one role. But, whatever the reason, the important thing for present purposes is that parrots never have a choice about which sounds to imitate, or about what constitutes imitating
================================================================================originate locally, as guesswork in our own minds, and can be tested only locally, by experience, how is it that they contain such extensive and accurate knowledge about the reality that we have never experienced? *The term was coined by the philosopher Norwood Russell Hanson. 10 The Reach of Explanations I am not asking what authority scientific knowledge is derived from, or rests on. I mean, literally, by what process do ever truer and more detailed explanations about the world come to be represented physically in our brains? How do we come to know about the interactions of subatomic particles during transmutation at the centre of a distant star, when even the tiny trickle of light that reaches our instruments from the star was emitted by glowing gas at the star’s surface, a million kilometres above where the transmutation is happening? Or about conditions in the fireball during the first few seconds after the Big Bang, which would instantly have destroyed any sentient being or scientific instrument? Or about the future, which we have no way of measuring at all? How is it that we can predict, with some non-negligible degree of confidence, whether a new design of microchip will work, or whether a new drug will cure a particular disease, even though they have never existed before? For most of human history, we did not know how to do any of this. People were not designing microchips or medications or even the wheel. For thousands of generations, our ancestors looked up at the night sky and wondered what stars are – what they are made of, what makes them shine, what their relationship is with each other and with us – which was exactly the right thing to wonder about. And they were using eyes and brains anatomically indistinguishable from those of modern astronomers. But they discovered nothing about it. Much the same was true in every other field of knowledge. It was not for lack of trying, nor for lack of thinking. People observed the world. They tried to understand it – but almost entirely in vain. Occasionally they recognized simple patterns in the appearances. But when they tried to find out what was really there behind those appearances, they failed almost completely. I expect that, like today, most people wondered about such things only occasionally – during breaks from addressing their more parochial concerns. But their parochial concerns also involved yearning to know – and not only out of pure curiosity. They wished they knew how to safeguard their food supply; how they could rest when tired without risking starvation; how they could be warmer, cooler, safer, in less pain – in every aspect of their lives, they wished they knew how to make progress. But, on the timescale of individual lifetimes, they 11 the beginning of infinity almost never made any. Discoveries such as fire, clothing, stone tools, bronze, and so on, happened so rarely that from an individual’s point of view the world never improved. Sometimes people even realized (with somewhat miraculous prescience) that making progress in practical ways would depend on progress in understanding puzzling phenomena in the sky. They even conjectured links between the two, such as myths, which they found compelling enough to dominate their lives – yet which still bore no resemblance to the truth. In short, they wanted to create knowledge, in order to make progress, but they did not know how. This was the situation from our species’ earliest prehistory, through the dawn of civilization, and through its imperceptibly slow increase in sophistication – with many reverses – until a few centuries ago. Then a powerful new mode of discovery and explanation emerged, which later became known as science. Its emergence is known as the scientific revolution, because it succeeded almost immediately in creating know- ledge at a noticeable rate, which has increased ever since. What had changed? What made science effective at understanding the physical world when all previous ways had failed? What were people now doing, for the first time, that made the difference? This question began to be asked as soon as science began to be successful, and there have been many conflicting answers, some containing truth. But none, in my view, has reached the heart of the matter. To explain my own answer, I have to give a little context first. The scientific revolution was part of a wider intellectual revolution, the Enlightenment, which also brought progress in other fields, especially moral and political philosophy, and in the institutions of society. Unfortunately, the term ‘the Enlightenment’ is used by historians and philosophers to denote a variety of different trends, some of them violently opposed to each other. What I mean by it will emerge here as we go along. It is one of several aspects of ‘the beginning of infinity’, and is a theme of this book. But one thing that all conceptions of the Enlightenment agree on is that it was a rebellion, and specifically a rebellion against authority in regard to knowledge. Rejecting authority in regard to knowledge was not just a matter of abstract analysis. It was a necessary condition for progress, because, before the Enlightenment, it was generally believed that everything 12 The Reach of Explanations important that was knowable had already been discovered, and was enshrined in authoritative sources such as ancient writings and traditional assumptions. Some of those sources did contain some genuine knowledge, but it was entrenched in the form of dogmas along with many falsehoods. So the situation was that all the sources from which it was generally believed knowledge came actually knew very little, and were mistaken about most of the things that they claimed to know. And therefore progress depended on learning how to reject their authority. This is why the Royal Society (one of the earliest scientific academies, founded in London in 1660) took as its motto ‘Nullius in verba’, which means something like ‘Take no one’s word for it.’ However, rebellion against authority
================================================================================given that they have content that the recipient never observes. I think that both those puzzles have the same solution: what replicates human memes is creativity; and creativity was used, while it was evolving, to replicate memes. In other words, it was used to acquire existing knowledge, not to create new knowledge. But the mechanism to do both things is identical, and so in acquiring the ability to do the former, we automatically became able to do the latter. It was a momentous example of reach, which made possible everything that is uniquely human. A person acquiring a meme faces the same logical challenge as a scientist. Both must discover a hidden explanation. For the former, it is an idea in the minds of other people; for the latter, a regularity or law of nature. Neither person has direct access to this explanation. But both have access to evidence with which explanations can be tested: the observed behaviour of people who hold the meme, and physical phenomena conforming to the law. The puzzle of how one can possibly translate behaviour back into a theory that contains its meaning is therefore the same puzzle as where scientific knowledge comes from. And the idea that memes are copied by imitating their holders’ behaviour is the same mistake as empiricism or inductivism or Lamarckism. They all depend on there being a way of automatically translating problems (like the problem of planetary motions, or of how to reach leaves on tall trees or to be invisible to one’s prey) into their solutions. In other words, they assume that the environment (in the form of an observed phenomenon, or a tall tree, say) can ‘instruct’ minds or genomes in how to meet its challenges. Popper wrote: The inductivist or Lamarckian approach operates with the idea of instruction from without, or from the environment. But the critical or Darwinian approach only allows instruction from within – from within the structure itself . . . I contend that there is no such thing as instruction from without the structure. We do not discover new facts or new effects by copying them, or by inferring them inductively from observation, or by any other method of instruction by the environment. We use, rather, the method 411 the beginning of infinity of trial and the elimination of error. As Ernst Gombrich says, ‘making comes before matching’: the active production of a new trial structure comes before its exposure to eliminating tests. The Myth of the Framework Popper could just as well have written, ‘We do not acquire new memes by copying them, or by inferring them inductively from observation, or by any other method of imitation of, or instruction by, the environ- ment.’ The transmission of human-type memes – memes whose meaning is not mostly predefined within the receiver – cannot be other than a creative activity on the part of the receiver. Memes, like scientific theories, are not derived from anything. They are created afresh by the recipient. They are conjectural explanations, which are then subjected to criticism and testing before being tentatively adopted. This same pattern of creative conjecture, criticism and testing generates inexplicit as well as explicit ideas. In fact all creativity does, for no idea can be represented entirely explicitly. When we make an explicit conjecture, it has an inexplicit component whether we are aware of it or not. And so does all criticism. Thus, as has so often happened in the history of universality, the human capacity for universal explanation did not evolve to have a universal function. It evolved simply to increase the volume of memetic information that our ancestors could acquire, and the speed and accuracy which they could acquire it. But since the easiest way for evolution to do that was to give us a universal ability to explain, through creativity, that is what it did. This epistemological fact provides not only the solution of the two puzzles I mentioned, but also the reason for the evolution of human creativity – and therefore the human species – in the first place. It must have happened something like this. In early pre-human societies, there were only very simple memes – the kind that apes now have, though perhaps with a wider repertoire of copiable elementary behaviours. Those memes were about practical things like how to get food that was otherwise inaccessible. The value of such knowledge must have been high, so this created a ready-made niche for any adaptation that would reduce the effort required to replicate memes. Creativity was the ultimate adaptation to fill that niche. As it increased, 412 The Evolution of Creativity further adaptations co-evolved, such as an increase in memory capacity (to store more memes), finer motor control, and specialized brain structures for dealing with language. As a result, the meme band- width (the amount of memetic information that could be passed from each generation to the next) increased too. Memes also became more complex and sophisticated. This is why and how our species evolved, and why it evolved rapidly – at first. Memes gradually came to dominate our ancestors’ behaviour. Meme evolution took place, and, like all evolution, this was always in the direction of greater faithfulness. This meant becoming ever more anti-rational. At some point, meme evolution achieved static societies – presumably they were tribes. Consequently, all those increases in creativity never produced streams of innovations. Innovation remained imperceptibly slow, even as the capacity for it was increasing rapidly. Even in a static society, memes still evolve, due to imperceptible errors of replication. They just evolve more slowly than anyone can notice: imperceptible errors cannot be suppressed. They would generally evolve towards greater fidelity of replication, as usual with evolution, and hence to greater staticity of the society. Status in such a society is reduced by transgressing people’s ex - pectations of proper behaviour, and is improved by meeting them. There would have been the expectations of parents, priests, chiefs and potential mates (or whoever controlled mating
================================================================================to do with geography? They may simply have been too set in their ways. Perhaps innovative uses for animals were taboo. Perhaps such a trade was attempted, but failed every time because of sheer bad luck. But, whatever the reason was, it cannot have been that the hot region constituted a physical barrier, for it did not. Those are the parochial considerations. The bigger picture is that the spread of llamas can only have been prevented by people’s ideas and outlook. Had the Andeans had a Polynesian outlook instead, llamas might have spread all over the Americas. Had the ancient Polynesians not had that outlook, they might never have settled Polynesia in the first place, and biogeographical explanations would now be referring to the great ocean barrier as the ‘ultimate explanation’ for that. If the Polynesians had been even better at long-range trading, they might have managed to transport horses from Asia to their islands and thence to South America – a feat perhaps no more impressive than Hannibal’s transporting elephants across the Alps. If the ancient Greek enlighten- ment had continued, Athenians might have been the first to settle the Pacific islands and they would now be the ‘Polynesians’. Or, if the early Andeans had worked out how to breed giant war llamas and had ridden out to explore and conquer before anyone else had even thought of domesticating the horse, South American biogeographers might now be explaining that their ancestors colonized the world because no other continent had llamas. Moreover, the Americas had not always lacked large quadrupeds. When the first humans arrived there, many species of ‘mega-fauna’ were common, including wild horses, mammoths, mastodons and other members of the elephant family. According to some theories, the humans hunted them to extinction. What would have happened if one 427 the beginning of infinity of those hunters had had a different idea: to ride the beast before killing it? Generations later, the knock-on effects of that bold conjecture might have been tribes of warriors on horses and mammoths pouring back through Alaska and re-conquering the Old World. Their descendants would now be attributing this to the geographical distribution of mega- fauna. But the real cause would have been that one idea in the mind of that one hunter. In early prehistory, populations were tiny, knowledge was parochial, and history-making ideas were millennia apart. In those days, a meme spread only when one person observed another enacting it nearby, and (because of the staticity of cultures) rarely even then. So at that time human behaviour resembled that of other animals, and much of what happened was indeed explained by biogeography. But developments such as abstract language, explanation, wealth above the level of subsist- ence, and long-range trade all had the potential to erode parochialism and hence to give causal power to ideas. By the time history began to be recorded, it had long since become the history of ideas far more than anything else – though unfortunately the ideas were still mainly of the self-disabling, anti-rational variety. As for subsequent history, it would take considerable dedication to insist that biogeographical explanations account for the broad sweep of events. Why, for instance, did the societies in North America and Western Europe, rather than Asia and Eastern Europe, win the Cold War? Analysing climate, minerals, flora, fauna and diseases can teach us nothing about that. The explanation is that the Soviet system lost because its ideology wasn’t true, and all the biogeography in the world cannot explain what was false about it. Coincidentally, one of the things that was most false about the Soviet ideology was the very idea that there is an ultimate explanation of history in mechanical, non-human terms, as proposed by Marx, Engels and Diamond. Quite generally, mechanical reinterpretations of human affairs not only lack explanatory power, they are morally wrong as well, for in effect they deny the humanity of the participants, casting them and their ideas merely as side effects of the landscape. Diamond says that his main reason for writing Guns, Germs and Steel was that, unless people are convinced that the relative success of Europeans was caused by biogeography, they will for ever be tempted by racist explanations. Well, not readers of this book, I trust! Presumably 428 Unsustainable Diamond can look at ancient Athens, the Renaissance, the Enlighten- ment – all of them the quintessence of causation through the power of abstract ideas – and see no way of attributing those events to ideas and to people; he just takes it for granted that the only alternative to one reductionist, dehumanizing reinterpretation of events is another. In reality, the difference between Sparta and Athens, or between Savonarola and Lorenzo de’ Medici, had nothing to do with their genes; nor did the difference between the Easter Islanders and the imperial British. They were all people – universal explainers and constructors. But their ideas were different. Nor did landscape cause the Enlightenment. It would be much truer to say that the landscape we live in is the product of ideas. The primeval landscape, though packed with evidence and therefore opportunity, contained not a single idea. It is knowledge alone that converts landscapes into resources, and humans alone who are the authors of explanatory knowledge and hence of the uniquely human behaviour called ‘history’. Physical resources such as plants, animals and minerals afford opportunities, which may inspire new ideas, but they can neither create ideas nor cause people to have particular ideas. They also cause problems, but they do not prevent people from finding ways to solve those problems. Some overwhelming natural event like a volcanic eruption might have wiped out an ancient civilization regardless of what the victims were thinking, but that sort of thing is exceptional. Usually, if there are human beings left alive to think, there are ways of thinking that can improve their situation, and then improve it further. Unfortunately, as I have explained, there are also ways of thinking that can prevent
================================================================================education enjoins them to hold their most important ideas immune from criticism. Not to be open to suggestions. Not to criticize certain ideas such as their traditions or their conceptions of the gods; not to seek the truth, because they claim that they already have it. Hence they do not believe that ‘in the course of time they may *Popper’s translation in The World of Parmenides (1998). 230 A Dream of Socrates learn and know things better.’ They agree among themselves because their laws and customs enforce conformity. We agree among ourselves (to the extent that we do) because, through our tradition of endless critical debate, we have discovered some genuine knowledge. Since there is only one truth of any given matter, as we discover ideas closer to the truth our ideas become closer to each other’s, so we agree more. People who converge upon the truth converge with each other. hermes: Indeed. socrates: Moreover, since the Spartans never seek improvement, it is not surprising that they never find it. We, in contrast, have sought it – by constantly criticizing and debating and trying to correct our ideas and behaviour. And thereby we are well placed to learn more in the future. hermes: It follows, then, that it is wrong of the Spartans to educate their children to hold their city’s ideas, laws and customs immune from criticism. socrates: I thought you weren’t going to reveal moral truths! hermes: I can’t help it if it follows logically from epistemology. But, anyway, you already know this one. socrates: Yes, I do. And I see what you are getting at. You are showing me that there are such things as mirages and tricks in regard to moral knowledge. Some of them are embedded in the Spartans’ traditional moral choices. Their whole way of life misleads and traps them – because one of their mistaken beliefs is that they must take no steps to prevent their way of life from misleading and trapping them! hermes: Yes. socrates: Are there such traps embedded in our way of life? [Frowns.] Of course, I think there aren’t – but I would think that, wouldn’t I? As Xenophanes also wrote, it’s all too easy to attribute universal truth to mere local appearances: The Ethiops say that their gods are flat-nosed and black While the Thracians say that theirs have blue eyes and red hair. Yet if cattle or horses or lions had hands and could draw And could sculpture like men, then the horses would draw their gods Like horses, and cattle like cattle . . . 231 the beginning of infinity hermes: So now you are imagining some Spartan Socrates who considers their ways virtuous and yours decadent – socrates: And who considers us to be stuck in a trap, since we shall never willingly ‘correct’ ourselves by adopting Spartan ways. Yes. hermes: But does this Spartan Socrates, if he exists, worry that the Athenian Socrates may be right, and he wrong? Was there a Spartan Xenophanes who suspected that the gods might not be as the Greeks think they are? socrates: Most certainly not! hermes: So, since one of their ‘ways’ is to preserve all their ways unchanged, then if he were right, and you wrong – socrates: Then the Spartans must also have been right ever since they embarked on their present way of life. The gods must have revealed the perfect way of life to them at the outset. So – did you? hermes: [Raises his eyebrows.] socrates: Of course you didn’t. Now I see that the difference between our ways and theirs is not merely a matter of perspective, nor just a matter of degree.* Let me restate it: If the Spartan Socrates is right that Athens is trapped in falsehoods but Sparta is not, then Sparta, being unchanging, must already be perfect, and hence right about everything else too. Yet in fact they know almost nothing. One thing that they clearly don’t know is how to persuade other cities that Sparta is perfect, even cities that have a policy of listening to arguments and criticism . . . hermes: Well, logically it could be that the ‘perfect way of life’ involves having few accomplishments and being wrong about most things. But, yes, you are glimpsing something important here – socrates: Whereas if I am right that Athens is not in such a trap, that implies nothing about whether we are right or wrong about any other matter. Indeed, our very idea that improvement is possible implies that there must be errors and inadequacies in our current ideas. I thank you, generous Apollo, for this ‘glimpse’ into that important difference. hermes: Yet there is even more of a difference than you think. Bear *I shall say more about the difference between those two kinds of society – which I call static and dynamic societies – in Chapter 15. 232 A Dream of Socrates in mind that the Spartans and Athenians alike are but fallible men and are subject to misconceptions and errors in all their thinking – socrates: Wait! We are fallible in all our thinking? Is there literally no idea that we may safely hold immune from criticism? hermes: Like what? socrates: [Ponders for a while. Then:] What about the truths of arithmetic, like two plus two equals four? Or the fact that Delphi exists? What about the geometrical fact that the angles of a triangle sum to two right angles? hermes: Revealing no facts, I cannot confirm that all three of those propositions are even true! But more important is this: how did you come to choose those particular propositions as candidates for immunity from criticism? Why Delphi and not Athens? Why two plus two and not three plus four? Why not the theorem of Pythagoras? Was it because you decided that the propositions you chose would best make your point because they were the most obviously, un - ambiguously true of all the propositions you considered using? socrates: Yes.
================================================================================371, 437, 439 114, 116, 118, 123, 124, 130, 141, ecosystems 293, 373, 444, 459 artificial/virtual 68 and reductionism 109–10 see also biosphere emotions 154, 356, 384, 389 Eden, Garden of 52, 63 empiricism 4–29, 32, 119, 122, 155, Edison, Thomas 36, 41, 158, 341 165, 311–12, 358, 361, 411 see also inspiration/perspiration and the deceptiveness of the senses 8, education 123, 203–4, 210, 217–18, 14, 301 230–31, 244, 247, 252, 254, 311, failed to eliminate authority 8–10; see 377–8, 382, 389, 391, 392, 393, also justificationism 469 index empiricism (cont.) empiricism see empiricism the falseness of 7–8, 32, 39, 120, inductivism 5–7 209–10, 403 see also knowledge and the history of ideas 311–12, equivocation 309, 318, 325, 448 314–16, 325, 345, 354 Eratosthenes of Cyrene 443, 458 Horgan’s misconceptions based on error correction 94, 136, 140–42, 147, 448 192, 209, 210, 211, 222, 271, 302, and inductivism 5–7 322, 323, 328, 389, 395, 409, and instrumentalism 15 411–12 mistaken idea of theory-free and convergence 350 observation 39 requires digital information 140–42 salutary role 13, 311 in plurality voting 348 see also knowledge and universality 147 end-of-the-world prophet 14, 21–2; see see also fooling ourselves also Malthusian prophetic fallacy Euclid energy 267, 361, 439 Euclidean space 164, 183 dark 451 theory of geometry 42, 183, 184 and fungibility 267, 298 Euripides 216 gravitational 3, 450 europium 433, 434 law of conservation of 109 Everett, Hugh 310 needed for knowledge creation 61–2, interpretation of quantum theory 310 146 evidence 22, 25, 27–8, 39, 49, 73, 75, of photons in different universes 103 297–8 circumstantial 10 quantized 274, 291, 298, 433 as an essential requirement for solar 50, 66, 74 knowledge creation 61, 67 Engels, Friedrich 426, 428, 430, 442 we are inundated with 61–2, 66 ENIAC (computer) 139 literally within arm’s reach 62 Enlightenment, the 31 in philosophy 209 British 65–6; and progress 12–14, of our senses 4 22–3, 29, 32–3, 65–6, 133, is the same throughout the universe 203, 390–91; and the scientific 62, 67–9 revolution 12, 14, 23, 32, 53; and evils 199–200, 212, 213, 221, 319, 395, universality 133–4 435 and the evolution of memes 390–93 evil of death 213 mini-enlightenments 23, 31, 216–21 problem of evil 80, 199 and our view of the Earth 443 evolution 48–9, 52 utopian (Continental) 65–6, 313 artificial 158–63 entanglement 284–5, 293, 295, 296–7, and attraction 360–65 303, 308 co-evolution 360–62, 400, 414–15 entanglement information 281, convergent 95 289–90, 307 of creativity see creativity: evolution protection of qubits from 295 of time as an entanglement phenomenon of culture see cultural evolution 299 Darwinian 105 environment see biosphere of the human species 48, 55, 394, epidemics/pandemics 196, 208, 418, 412–13 436 and knowledge 77, 78–105 see also Black Death natural selection 52, 56, 78, 87,not epistemology 225, 412 necessarily adaptive 91 and ‘a dream of Socrates’ 226–43, of non-explanatory knowledge 94 245, 252–3 ‘survival of the fittest’ 91, 371 470 index see also adaptation; Lamarckism and technology, fundamental link with evolutionary cosmologies 178–9 55–6, 58 ex nihilo creation 104, 345 ‘ultimate’ 425–8 see also regress, infinite universal explainers 123, 157, 415 expectations 4, 17–19 explicability 53–4, 60, 64, 103, 108, experience, sensory see sensory 111, 121,146, 193, 200, 213, 260, experience 264–5, 270, 272, 282, 300–301, experimental testing 13–14, 26 358, 445–6, 459 essence of 16–18 extinction of species 48, 49, 90, 95–6, falsification through 26 428, 436, 437 Galileo and 14 caused by their own evolution 49, principle of testability 14, 26, 111 55, 92 explanationless theories 15, 16, 158, hedge against extinction of human 210, 316, 318–19, 320–23, 325 species 62–3 see also philosophy, bad; human escapes from 49, 196–7, inexplicability; rules of thumb 204–5, 206–7 explanations 30 mass extinction events 49, 95–6 of abstractions 114–24 and storing the genes of endangered bad (easy to vary) 19–22, 25–6, 29, species 95 31, 53–4, 64, 80, 83, 97, 101–2, extraterrestrials 2, 60, 145, 322, 414 150, 154, 174, 199–200, 260, 264, art and 354 282, 311, 324; and bad philosophy dangerous 60, 202–3 311–25 detecting life on distant planets 68, 73 are conjectural 2, 9, 10, 17, 26, 191–3 extraterrestrial civilizations 79, 101, creating new problems 64, 76, 350, 202–4, 399 422 search for intelligent (SETI) 72–3, creativity and 7–8, 342 179–80 and decision-making 341 see also Fermi’s problem discrete options between 342 eyes 1, 2, 3, 11, 37, 40, 46, 52, 54–5, and elegance 355 59, 68, 80, 83–4, 85, 226, 229, 231, evolution of explanatory theories 94 240n, 241, 252, 261, 294, 316, 355, falsified 26 383 good (hard to vary) vii, 6, 24, 25, 28, 31, 78–9, 94, 156, 209, 257, 306, Fabric of Reality, The (Deutsch) 109–10, 341, 342, 353 450, 460 and imagination 26, 264–5 fairness imitation and 410 apportionment paradoxes 326–33, instrumentalist conception of 13 334 mythical 19–21, 24, 25 impartiality 330, 331, 334 open-ended stream of explanatory misconceptions in social-choice theory knowledge 60–65, 67, 69, 81, 175, 345–6 450, 457–9 Fall from Grace 52 the quest for good explanations vii, fallibilism 9, 32, 64, 65, 193, 211, 232, 22–3, 26, 39, 314 233, 395, 446, 448 reach of 1–33, 59–60, 75, 78–9, 105, fallibility 66, 135, 192, 226, 233–5, 240, 118, 123, 166–7, 197, 220, 458–9 242, 252–3, 254–5, 311, 317, 413 and reality 6 see also fallibilism reductive 109–10, 116, 361, 371, 429 farming see agriculture scientific theories as 3, 14, 113 Fascist ideologies 371 of seasons 19–21, 23–5, 26–9, 42, see also Nazism 44, 458 fashion 314, 354, 356 simplicity is inadequate 25–6 fads 379, 394 471 index Fatherland (Harris) 259 of creativity 358, 415–16 FDP (Free Democratic Party, Germany) not yet imaginable 444 339–40 optimism and the desirable future Fermi, Enrico 101 446–7 Fermi’s problem 101, 453 and the pessimistic view of bounded Feynman, Richard 22, 39, 101, 209, knowledge 198, 445–6, 447–9 305, 355, 444 and the shedding of parochialism fiction 26, 294 444–5 see also science fiction and the simulation argument 453–4 fine-tuning of the universe/laws of unpredictability of knowledge
================================================================================fluctuations, and random outside influences makes analogue computers wander off the intended compu- tational path. This may sound like a minor or parochial consideration. But it is quite the opposite. Without error-correction all information processing, and hence all knowledge-creation, is necessarily bounded. Error-correction is the beginning of infinity. For example, tallying is universal only if it is digital. Imagine that some ancient goatherds had tried to tally the total length of their flock instead of the number. As each goat left the enclosure, they could reel out some string of the same length as the goat. Later, when the goats returned, they could reel that length back in. When the whole length had been reeled back in, that would mean that all the goats had returned. But in practice the outcome would always be at least a little long or short, because of the accumulation of measurement errors. For any given accuracy of measurement, there would be a maximum number of goats that could be reliably tallied by this ‘analogue tallying’ 140 The Jump to Universality system. The same would be true of all arithmetic performed with those ‘tallies’. Whenever the strings representing several flocks were added together, or a string was cut in two to record the splitting of a flock, and whenever a string was ‘copied’ by making another of the same length, there would be errors. One could mitigate their effect by performing each operation many times, and then keeping only the outcome of median length. But the operations of comparing or duplicat- ing lengths can themselves be performed only with finite accuracy, and so could not reduce the rate of error accumulation per step below that level of accuracy. That would impose a maximum number of consecutive operations that could be performed before the result became useless for a given purpose – which is why analogue computation can never be universal. What is needed is a system that takes for granted that errors will occur, but corrects them once they do – a case of ‘problems are inev- itable, but they are soluble’ at the lowest level of information-processing emergence. But, in analogue computation, error correction runs into the basic logical problem that there is no way of distinguishing an erroneous value from a correct one at sight, because it is in the very nature of analogue computation that every value could be correct. Any length of string might be the right length. And that is not so in a computation that confines itself to whole numbers. Using the same string, we might represent whole numbers as lengths of string in whole numbers of inches. After each step, we trim or lengthen the resulting strings to the nearest inch. Then errors would no longer accumulate. For example, suppose that the measurements could all be done to a tolerance of a tenth of an inch. Then all errors would be detected and eliminated after each step, which would eliminate the limit on the number of consecutive steps. So all universal computers are digital; and all use error-correction with the same basic logic that I have just described, though with many different implementations. Thus Babbage’s computers assigned only ten different meanings to the whole continuum of angles at which a cogwheel might be oriented. Making the representation digital in that way allowed the cogs to carry out error-correction automatically: after each step, any slight drift in the orientation of the wheel away from its ten ideal positions would immediately be corrected back to the 141 the beginning of infinity nearest one as it clicked into place. Assigning meanings to the whole continuum of angles would nominally have allowed each wheel to carry (infinitely) more information; but, in reality, information that cannot be reliably retrieved is not really being stored. Fortunately, the limitation that the information being processed must be digital does not detract from the universality of digital computers – or of the laws of physics. If measuring the goats in whole numbers of inches is insufficient for a particular application, use whole numbers of tenths of inches, or billionths. The same holds for all other appli- cations: the laws of physics are such that the behaviour of any physical object – and that includes any other computer – can be simulated with any desired accuracy by a universal digital computer. It is just a matter of approximating continuously variable quantities by a sufficiently fine grid of discrete ones. Because of the necessity for error-correction, all jumps to universality occur in digital systems. It is why spoken languages build words out of a finite set of elementary sounds: speech would not be intelligible if it were analogue. It would not be possible to repeat, nor even to remember, what anyone had said. Nor, therefore, does it matter that universal writing systems cannot perfectly represent analogue inform- ation such as tones of voice. Nothing can represent those perfectly. For the same reason, the sounds themselves can represent only a finite number of possible meanings. For example, humans can distinguish between only about seven different sound volumes. This is roughly reflected in standard musical notation, which has approximately seven different symbols for loudness (such as p, mf, f, and so on). And, for the same reason, speakers can only intend a finite number of possible meanings with each utterance. Another striking connection between all those diverse jumps to universality is that they all happened on Earth. In fact all known jumps to universality happened under the auspices of human beings – except one, which I have not mentioned yet, and from which all the others, historically, emerged. It happened during the early evolution of life. Genes in present-day organisms replicate themselves by a complicated and very indirect chemical route. In most species they act as templates for forming stretches of a similar molecule, RNA. Those then act as programs which direct the synthesis of the body’s constituent chemicals, 142 The Jump to Universality especially enzymes, which are catalysts. A catalyst
================================================================================when I shop for oil. Should I buy the extra oily, the super oily, or the ultra oily. There’s no way to tell. judge: h ow about your career? does that involve oil? 151 the beginning of infinity elbot: Well what about humans and occupation? Where do they stand on this? When the judge helpfully took up Elbot’s randomly introduced theme of oil, Elbot ignored it. Instead, having detected the keyword ‘career’, it converted it to the synonym ‘occupation’ and inserted it into a stock sentence pattern. This is how much success the quest for ‘machines that think’ had achieved in the fifty-eight years following Turing’s paper: nil. Yet, in every other respect, computer science and technology had made astounding progress during that period. The dwindling group of op - ponents of the very possibility of AI are no doubt unsurprised by this failure – for the wrong reason: they do not appreciate the significance of universality. But the most passionate enthusiasts for the imminence of AI do not appreciate the significance of the failure. Some claim that the above criticism is unfair: modern AI research is not focused on passing the Turing test, and great progress has been made in what is now called ‘AI’ in many specialized applications. However, none of those applications look like ‘machines that think’.* Others maintain that the criticism is premature, because, during most of the history of the field, computers had absurdly little speed and memory capacity compared with today’s. Hence they continue to expect the breakthrough in the next few years. This will not do either. It is not as though someone has written a chatbot that could pass the Turing test but would currently take a year to compute each reply. People would gladly wait. And in any case, if anyone knew how to write such a program, there would be no need to wait – for reasons that I shall get to shortly. In his 1950 paper, Turing estimated that, to pass his test, an AI program together with all its data would require no more than about 100 megabytes of memory, that the computer would need to be no faster than computers were at the time (about ten thousand operations per second), and that by the year 2000 ‘one will be able to speak of machines thinking without expecting to be contradicted.’ Well, the year 2000 has come and gone, the laptop computer on which I am writing this book has over a thousand times as much memory as Turing * Hence what I am calling ‘AI’ is sometimes called ‘AGI’: Artificial General Intelligence. 152 Artificial Creativity specified (counting hard-drive space), and about a million times the speed (though it is not clear from his paper what account he was taking of the brain’s parallel processing). But it can no more think than Turing’s slide rule could. I am just as sure as Turing was that it could be programmed to think; and this might indeed require as few re- sources as Turing estimated, even though orders of magnitude more are available today. But with what program? And why is there no sign of such a program? Intelligence in the general-purpose sense that Turing meant is one of a constellation of attributes of the human mind that have been puzzling philosophers for millennia; others include consciousness, free will, and meaning. A typical such puzzle is that of qualia (singular quale, which rhymes with ‘baa-lay’) – meaning the subjective aspect of sensations. So for instance the sensation of seeing the colour blue is a quale. Consider the following thought experiment. You are a biochemist with the misfortune to have been born with a genetic defect that disables the blue receptors in your retinas. Consequently you have a form of colour blindness in which you are able to see only red and green, and mixtures of the two such as yellow, but anything purely blue also looks to you like one of those mixtures. Then you discover a cure that will cause your blue receptors to start working. Before administering the cure to yourself, you can confidently make certain predictions about what will happen if it works. One of them is that, when you hold up a blue card as a test, you will see a colour that you have never seen before. You can predict that you will call it ‘blue’, because you already know what the colour of the card is called (and can already check which colour it is with a spectrophotometer). You can also predict that when you first see a clear daytime sky after being cured you will experience a similar quale to that of seeing the blue card. But there is one thing that neither you nor anyone else could predict about the outcome of this experiment, and that is: what blue will look like. Qualia are currently neither describable nor predictable – a unique property that should make them deeply problematic to anyone with a scientific world view (though, in the event, it seems to be mainly philosophers who worry about it). I consider this exciting evidence that there is a fundamental discovery to be made which will integrate things like qualia into our other 153 the beginning of infinity knowledge. Daniel Dennett draws the opposite conclusion, namely that qualia do not exist! His claim is not, strictly speaking, that they are an illusion – for an illusion of a quale would be that quale. It is that we have a mistaken belief. Our introspection – which is an inspection of memories of our experiences, including memories dating back only a fraction of a second – has evolved to report that we have experienced qualia, but those are false memories. One of Dennett’s books defending this theory is called Consciousness Explained. Some other philosophers have wryly remarked that Consciousness Denied would be a more accurate name. I agree, because, although any true explanation of qualia will have to meet the challenge of Dennett’s criticisms
================================================================================effects typically continue indefinitely, as I have described, with a wave of differentiation entangling more and more objects. If the differential effects can all be undone, then interference between those original values becomes possible again; but the laws of quantum mechanics dictate that undoing them requires fine control of all the affected objects, and that rapidly becomes infeasible. The process of its becoming infeasible is known as decoherence. In most situations, decoherence is very rapid, which is why splitting typically predominates over interference, and why interference – though ubiquitous on microscopic scales – is quite hard to demonstrate unambiguously in the laboratory. Nevertheless, it can be done, and quantum interference phenomena constitute our main evidence of the existence of the multiverse, and of what its laws are. A real-life analogue of the above experiment is standard in quantum optics laboratories. Instead of experimenting on voltmeters (whose many interactions with their environment quickly cause decoherence), one uses individual photons, and the variable being acted upon is not voltage but which of two possible paths the photon is on. Instead of the transporter, one uses a simple device called a semi- silvered mirror (represented by the grey sloping bars in the diagrams below). When a photon strikes such a mirror, it bounces off in half the universes, and passes straight through in the other half, as shown on next page: 285 the beginning of infinity Semi-silvered mirror The attributes of travelling in the X or Y directions behave analogously to the two voltages X and Y in our fictitious multiverse. So passing through the semi-silvered mirror is the analogue of the transformation above. And when the two instances of a single photon, travelling in directions X and Y, strike the second semi-silvered mirror at the same time, they undergo the transformation , which means that both instances emerge in the direction X: the two histories rejoin. To demonstrate this, one can use a set-up known as a ‘Mach– Zehnder interferometer’, which performs those two transfor mations (splitting and interference) in quick succession: Mach–Zehnder interferometer 286 The Multiverse The two ordinary mirrors (the black sloping bars) are merely there to steer the photon from the first to the second semi-silvered mirror. If a photon is introduced travelling rightwards (X) after the first mirror instead of before as shown, then it appears to emerge randomly, rightwards or downwards, from the last mirror (because then, happens there). The same is true of a photon introduced travelling downwards (Y) after the first mirror. But a photon introduced as shown in the diagram invariably emerges rightwards, never downwards. By doing the experiment repeatedly with and without detectors on the paths, one can verify that only one photon is ever present per history, because only one of those detectors is ever observed to fire during such an experiment. Then, the fact that the intermediate histories X and Y both contribute to the deterministic final outcome X makes it inescapable that both are happening at the intermediate time. In the real multiverse, there is no need for the transporter or any other special apparatus to cause histories to differentiate and to rejoin. Under the laws of quantum physics, elementary particles are undergoing such processes of their own accord, all the time. Moreover, histories may split into more than two – often into many trillions – each character ized by a slightly different direction of motion or difference in other physical variables of the elementary particle concerned. Also, in general the resulting histories have unequal measures. So let us now dispense with the transporter in the fictional multiverse too. The rate of growth in the number of distinct histories is quite mind- boggling – even though, thanks to interference, there is now a certain amount of spontaneous rejoining as well. Because of this rejoining, the flow of information in the real multiverse is not divided into strictly autonomous subflows – branching, autonomous histories. Although there is still no communication between histories (in the sense of message-sending), they are intimately affecting each other, because the effect of interference on a history depends on what other histories are present. Not only is the multiverse no longer perfectly partitioned into histories, individual particles are not perfectly partitioned into in- stances. For example, consider the following interference phenom enon, 287 the beginning of infinity where X and Y now represent different values of the position of a single particle: X X (cid:3514) X (cid:3514) Y Y How instances of a particle lose their identity during interference. Has the instance of the particle at X stayed at X or moved to Y? Has the instance of the particle at Y returned to Y or moved to X? Because these two groups of instances of the particle, initially at different positions, have gone through a moment of being fungible, there is no such thing as which of them has ended up at which final position. This sort of interference is going on all the time, even for a single particle in a region of otherwise empty space. So there is in general no such thing as the ‘same’ instance of a particle at different times. Even within the same history, particles in general do not retain their identities over time. For example, during a collision between two atoms, the histories of the event split into something like this and something like this 288 The Multiverse So, for each particle individually, the event is rather like a collision with a semi-silvered mirror. Each atom plays the role of the mirror for the other atom. But the multiversal view of both particles looks like this where at the end of the collision some of the instances of each atom have become fungible with what was originally a different atom. For the same reason, there is no such thing as the speed of one instance of the particle at a given location. Speed is defined as distance travelled divided by time taken, but that is not meaningful in situations
================================================================================well be in - tractably complicated. In practice the author’s explanation would always be at some emergent, abstract level. But that would not prevent it from being a good explanation. It would not have to account for the specific computational steps that composed a joke, just as the theory of evolution does not have to account for why every specific mutation succeeded or failed in the history of a given adaptation. It would just explain how it could happen, and why we should expect it to happen, given how the program works. If that were a good explanation, it would convince us that the joke – the knowledge in the joke – originated in the program and not in the programmer. Thus the very same utterance by the program – the joke – can be either evidence that it is not think- ing or evidence that it is thinking depending on the best available explanation of how the program works. 156 Artificial Creativity The nature of humour is not very well understood, so we do not know whether general-purpose thinking is required to compose jokes. So it is conceivable that, despite the wide range of subject matter about which one can joke, there are hidden connections that reduce all joke making to a single narrow function. In that case there could one day be general-purpose joke-making programs that are not people, just as today there are chess-playing programs that are not people. It sounds implausible, but, since we have no good explanation ruling it out, we could not rely on joke-making as our only way of judging an AI. What we could do, though, is have a conversation ranging over a diverse range of topics, and pay attention to whether the program’s utterances were or were not adapted, in their meanings, to the various purposes that came up. If the program really is thinking, then in the course of such a conversation it will explain itself – in one of countless, unpredictable ways – just as you or I would. There is a deeper issue too. AI abilities must have some sort of universality: special-purpose thinking would not count as thinking in the sense Turing intended. My guess is that every AI is a person: a general-purpose explainer. It is conceivable that there are other levels of universality between AI and ‘universal explainer/constructor’, and perhaps separate levels for those associated attributes like conscious- ness. But those attributes all seem to have arrived in one jump to universality in humans, and, although we have little explanation of any of them, I know of no plausible argument that they are at different levels or can be achieved independently of each other. So I tentatively assume that they cannot. In any case, we should expect AI to be achieved in a jump to universality, starting from something much less powerful. In contrast, the ability to imitate a human imperfectly or in specialized functions is not a form of universality. It can exist in degrees. Hence, even if chatbots did at some point start becoming much better at imitating humans (or at fooling humans), that would still not be a path to AI. Becoming better at pretending to think is not the same as coming closer to being able to think. There is a philosophy whose basic tenet is that those are the same. It is called behaviourism – which is instrumentalism applied to psychology. In other words, it is the doctrine that psychology can only, or should only, be the science of behaviour, not of minds; that it can 157 the beginning of infinity only measure and predict relationships between people’s external circumstances (‘stimuli’) and their observed behaviours (‘responses’). The latter is, unfortunately, exactly how the Turing test asks the judge to regard a candidate AI. Hence it encouraged the attitude that if a program could fake AI well enough, one would have achieved it. But ultimately a non-AI program cannot fake AI. The path to AI cannot be through ever better tricks for making chatbots more convincing. A behaviourist would no doubt ask: what exactly is the difference between giving a chatbot a very rich repertoire of tricks, templates and databases and giving it AI abilities? What is an AI program, other than a collection of such tricks? When discussing Lamarckism in Chapter 4, I pointed out the funda- mental difference between a muscle becoming stronger in an individual’s lifetime and muscles evolving to become stronger. For the former, the knowledge to achieve all the available muscle strengths must already be present in the individual’s genes before the sequence of changes begins. (And so must the knowledge of how to recognize the circum- stances under which to make the changes.) This is exactly the analogue of a ‘trick’ that a programmer has built into a chatbot: the chatbot responds ‘as though’ it had created some of the knowledge while composing its response, but in fact all the knowledge was created earlier and elsewhere. The analogue of evolutionary change in a species is creative thought in a person. The analogue of the idea that AI could be achieved by an accumulation of chatbot tricks is Lamarckism, the theory that new adaptations could be explained by changes that are in reality just a manifestation of existing knowledge. There are several current areas of research in which that same misconception is common. In chatbot-based AI research it sent the whole field down a blind alley, but in other fields it has merely caused researchers to attach overambitious labels to genuine, albeit relatively modest, achievements. One such area is artificial evolution. Recall Edison’s idea that progress requires alternating ‘inspiration’ and ‘perspiration’ phases, and that, because of computers and other technology, it is increasingly becoming possible to automate the per - spiration phase. This welcome development has misled those who are overconfident about achieving artificial evolution (and AI). For example, suppose that you are a graduate student in robotics, hoping 158 Artificial Creativity to build a robot
================================================================================the Earth is not at rest but in complex motion. Although we first noticed a daily rotation by observing stars, it is not a property of the stars at all, but of the Earth, and of the observers who rotate with it. It is a classic example of the deceptiveness of the senses: the Earth looks and feels as though it is at rest beneath our feet, even though it is really rotating. As for the celestial sphere, despite being visible in broad daylight (as the sky), it does not exist at all. The deceptiveness of the senses was always a problem for empiricism – and thereby, it seemed, for science. The empiricists’ best defence was that the senses cannot be deceptive in themselves. What misleads us are only the false interpretations that we place on appearances. That is indeed true – but only because our senses themselves do not say anything. Only our interpretations of them do, and those are very fallible. But the real key to science is that our explanatory theories – which include those interpretations – can be improved, through conjecture, criticism and testing. Empiricism never did achieve its aim of liberating science from authority. It denied the legitimacy of traditional authorities, and that was salutary. But unfortunately it did this by setting up two other false 8 The Reach of Explanations authorities: sensory experience and whatever fictitious process of ‘derivation’, such as induction, one imagines is used to extract theories from experience. The misconception that knowledge needs authority to be genuine or reliable dates back to antiquity, and it still prevails. To this day, most courses in the philosophy of knowledge teach that knowledge is some form of justified, true belief, where ‘justified’ means designated as true (or at least ‘probable’) by reference to some authoritative source or touchstone of knowledge. Thus ‘how do we know . . . ?’ is trans- formed into ‘by what authority do we claim . . . ?’ The latter question is a chimera that may well have wasted more philosophers’ time and effort than any other idea. It converts the quest for truth into a quest for certainty (a feeling) or for endorsement (a social status). This misconception is called justificationism. The opposing position – namely the recognition that there are no authoritative sources of knowledge, nor any reliable means of justifying ideas as being true or probable – is called fallibilism. To believers in the justified-true-belief theory of knowledge, this recognition is the occasion for despair or cynicism, because to them it means that know- ledge is unattainable. But to those of us for whom creating knowledge means understanding better what is really there, and how it really behaves and why, fallibilism is part of the very means by which this is achieved. Fallibilists expect even their best and most fundamental explanations to contain misconceptions in addition to truth, and so they are predisposed to try to change them for the better. In contrast, the logic of justificationism is to seek (and typically, to believe that one has found) ways of securing ideas against change. Moreover, the logic of fallibilism is that one not only seeks to correct the misconceptions of the past, but hopes in the future to find and change mistaken ideas that no one today questions or finds problematic. So it is fallibilism, not mere rejection of authority, that is essential for the initiation of unlimited knowledge growth – the beginning of infinity. The quest for authority led empiricists to downplay and even stig- matize conjecture, the real source of all our theories. For if the senses were the only source of knowledge, then error (or at least avoidable error) could be caused only by adding to, subtracting from or mis - interpreting what that source is saying. Thus empiricists came to believe 9 the beginning of infinity that, in addition to rejecting ancient authority and tradition, scientists should suppress or ignore any new ideas they might have, except those that had been properly ‘derived’ from experience. As Arthur Conan Doyle’s fictional detective Sherlock Holmes put it in the short story ‘A Scandal in Bohemia’, ‘It is a capital mistake to theorize before one has data.’ But that was itself a capital mistake. We never know any data before interpreting it through theories. All observations are, as Popper put it, theory-laden,* and hence fallible, as all our theories are. Consider the nerve signals reaching our brains from our sense organs. Far from providing direct or untainted access to reality, even they themselves are never experienced for what they really are – namely crackles of electrical activity. Nor, for the most part, do we experience them as being where they really are – inside our brains. Instead, we place them in the reality beyond. We do not just see blue: we see a blue sky up there, far away. We do not just feel pain: we experience a headache, or a stomach ache. The brain attaches those interpretations – ‘head’, ‘stomach’ and ‘up there’ – to events that are in fact within the brain itself. Our sense organs themselves, and all the interpretations that we consciously and unconsciously attach to their outputs, are notoriously fallible – as witness the celestial-sphere theory, as well as every optical illusion and conjuring trick. So we perceive nothing as what it really is. It is all theoretical interpretation: conjecture. Conan Doyle came much closer to the truth when, during ‘The Boscombe Valley Mystery’, he had Holmes remark that ‘circumstantial evidence’ (evidence about unwitnessed events) is ‘a very tricky thing . . . It may seem to point very straight to one thing, but if you shift your own point of view a little, you may find it pointing in an equally uncompromising manner to something entirely different . . . There is nothing more deceptive than an obvious fact.’ The same holds for scientific discovery. And that again raises the question: how do we know? If all our theories
================================================================================if and when SETI succeeds in its mission to detect radio signals transmitted by an extraterrestrial intelligence. Hence, if you were to keep a careful watch on the cork, and one day saw it popping from the bottle, you could infer that an extraterrestrial intelligence exists. The configuration of the cork is what experimentalists call a ‘proxy’: a physical variable which can be measured as a way of measuring another variable. (All scientific measure ments involve chains of proxies.) Thus we can also regard the entire Arecibo observatory, including its staff and that bottle and its cork, as a scientific instrument to detect distant people. The behaviour of that humble cork is therefore extraordinarily difficult to explain or predict. To predict it, you have to know whether 72 The Spark there really are people sending radio signals from various solar systems. To explain it, you have to explain how you know about those people and their attributes. Nothing less than that specific knowledge, which depends among other things on subtle properties of the chemistry on the planets of distant stars, can explain or predict with any accuracy whether, and when, that cork will pop. The SETI instrument is also remarkably finely tuned to its purpose. Completely insensitive to the presence of several tonnes of people a few metres away, and even to the tens of millions of tonnes of people on the same planet, it detects only people on planets orbiting other stars, and only if they are radio engineers. No other type of phenomenon on Earth, or in the universe, is sensitive to what people are doing at locations hundreds of light years away, let alone with that enormous degree of discrimination. This is made possible in part by the corresponding fact that few types of matter are as prominent, at those distances, as that type of scum. Specifically, the only phenomena that our best current instru- ments can detect at stellar distances are (1) extraordinarily luminous ones such as stars (or, to be precise, only their surfaces); (2) a few objects that obscure our view of those luminous objects; and (3) the effects of certain types of knowledge. We can detect devices such as lasers and radio transmitters that have been designed for the purpose of communication; and we can detect components of planetary atmospheres that could not be present in the absence of life. Thus those types of knowledge are among the most prominent phenomena in the universe. Note also that the SETI instrument is exquisitely adapted to detecting something that has never yet been detected. Biological evolution could never produce such an adaptation. Only scientific knowledge can. This illustrates why non-explanatory knowledge cannot be universal. Like all science, the SETI project can conjecture the existence of something, calculate what some of its observable attributes would be, and then construct an instrument to detect it. Non-explanatory systems cannot cross the conceptual gap that an explanatory conjecture crosses, to engage with unexperienced evidence or non-existent phenomena. Nor is that true only of fundamental science: if such-and-such a load were put on the proposed bridge it would collapse, says the engineer, and 73 the beginning of infinity such statements can be true and immensely valuable even if the bridge is never even built, let alone subjected to such a load. Similar champagne bottles are stored in other laboratories. The popping of each such cork signals a discovery about something significant in the cosmic scheme of things. Thus the study of the behaviour of champagne corks and other proxies for what people do is logically equivalent to the study of everything significant. It follows that humans, people and knowledge are not only objectively significant: they are by far the most significant phenomena in nature – the only ones whose behaviour cannot be understood without understanding everything of fundamental importance. Finally, consider the enormous difference between how an environ- ment will behave spontaneously (that is to say, in the absence of knowledge) and how it behaves once a tiny sliver of knowledge, of just the right kind, has reached it. We would normally regard a lunar colony, even after it has become self-sufficient, as having originated on Earth. But what, exactly, will have originated on Earth? In the long run, all its atoms have originated on the moon (or the asteroids). All the energy that it uses has originated in the sun. Only some proportion of its knowledge came from Earth, and, in the hypothetical case of a perfectly isolated colony, that would be a rapidly dwindling proportion. What has happened, physically, is that the moon has been changed – initially only minimally – by matter that came from the Earth. And what made the difference was not the matter, but the knowledge that it encoded. In response to that knowledge, the substance of the moon reorganized itself in a new, increasingly extensive and complex way, and started to create an indefinitely long stream of ever-improving explanations. A beginning of infinity. Similarly, in the intergalactic thought experiment, we imagined ‘priming’ a typical cube, and as a result intergalactic space itself began to produce a stream of ever-improving explanations. Notice how different, physically, the transformed cube is from a typical one. A typical cube has about the same mass as any of the millions of nearby cubes, and that mass barely changes over many millions of years. The transformed cube is more massive than its neighbours, and its mass is increasing continuously as the inhabitants systematically capture matter and use it to embody knowledge. The mass of a typical cube is 74 The Spark spread thinly throughout its whole volume; most of the mass of the transformed cube is concentrated at its centre. A typical cube contains mostly hydrogen; the transformed cube contains every element. A typical cube is not producing any energy; the transformed cube is converting mass to energy at a substantial rate. A typical cube is full of evidence, but most of it is just passing through, and none
================================================================================history. This was first understood by the physicists Don Page and William Wooters, in 1983. In this full version of the quantum multiverse, how is our science- fiction story to continue? Almost all the attention that the quantum theory has attracted, from physicists, philosophers and science-fiction authors alike, has focused on its parallel-universes aspect. That is ironic, because it is in the parallel-universe approximation that the world most resembles that of classical physics, yet that is the very aspect of quantum theory that many people seem to find viscerally unacceptable. Fiction can explore the possibilities opened up by parallel universes. For instance, since our story is a romance, the characters may well wonder about their counterparts in other histories. The story could compare their speculations with what we ‘know’ happened in the other histories. The character whose spouse’s unfaithfulness was revealed by a ‘random’ event might wonder whether that event provided a lucky escape from what was a doomed marriage anyway. Are they still married in the history in which the unfaithfulness was not subsequently revealed? Are they still happy? Can it be true happiness if it is ‘based on a lie’? As we see them speculating on these matters, we see the ‘still married’ history and know the (fictional) fact of the matter. They might also speculate about less parochial issues. The story could say that their sun is part of a cluster of dozens of stars, all within a sphere of a few light-weeks’ radius. This has puzzled their scientists for decades, since the composition of the stars shows that they originated from far and wide and became gravitationally bound through a series of very unlikely coincidences. In most universes, these scientists calcu- late, life cannot evolve in such dense star clusters, because there are too many collisions. So in most universes that contain humans there are no fleets of starships visiting inhabited star systems one after another. They have been trying to discover a mechanism by which the proximity of nearby stars might somehow precipitate the formation of intelligent life, but they have failed. Should they consider it just an astronomically 299 the beginning of infinity unlikely coincidence? But they do not like leaving things unexplained. Something must have selected them, they conclude. It did. Those people are not just a story. They are real, living, thinking human beings, wondering at this very moment where they came from. But they will never find out. In that one respect, they are unlucky: they were indeed selected by coincidence. Another way of putting that is that they were selected by the very story that I am now telling about them. All fiction that does not violate the laws of physics is fact. Some fiction in which the laws of physics appear to be violated is also fact, somewhere in the multiverse. This involves a subtle issue about how the multiverse is structured – how histories emerge. A history is approximately autonomous. If I boil some water in a kettle and make tea, I am in a history in which I switched on the kettle and the water became gradually hotter because of the energy being poured into it by the kettle, causing bubbles to form and so on, and eventually hot tea forms. That is a history because one can give explanations and make predictions about it without ever mentioning either that there are other histories in the multiverse where I chose to make coffee instead or that the microscopic motion of the water molecules is slightly affected by parts of the multiverse that are outside that history. It is irrelevant to that explanation that a small measure of that history differentiates itself during that process and does other things. In some tiny sliver of it, the kettle transforms itself into a top hat, and the water into a rabbit which then hops away, and I get neither tea nor coffee but am very surprised. That is a history too, after that transformation. But there is no way of correctly explaining what was happening during it, or predicting the probabilities, without referring to other parts of the multiverse – enormously larger parts (i.e. with larger measures) – in which there was no rabbit. So that history began at the transformation, and its causal connection with what happened before that cannot be expressed in history terms but only in multiverse terms. In simple cases like that, there is a ready-made approximative language in which we can minimize mention of the rest of the multiverse: the language of random events. This allows us to acknowledge that most of the high-level objects concerned still behaved autonomously except for being affected by something outside themselves – as when I am affected by the rabbit. This constitutes some continuity between a history 300 The Multiverse and a previous history from which it split, and we can refer to the former as a ‘history that has been affected by random events’. However, this is never literally what has happened: the part of that ‘history’ prior to the ‘random event’ is fungible with the rest of the broader history and therefore has no separate identity from it: it is not separately explicable. But the broader of those two histories still is. That is to say, the rabbit history is fundamentally different from the tea history, in that the latter remains very accurately autonomous throughout the period. In the rabbit history I end up with memories that are identical to what they would be in a history in which water became a rabbit. But those are misleading memories. There was no such history; the history containing those memories began only after the rabbit had formed. For that matter, there are also places in the multiverse – of far larger measure than that one – in which only my brain was affected, producing exactly those memories. In effect, I had a hallucination, caused by random motion of the atoms in my brain. Some philosophers make a big issue
================================================================================revenge on Hades by raiding the underworld and cooling all the caverns with spring air. The hot air thus displaced rises into the human world, causing summer. Demeter celebrates Persephone’s revenge and the anniversary of her escape by commanding plants to grow and adorn the Earth. This myth accounts for the same observations as the original, and it is testable (and in fact refuted) by the same observations. Yet what it asserts about reality is markedly different from – in many ways it is the opposite of – the original myth. Every other detail of the story, apart from its bare prediction that winter happens once a year, is just as easily variable. So, although the myth was created to explain the seasons, it is only superficially adapted to that purpose. When its author was wondering what could possibly make a goddess do something once a year, he did not shout, ‘Eureka! It must have been a marriage contract enforced by a magic seed.’ He made that choice – and all his substantive choices as author – for cultural and artistic reasons, and not because of the attributes of winter at all. He may also have been trying to explain aspects of human nature metaphorically – but here I am concerned with the myth only in its capacity as an explanation of seasons, and in that respect even its 20 The Reach of Explanations author could not have denied that the role of all the details could be played equally well by countless other things. The Persephone and Freyr myths assert radically incompatible things about what is happening in reality to cause seasons. Yet no one, I guess, has ever adopted either myth as a result of comparing it on its merits with the other, because there is no way of distinguishing between them. If we ignore all the parts of both myths whose role could be easily replaced, we are left with the same core explanation in both cases: the gods did it. Although Freyr is a very different god of spring from Persephone, and his battles very different events from her conjugal visits, none of those differing attributes has any function in the myths’ respective accounts of why seasons happen. Hence none of them provides any reason for choosing one explanation over the other. The reason those myths are so easily variable is that their details are barely connected to the details of the phenomena. Nothing in the problem of why winter happens is addressed by postulating specifically a marriage contract or a magic seed, or the gods Persephone, Hades and Demeter – or Freyr. Whenever a wide range of variant theories can account equally well for the phenomenon they are trying to explain, there is no reason to prefer one of them over the others, so advocating a particular one in preference to the others is irrational. That freedom to make drastic changes in those mythical explanations of seasons is the fundamental flaw in them. It is the reason that myth- making in general is not an effective way to understand the world. And that is so whether the myths are testable or not, for whenever it is easy to vary an explanation without changing its predictions, one could just as easily vary it to make different predictions if they were needed. For example, if the ancient Greeks had discovered that the seasons in the northern and southern hemispheres are out of phase, they would have had a choice of countless slight variants of the myth that would be consistent with that observation. One would be that when Demeter is sad she banishes warmth from her vicinity, and it has to go elsewhere – into the southern hemisphere. Similarly, slight variants of the Perse- phone explanation could account just as well for seasons that were marked by green rainbows, or seasons that happened once a week, or sporadically, or not at all. Likewise for the superstitious gambler or the end-of-the-world prophet: when their theory is refuted by experience, 21 the beginning of infinity they do indeed switch to a new one; but, because their underlying explanations are bad, they can easily accommodate the new experience without changing the substance of the explanation. Without a good explanatory theory, they can simply reinterpret the omens, pick a new date, and make essentially the same prediction. In such cases, testing one’s theory and abandoning it when it is refuted constitutes no progress towards understanding the world. If an explanation could easily explain anything in the given field, then it actually explains nothing. In general, when theories are easily variable in the sense I have described, experimental testing is almost useless for correcting their errors. I call such theories bad explanations. Being proved wrong by experiment, and changing the theories to other bad explanations, does not get their holders one jot closer to the truth. Because explanation plays this central role in science, and because testability is of little use in the case of bad explanations, I myself prefer to call myths, superstitions and similar theories unscientific even when they make testable predictions. But it does not matter what terminology you use, so long as it does not lead you to conclude that there is something worthwhile about the Persephone myth, or the prophet’s apocalyptic theory or the gambler’s delusion, just because is it testable. Nor is a person capable of making progress merely by virtue of being willing to drop a theory when it is refuted: one must also be seeking a better explanation of the relevant phenomena. That is the scientific frame of mind. As the physicist Richard Feynman said, ‘Science is what we have learned about how to keep from fooling ourselves.’ By adopting easily variable explanations, the gambler and prophet are ensuring that they will be able to continue fooling themselves no matter what happens. Just as thoroughly as if they had adopted untestable theories, they are insulating themselves from facing evidence that they are mistaken about
================================================================================relations or truths.’ The mathematician and computer pioneer Alan Turing later called this mistake ‘Lady Lovelace’s objection’. It was not computational universality that Lovelace failed to appreciate, but the universality of the laws of physics. Science at the time had almost no knowledge of the physics of the brain. Also, Darwin’s theory of evolution had not yet been published, and supernatural accounts of the nature of human beings were still prevalent. Today there is less mitigation for the minority of scientists and philosophers who still believe that AI is unattainable. For instance, the philosopher John Searle has placed the AI project in the following historical perspective: for centuries, some people have tried to explain the mind in mechanical terms, using similes and metaphors based on the most complex machines of the day. First the brain was supposed to be like an immensely complicated set of gears and levers. Then it was hydraulic pipes, then steam engines, then telephone ex c hanges – and, now that computers are our most impressive technology, brains are said to be computers. But this is still no more than a metaphor, says Searle, and there is no more reason to expect the brain to be a computer than a steam engine. But there is. A steam engine is not a universal simulator. But a computer is, so expecting it to be able to do whatever neurons can is not a metaphor: it is a known and proven property of the laws of physics as best we know them. (And, as it happens, hydraulic pipes could also be made into a universal classical computer, and so could gears and levers, as Babbage showed.) Ironically, Lady Lovelace’s objection has almost the same logic as Douglas Hofstadter’s argument for reductionism (Chapter 5) – yet Hofstadter is one of today’s foremost proponents of the possibility of AI. That is because both of them share the mistaken premise that low-level computational steps cannot possibly add up to a higher-level ‘I’ that affects anything. The difference between them is that they chose opposite horns of the dilemma that that poses: Lovelace chose the false conclusion that AI is impossible, while Hofstadter chose the false conclusion that no such ‘I’ can exist. Because of Babbage’s failure either to build a universal computer or 138 The Jump to Universality to persuade others to do so, an entire century would pass before the first one was built. During that time, what happened was more like the ancient history of universality: although calculating machines similar to the Difference Engine were being built by others even before Babbage had given up, the Analytical Engine was almost entirely ignored even by mathematicians. In 1936 Turing developed the definitive theory of universal classical computers. His motivation was not to build such a computer, but only to use the theory abstractly to study the nature of mathematical proof. And when the first universal computers were built, a few years later, it was, again, not out of any special intention to implement universality. They were built in Britain and the United States during the Second World War for specific wartime applications. The British computers, named Colossus (in which Turing was involved), were used for code- breaking; the American one, ENIAC, was designed to solve the equations needed for aiming large guns. The technology used in both was elec- tronic vacuum tubes, which acted like relays but about a hundred times as fast. At the same time, in Germany, the engineer Konrad Zuse was building a programmable calculator out of relays – just as Babbage should have done. All three of these devices had the technological features necessary to be a universal computer, but none of them was quite configured for this. In the event, the Colossus machines never did anything but code-breaking, and most were dismantled after the war. Zuse’s machine was destroyed by Allied bombing. But ENIAC was allowed to jump to universality: after the war it was put to diverse uses for which it had never been designed, such as weather forecasting and the hydrogen-bomb project. The history of electronic technology since the Second World War has been dominated by miniaturization, with ever more microscopic switches being implemented in each new device. These improve- ments led to a jump to universality in about 1970, when several companies independently produced a microprocessor, a universal classical com puter on a single silicon chip. From then on, designers of any information-processing device could start with a microprocessor and then customize it – program it – to perform the specific tasks needed for that device. Today, your washing machine is almost certainly controlled by a computer that could be programmed to do astrophysics 139 the beginning of infinity or word processing instead, if it were given suitable input–output devices and enough memory to hold the necessary data. It is a remarkable fact that, in that sense (that is to say, ignoring issues of speed, memory capacity and input–output devices), the human ‘computers’ of old, the steam-powered Analytical Engine with its literal bells and whistles, the room-sized vacuum-tube computers of the Second World War, and present-day supercomputers all have an identical repertoire of computations. Another thing that they have in common is that they are all digital: they operate on information in the form of discrete values of physical variables, such as electronic switches being on or off, or cogs being at one of ten positions. The alternative, ‘analogue’, computers, such as slide rules, which represent information as continuous physical variables, were once ubiquitous but are hardly ever used today. That is because a modern digital computer can be programmed to imitate any of them, and to outperform them in almost any application. The jump to universality in digital computers has left analogue computation behind. That was inevitable, because there is no such thing as a universal analogue computer. That is because of the need for error correction: during lengthy computations, the accumulation of errors due to things like imperfectly constructed components, thermal
================================================================================even aside from the philosophical enormity of reducing science to a collection of statements about human experiences, does not make sense in its own terms. For there is no such thing as a purely predictive, explanationless theory. One cannot make even the simplest prediction without invoking quite a sophisticated explanatory framework. For example, those predictions about conjuring tricks apply specifically to conjuring tricks. That is explanatory information, and it tells me, among other things, not to ‘extrapolate’ the predictions to another type of situation, however successful they are at predicting 15 the beginning of infinity conjuring tricks. So I know not to predict that saws in general are harmless to humans; and I continue to predict that if I were to place a ball under a cup, it really would go there and stay there. The concept of a conjuring trick, and of the distinction between it and other situations, is familiar and unproblematic – so much so that it is easy to forget that it depends on substantive explanatory theories about all sorts of things such as how our senses work, how solid matter and light behave, and also subtle cultural details. Knowledge that is both familiar and uncontroversial is background knowledge. A predictive theory whose explanatory content consists only of back ground know- ledge is a rule of thumb. Because we usually take background knowledge for granted, rules of thumb may seem to be explanationless predictions, but that is always an illusion. There is always an explanation, whether we know it or not, for why a rule of thumb works. Denying that some regularity in nature has an explanation is effectively the same as believing in the supernatural – saying, ‘That’s not conjuring, it’s actual magic.’ Also, there is always an explanation when a rule of thumb fails, for rules of thumb are always parochial: they hold only in a narrow range of familiar circum- stances. So, if an unfamiliar feature were introduced into a cups- and-balls trick, the rule of thumb I stated might easily make a false prediction. For instance, I could not tell from the rule of thumb whether it would be possible to perform the trick with lighted candles instead of balls. If I had an explanation of how the trick worked, I could tell. Explanations are also essential for arriving at a rule of thumb in the first place: I could not have guessed those predictions about conjuring tricks without having a great deal of explanatory information in mind – even before any specific explanation of how the trick works. For instance, it is only in the light of explanations that I could have abstracted the concept of cups and balls from my experience of the trick, rather than, say, red and blue, even if it so happened that the cups were red and the balls blue in every instance of the trick that I had witnessed. The essence of experimental testing is that there are at least two apparently viable theories known about the issue in question, making conflicting predictions that can be distinguished by the experiment. Just as conflicting predictions are the occasion for experiment and 16 The Reach of Explanations observation, so conflicting ideas in a broader sense are the occasion for all rational thought and inquiry. For example, if we are simply curious about something, it means that we believe that our existing ideas do not adequately capture or explain it. So, we have some criterion that our best existing explanation fails to meet. The criterion and the existing explanation are conflicting ideas. I shall call a situation in which we experience conflicting ideas a problem. The example of a conjuring trick illustrates how observations provide problems for science – dependent, as always, on prior explanatory theories. For a conjuring trick is a trick only if it makes us think that something happened that cannot happen. Both halves of that proposition depend on our bringing quite a rich set of explanatory theories to the experience. That is why a trick that mystifies an adult may be uninterest- ing to a young child who has not yet learned to have the expectations on which the trick relies. Even those members of the audience who are incurious about how the trick works can detect that it is a trick only because of the explanatory theories that they brought with them into the auditorium. Solving a problem means creating an explanation that does not have the conflict. Similarly, no one would have wondered what stars are if there had not been existing expectations – explanations – that unsupported things fall, and that lights need fuel, which runs out, and so on, which con- flicted with interpretations (which are also explanations) of what was seen, such as that the stars shine constantly and do not fall. In this case it was those interpretations that were false: stars are indeed in free fall and do need fuel. But it took a great deal of conjecture, criticism and testing to discover how that can be. A problem can also arise purely theoretically, without any obser- vations. For instance, there is a problem when a theory makes a prediction that we did not expect. Expectations are theories too. Similarly, it is a problem when the way things are (according to our best explanation) is not the way they should be – that is, according to our current criterion of how they should be. This covers the whole range of ordinary meanings of the word ‘problem’, from unpleasant, as when the Apollo 13 mission reported, ‘Houston, we’ve had a problem here,’ to pleasant, as when Popper wrote: 17 the beginning of infinity I think that there is only one way to science – or to philosophy, for that matter: to meet a problem, to see its beauty and fall in love with it; to get married to it and to live with it happily, till death do ye part – unless you should meet another and even
================================================================================need. The knowledge that currently sustains human life in Oxfordshire does so only in the first sense: it does not make us enact the same, traditional way of life in every generation. In fact it prevents us from doing so. For comparison: if your way of life merely makes you build a new, giant statue, you can continue to live afterwards exactly as you did before. That is sustainable. But if your way of life leads you to invent a more efficient method of farming, and to cure a disease that has been killing many children, that is unsustainable. The population grows because children who would have died survive; meanwhile, fewer of them are needed to work in the fields. And so there is no way to continue as before. You have to live the solution, and to set about solving the new problems that this creates. It is because of this unsus- tainability that the island of Britain, with a far less hospitable climate than the subtropical Easter Island, now hosts a civilization with at least three times the population density that Easter Island had at its zenith, and at an enormously higher standard of living. Appropriately enough, this civilization has knowledge of how to live well without the forests that once covered much of Britain. The Easter Islanders’ culture sustained them in both senses. This is the hallmark of a functioning static society. It provided them with a way of life; but it also inhibited change: it sustained their determination to enact and re-enact the same behaviours for generations. It sustained the values that placed forests – literally – beneath statues. And it sustained the shapes of those statues, and the pointless project of building ever more of them. Moreover, the portion of the culture that sustained them in the sense of providing for their needs was not especially impressive. Other Stone Age societies have managed to take fish from the sea and sow crops without wasting their efforts in endless monument-building. And, if the prevailing theory is true, the Easter Islanders started to starve before the fall of their civilization. In other words, even after it had stopped providing for them, it retained its fatal proficiency at sustaining a fixed pattern of behaviour. And so it remained effective at preventing them from addressing the problem by the only means that could possibly have been effective: 422 Unsustainable creative thought and innovation. Attenborough regards the culture as having been very valuable and its fall as a tragedy. Bronowski’s view was closer to mine, which is that since the culture never improved, its survival for many centuries was a tragedy, like that of all static societies. Attenborough is not alone in drawing frightening lessons from the history of Easter Island. It has become a widely adduced version of the Spaceship Earth metaphor. But what exactly is the analogy behind the lesson? The idea that civilization depends on good forest manage- ment has little reach. But the broader interpretation, that survival depends on good resource management, has almost no content: any physical object can be deemed a ‘resource’. And, since problems are soluble, all disasters are caused by ‘poor resource management’. The ancient Roman ruler Julius Caesar was stabbed to death, so one could sum marize his mistake as ‘imprudent iron management, resulting in an excessive build-up of iron in his body’. It is true that if he had succeeded in keeping iron away from his body he would not have died in the (exact) way he did, yet, as an explanation of how and why he died, that ludicrously misses the point. The interesting question is not what he was stabbed with, but how it came about that other politicians plotted to remove him violently from office and that they succeeded. A Popperian analysis would focus on the fact that Caesar had taken vigorous steps to ensure that he could not be removed without violence. And then on the fact that his removal did not rectify, but actually entrenched, this progress-suppressing innovation. To under stand such events and their wider significance, one has to understand the politics of the situation, the psychology, the philosophy, sometimes the theology. Not the cutlery. The Easter Islanders may or may not have suffered a forest-management fiasco. But, if they did, the ex planation would not be about why they made mistakes – problems are inevitable – but why they failed to correct them. I have argued that the laws of nature cannot possibly impose any bound on progress: by the argument of Chapters 1 and 3, denying this is tantamount to invoking the supernatural. In other words, progress is sustainable, indefinitely. But only by people who engage in a particular kind of thinking and behaviour – the problem-solving and problem- creating kind characteristic of the Enlightenment. And that requires the optimism of a dynamic society. 423 the beginning of infinity One of the consequences of optimism is that one expects to learn from failure – one’s own and others’. But the idea that our civilization has something to learn from the Easter Islanders’ alleged forestry failure is not derived from any structural resemblance between our situation and theirs. For they failed to make progress in practically every area. No one expects the Easter Islanders’ failures in, say, medicine to explain our difficulties in curing cancer, or their failure to understand the night sky to explain why a quantum theory of gravity is elusive to us. The Easter Islanders’ errors, both methodological and substantive, were simply too elementary to be relevant to us, and their imprudent forestry, if that is really what destroyed their civilization, would merely be typical of their lack of problem-solving ability across the board. We should do much better to study their many small successes than their entirely commonplace failures. If we could discover their rules of thumb (such as ‘stone mulching’ to help grow crops on poor soil), we might find valuable fragments of historical and ethnological knowledge, or
================================================================================‘dark matter’ (see the next chapter) really exists – and it succeeded. If Edison, or those graduate students, or any scientific researcher engaged upon the ‘perspiration’ 36 Closer to Reality phase of discovery, had really been doing it mindlessly, they would be missing most of the fun – which is also what largely powers that ‘one per cent inspiration’. As I reached one particularly ambiguous image I asked my hosts, ‘Is that a galaxy or a star?’ ‘Neither,’ was the reply. ‘That’s just a defect in the photographic emulsion.’ The drastic mental gear change made me laugh. My grandiose speculations about the deep meaning of what I was seeing had turned out to be, in regard to this particular object, about nothing at all: suddenly there were no astronomers in that image, no rivers or earthquakes. They had disappeared in a puff of imagination. I had overestimated the mass of what I was looking at by some fifty powers of ten. What I had taken to be the largest object I had ever seen, and the most distant in space and time, was in reality just a speck barely visible without a microscope, within arm’s reach. How easily, and how thoroughly, one can be misled. But wait. Was I ever looking at a galaxy? All the other blobs were in fact microscopic smudges of silver too. If I misclassified the cause of one of them, because it looked too like the others, why was that such a big error? Because an error in experimental science is a mistake about the cause of something. Like an accurate observation, it is a matter of theory. Very little in nature is detectable by unaided human senses. Most of what happens is too fast or too slow, too big or too small, or too remote, or hidden behind opaque barriers, or operates on principles too differ- ent from anything that influenced our evolution. But in some cases we can arrange for such phenomena to become perceptible, via scientific instruments. We experience such instruments as bringing us closer to the reality – just as I felt while looking at that galactic cluster. But in purely physical terms they only ever separate us further from it. I could have looked up at the night sky in the direction of that cluster, and there would have been nothing between it and my eye but a few grams of air – but I would have seen nothing at all. I could have interposed a telescope, and then I might have seen it. In the event, I was interposing a telescope, a camera, a photographic development laboratory, another camera (to 37 the beginning of infinity make copies of the plates), a truck to bring the plates to my university, and a microscope. I could see the cluster far better with all that equipment in the way. Astronomers nowadays never look up at the sky (except perhaps in their spare time), and hardly ever look through telescopes. Many telescopes do not even have eyepieces suitable for a human eye. Many do not even detect visible light. Instead, instruments detect invisible signals which are then digitized, recorded, combined with others, and processed and analysed by computers. As a result, images may be produced – perhaps in ‘false colours’ to indicate radio waves or other radiation, or to display still more indirectly inferred attributes such as temperature or composition. In many cases, no image of the distant object is ever produced, only lists of numbers, or graphs and diagrams, and only the outcome of those processes affects the astronomers’ senses. Every additional layer of physical separation requires further levels of theory to relate the resulting perceptions to reality. When the astron- omer Jocelyn Bell discovered pulsars (extremely dense stars that emit regular bursts of radio waves), this is what she was looking at: Radio-telescope output from the first known pulsar Only through a sophisticated chain of theoretical interpretation could she ‘see’, by looking at that shaky line of ink on paper, a powerful, pulsating object in deep space, and recognize that it was of a hitherto unknown type. The better we come to understand phenomena remote from our everyday experience, the longer those chains of interpretation become, and every additional link necessitates more theory. A single unexpected 38 Closer to Reality or misunderstood phenomenon anywhere in the chain can, and often does, render the resulting sensory experience arbitrarily misleading. Yet, over time, the conclusions that science has drawn have become ever truer to reality. Its quest for good explanations corrects the errors, allows for the biases and misleading perspectives, and fills in the gaps. This is what we can achieve when, as Feynman said, we keep learning more about how not to fool ourselves. Telescopes contain automatic tracking mechanisms that continuously realign them so as to compensate for the effect of the Earth’s motion; in some, computers continuously change the shape of the mirror so as to compensate for the shimmering of the Earth’s atmosphere. And so, observed through such a telescope, stars do not appear to twinkle or to move across the sky as they did to generations of observers in the past. Those things are only appearance – parochial error. They have nothing to do with the reality of stars. The primary function of the telescope’s optics is to reduce the illusion that the stars are few, faint, twinkling and moving. The same is true of every feature of the telescope, and of all other scientific instruments: each layer of indirectness, through its associated theory, corrects errors, illusions, misleading perspectives and gaps. Perhaps it is the mistaken empiricist ideal of ‘pure’, theory-free observation that makes it seem odd that truly accurate observation is always so hugely indirect. But the fact is that progress requires the application of ever more knowledge in advance of our observations. So I was indeed looking at galaxies. Observing a galaxy via specks of silver is no different in that regard from observing a garden via
================================================================================make the cell cancerous. Some non-negligible pro - portion of all cancers are caused in this way. As a result, there exist histories in which any given person, alive in our history at any time, is killed soon afterwards by cancer. There exist other histories in which the course of a battle, or a war, is changed by such an event, or by a lightning bolt at exactly the right place and time, or by any of countless other unlikely, ‘random’ events. This makes it highly plausible that there exist histories in which events have played out more or less as in alternative-history stories such as Fatherland and Roma Eterna – or in which events in your own life played out very differently, for better or worse. A great deal of fiction is therefore close to a fact somewhere in the multiverse. But not all fiction. For instance, there are no histories in which my stories of the transporter malfunction are true, because they require different laws of physics. Nor are there histories in which the fundamental constants of nature such as the speed of light or the charge on an electron are different. There is, however, a sense in which different laws of physics appear to be true for a period in some histories, because of a sequence of ‘unlikely accidents’. (There may also be universes in which there are different laws of physics, as required in anthropic explanations of fine-tuning. But as yet there is no viable theory of such a multiverse.) Imagine a single photon from a starship’s communication laser, heading towards Earth. Like the cosmic ray, it arrives all over the surface, in different histories. In each history, only one atom will absorb the photon and the rest will initially be completely unaffected. A receiver for such communications would then detect the relatively large, discrete change undergone by such an atom. An important consequence for the construction of measuring devices (including eyes) is that no matter 294 The Multiverse how far away the source is, the kick given to an atom by an arriving photon is always the same: it is just that the weaker the signal is, the fewer kicks there are. If this were not so – for instance, if classical physics were true – weak signals would be much more easily swamped by random local noise. This is the same as the advantage of digital over analogue information processing that I discussed in Chapter 6. Some of my own research in physics has been concerned with the theory of quantum computers. These are computers in which the information-carrying variables have been protected by a variety of means from becoming entangled with their surroundings. This allows a new mode of computation in which the flow of information is not confined to a single history. In one type of quantum computation, enormous numbers of different computations, taking place simul- taneously, can affect each other and hence contribute to the output of a computation. This is known as quantum parallelism. In a typical quantum computation, individual bits of information are represented in physical objects known as ‘qubits’ – quantum bits – of which there is a large variety of physical implementations but always with two essential features. First, each qubit has a variable that can take one of two discrete values, and, second, special measures are taken to protect the qubits from entanglement – such as cooling them to temperatures close to absolute zero. A typical algorithm using quantum parallelism begins by causing the information-carrying variables in some of the qubits to acquire both their values simultaneously. Con s equently, regarding those qubits as a register representing (say) a number, the number of separate instances of the register as a whole is exponentially large: two to the power of the number of qubits. Then, for a period, classical computations are performed, during which waves of differentiation spread to some of the other qubits – but no further, because of the special measures that prevent this. Hence, information is processed separately in each of that vast number of autonomous histories. Finally, an interference process involving all the affected qubits combines the information in those histories into a single history. Because of the intervening computation, which has processed the information, the final state is not the same as the initial one, as in the simple inter- ference experiment I discussed above, namely , but is some function of it, like this: 295 the beginning of infinity Y 1 X f(X) A typical quantum computation. Y . . . Y are intermediate results that 1 many depend on the input X. All of them are needed to compute the output f (X) efficiently. Just as the starship crew members could achieve the effect of large amounts of computation by sharing information with their doppel- gängers computing the same function on different inputs, so an algorithm that makes use of quantum parallelism does the same. But, while the fictional effect is limited only by starship regulations that we may invent to suit the plot, quantum computers are limited by the laws of physics that govern quantum interference. Only certain types of parallel computation can be performed with the help of the multiverse in this way. They are the ones for which the mathematics of quantum interference happens to be just right for combining into a single history the information that is needed for the final result. In such computations, a quantum computer with only a few hundred qubits could perform far more computations in parallel than there are atoms in the visible universe. At the time of writing, quantum computers with about ten qubits have been constructed. ‘Scaling’ the technology to larger numbers is a tremendous challenge for quantum technology, but it is gradually being met. I mentioned above that, when a large object is affected by a small influence, the usual outcome is that the large object is strictly unaffected. I can now explain why. For example, in the
================================================================================always that it got itself replicated more than its rival genes. Non-explanatory human knowledge can also evolve in an analogous way: rules of thumb are not passed on perfectly to the next generation of users, and the ones that survive in the long run are not necessarily the ones that optimize the ostensible function. For instance, a rule that is expressed in an elegant rhyme may be remembered, and repeated, better than one that is more accurate but expressed in ungainly prose. Also, no human knowledge is entirely non-explanatory. There is always at least a background of assumptions about reality against which the meaning of a rule of thumb is understood, and that background can make some false rules of thumb seem plausible. Explanatory theories evolve through a more complicated mechanism. Accidental errors in transmission and memory still play a role, but a much smaller one. That is because good explanations are hard to vary even without being tested, and hence random errors in the transmission of a good explanation are easier for the receiver to detect and correct. The most important source of variation in explanatory theories is creativity. For instance, when people are trying to understand an idea that they hear from others, they typically understand it to mean what makes most sense to them, or what they are most expecting to hear, or what they fear to hear, and so on. Those meanings are conjectured by the listener or reader, and may differ from what the speaker or writer intended. In addition, people often try to improve explanations even when they have received them accurately: they make creative amendments, spurred by their own criticism. If they then pass the explanation on to others, they usually try to pass on what they consider to be the improved version. Unlike genes, many memes take different physical forms every time they are replicated. People rarely express ideas in exactly the same words in which they heard them. They also translate from one language to another, and between spoken and written language, and so on. Yet we rightly call what is transmitted the same idea – the same meme – 94 Creation throughout. Thus, in the case of most memes, the real replicator is abstract: it is the knowledge itself. This is in principle true of genes as well: biotechnology routinely transcribes genes into the memories of computers, where they are stored in a different physical form. Those records could be translated back into DNA strands and implanted in different animals. The only reason this is not yet a common practice is that it is easier to copy the original gene. But one day the genes of a rare species could survive its extinction by causing themselves to be stored on a computer and then implanted into a cell of a different species. I say ‘causing themselves to be stored’ because the biotech- nologists would not be recording information indiscriminately, but only information that met a criterion such as ‘gene of an endangered species’. The ability to interest biotechnologists in this way would then be part of the reach of the knowledge in those genes. So, both human knowledge and biological adaptations are abstract replicators: forms of information which, once they are embodied in a suitable physical system, tend to remain so while most variants of them do not. The fact that the principles of neo-Darwinist theory are, from a certain perspective, self-evident has itself been used as a criticism of the theory. For instance, if the theory must be true, how can it be testable? One reply, often attributed to Haldane, is that the whole theory would be refuted by the discovery of a single fossilized rabbit in a stratum of Cambrian rock. However, that is misleading. The import of such an observation would depend on what explanations were available under the given circumstances. For instance, misidentifications of fossils, and of strata, have sometimes been made and would have to be ruled out by good explanations before one could call the discovery ‘a fossilized rabbit in Cambrian rock’. Even given such explanations, what would have been ruled out by the rabbit would be not the theory of evolution itself, but only the prevailing theory of the history of life and geological processes on Earth. Suppose, for instance, that there was a prehistoric continent, isolated from the others, on which evolution happened several times as fast as elsewhere, and that, by convergent evolution, a rabbit-like creature evolved there during the Cambrian era; and suppose that the continents were later connected by a catastrophe that obliterated most 95 the beginning of infinity of the life forms on that continent and submerged their fossils. The rabbit-like creature was a rare survivor which became extinct soon afterwards. Given the supposed evidence, that is still an infinitely better explanation than, for instance, creationism or Lamarckism, neither of which gives any account of the origin of the apparent knowledge in the rabbit. So what would refute the Darwinian theory of evolution? Evidence which, in the light of the best available explanation, implies that knowledge came into existence in a different way. For instance, if an organism was observed to undergo only (or mainly) favourable mutations, as predicted by Lamarckism or spontaneous generation, then Darwinism’s ‘random variation’ postulate would be refuted. If organisms were observed to be born with new, complex adaptations – for anything – of which there were no precursors in their parents, then the gradual-change prediction would be refuted and so would Darwinism’s mechanism of knowledge-creation. If an organism was born with a complex adaptation that has survival value today, yet was not favoured by selection pressure in its ancestry (say, an ability to detect and use internet weather forecasts to decide when to hibernate), then Darwinism would again be refuted. A fundamentally new ex - planation would be needed. Facing more or less the same unsolved problem that Paley and Darwin faced, we should have to set about finding an explanation that worked.
================================================================================bizarre occurrences and its entanglement information – would collapse into nothing, like the galaxy in Chapter 2 that became an emulsion flaw. The multiverse explanation of the same events would be a bad *That this information is carried entirely locally in objects is currently somewhat controversial. For a detailed technical discussion see the paper ‘Information Flow in Entangled Quantum Systems’ by myself and Patrick Hayden (Proceedings of the Royal Society A456 (2000)). 281 the beginning of infinity explanation, and so the world would be inexplicable to the inhabitants if it were true. It may seem that, by imposing all those conditions on information flow, we have gone to a lot of trouble to achieve that very attribute – to hide, from the inhabitants, the Byzantine intricacies of their world. In the words of Lewis Carroll’s White Knight in Through the Looking Glass, it is as if we were . . . thinking of a plan To dye one’s whiskers green, And always use so large a fan That they could not be seen. Now it is time to start removing the fan. In quantum physics, information flow in the multiverse is not as tame as in that branching tree of histories I have described. That is because of one further quantum phenomenon: under certain circum- stances, the laws of motion allow histories to rejoin (becoming fungible again). This is the time-reverse of the splitting (differentiation of history into two or more histories) that I have already described, so a natural way to implement it in our fictional multiverse is for the transporter to be capable of undoing its own history-splitting. If we represent the original splitting like this (cid:3514) X X Y where X is the normal voltage and Y is the anomalous one introduced by the transporter, then the rejoining of histories can be represented as X inter(cid:3514)ference X Y In an interference phenomenon, differentiated histories rejoin. 282 The Multiverse This phenomenon is known as interference: the presence of the Y-history interferes with what the transporter usually does to an X-history. Instead, the X and Y histories merge. This is rather like the doppelgängers merging with their originals in some phantom-zone stories, except that here we do not need to repeal the principle of the conservation of mass or any other conservation law: the total measure of all the histories remains constant. Interference is the phenomenon that can provide the inhabitants of the multiverse with evidence of the existence of multiple histories in their world without allowing the histories to communicate. For example, suppose that they run the transporter twice in quick succession (I shall explain in a moment what ‘quick’ means): (cid:3514) X (cid:3514) X X Y An interference experiment If they did this repeatedly (with, say, different copies of the transporter on each occasion), they could soon infer that the intermediate result could not be just randomly X or Y, because if it were then the final outcome would sometimes be Y (because of ), while in fact it is always X. Thus the inhabitants would no longer be able to explain away what they see by assuming that only one, randomly chosen, value of the voltage is real at the intermediate stage. Although such an experiment would provide evidence that multiple histories not only exist but affect each other strongly (in the sense that they behave differently according to whether the other is present or absent), it does not involve inter-history communication (sending a message of one’s choice to the other history). In our story, just as we did not allow splitting to happen in a way that would allow communication faster than light, so we must ensure the same for interference. The simplest way is to require that the rejoining take place only if no wave of differentiation has happened. That is to say, the transporter can undo the voltage surge only if this has not yet caused any differential effects on anything else. When a 283 the beginning of infinity wave of differentiation, set off by two different values X and Y of some variable, has left an object, the object is entangled with all the differentially affected objects. Object Rest of world Object Rest of world X Not differentially (cid:3450) X Affected by X Y affected by X and Y Y Affected (differently) by Y not entangled entangled Entanglement So our rule, in short, is that interference can happen only in objects that are unentangled with the rest of the world. This is why, in the interference experiment, the two applications of the transporter have to be ‘in quick succession’. (Alternatively, the object in question has to be sufficiently well isolated for its voltages not to affect its surround- ings.) So we can represent a generic interference experiment symbolically as follows: Object Object Rest of world Rest of sp(cid:3514)litting X Not differentially X world Y affected by X and Y interference (cid:3515) Not differentially X affected by X and Y If an object is unentangled, it can be made to undergo interference by something acting on it alone. (The arrows ‘ ’ and ‘(cid:2)’ represent the action of the transporter.) Once the object is entangled with the rest of the world in regard to the values X and Y, no operation on the object alone can create interference between those values. Instead, the histories are merely split further, in the usual way: 284 The Multiverse ObjectRest of world Object Rest of world Object Rest of world X Unaffected sp(cid:3514)litting X Y afN feo ct t ed dif f be yre Xn t aia nl dly Y entan(cid:3450)glement X Y AffecteA df f (e dc it fe fed r eb ny t lX y) by Y no interference, just splitting (cid:3515) Rest of world X Affected by X Y Y X Affected (differently) by Y In entangled objects, further splitting happens instead of interference. When two or more values of a physical variable have differently affected something in the rest of the world, knock-on
================================================================================The mathematician Pierre Simon Laplace (1749–1827) wrote, of the Indian system, ‘We shall appreciate the grandeur of this achievement when we remember that it escaped the genius of Archimedes and Apollonius, two of the greatest minds produced by antiquity.’ But was this really something that escaped them, or something that they chose to steer clear of? Archimedes must have been aware that his method of extending a number system – which he used twice in succession – could be continued indefinitely. But perhaps he doubted that the result- ing numerals would refer to anything about which one could validly reason. Indeed, one motivation for that whole project was to contradict the idea – which was a truism at the time – that the grains of sand on a beach could literally not be numbered. So he used his system to calculate the number of grains of sand that would be needed to fill the entire celestial sphere. This suggests that he, and ancient Greek culture in general, may not have had the concept of an abstract number at all, so that, for them, numerals could refer only to objects – if only objects of the imagination. In that case universality would have been a difficult property to grasp, let alone to aspire to. Or maybe he merely felt that he had to avoid aspiring to infinite reach in order to make a convincing case. At any rate, although from our perspective Archimedes’ system repeatedly ‘tried’ to jump to universality, he apparently did not want it to. Here is an even more speculative possibility. The largest benefits of any universality, beyond whatever parochial problem it is intended to solve, come from its being useful for further innovation. And innovation is unpredictable. So, to appreciate universality at the time of its dis - covery, one must either value abstract knowledge for its own sake or expect it to yield unforeseeable benefits. In a society that rarely ex - perienced change, both those attitudes would be quite unnatural. But that was reversed with the Enlightenment, whose quintessential idea is, as I have said, that progress is both desirable and attainable. And so, therefore, is universality. Be that as it may, with the Enlightenment, parochialism and all arbitrary exceptions and limitations began to be regarded as inherently 133 the beginning of infinity problematic – and not only in science. Why should the law treat an aristocrat differently from a commoner? A slave from a master? A woman from a man? Enlightenment philosophers such as Locke set out to free political institutions from arbitrary rules and assumptions. Others tried to derive moral maxims from universal moral explanations rather than merely to postulate them dogmatically. Thus universal explanatory theories of justice, legitimacy and morality began to take their place alongside universal theories of matter and motion. In all those cases, universality was being sought deliberately, as a desirable feature in its own right – even a necessary feature for an idea to be true – and not just as a means of solving a parochial problem. A jump to universality that played an important role in the early history of the Enlightenment was the invention of movable-type printing. Movable type consisted of individual pieces of metal, each embossed with one letter of the alphabet. Earlier forms of printing had merely streamlined writing in the same way that Roman numerals streamlined tallying: each page was engraved on a printing plate and thus all the symbols on it could be copied in a single action. But, given a supply of movable type with several instances of each letter, one does no further metalwork. One merely arranges the type into words and sentences. One does not have to know, in order to manufacture type, what the documents that it will eventually print are going to say: it is universal. Even so, movable type did not make much difference when it was invented in China in the eleventh century, perhaps because of the usual lack of interest in universality, or perhaps because the Chinese writing system used thousands of pictograms, which diminished the immediate advantages of a universal printing system. But when it was reinvented by the printer Johannes Gutenberg in Europe in the fifteenth century, using alphabetic type, it initiated an avalanche of further progress. Here we see a transition that is typical of the jump to universality: before the jump, one has to make specialized objects for each document to be printed; after the jump, one customizes (or specializes, or pro - grams) a universal object – in this case a printing press with movable type. Similarly, in 1801 Joseph Marie Jacquard invented a general- purpose silk-weaving machine now known as the Jacquard loom. Instead of having to control manually each row of stitches in each 134 The Jump to Universality individual bolt of patterned silk, one could program an arbitrary pattern on punched cards which would instruct the machine to weave that pattern any number of times. The most momentous such technology is that of computers, on which an increasing proportion of all technology now depends, and which also has deep theoretical and philosophical significance. The jump to computational universality should have happened in the 1820s, when the mathematician Charles Babbage designed a device that he called the Difference Engine – a mechanical calculator which represented decimal digits by cogs, each of which could click into one of ten positions. His original purpose was parochial: to automate the pro - duction of tables of mathematical functions such as logarithms and cosines, which were heavily used in navigation and engineering. At the time, they were compiled by armies of clerks known as ‘computers’ (which is the origin of the word), and were notoriously error-prone. The Difference Engine would make fewer errors, because the rules of arithmetic would be built into its hardware. To make it print out a table of a given function, one would program it only once with the definition of the function in terms of
================================================================================148–63 authority chatbots and 150, 152, 158, 160 the Enlightenment’s rebellion against and creativity 148–63 12–13, 22–3, 32–3, 65 Elbot program 151–2, 156 and knowledge 4, 8–13, 22–3, 123, Eliza program 148–9, 161 209, 227, 310, 311, 314, 356, 391, and humour 157 395 and the simulation argument 455 see also justificationism and the Singularity 456–7 automation 36, 39, 57–8, 62, 76, 135–6, Turing test 148, 149–50, 151, 152–3, 141, 158, 160, 320, 438, 456 154–6, 158, 161, 320 axis-tilt theory 23–5, 26–8, 44, 68, The Ascent of Man 419, 440–441, 460 458 464 index Babbage, Charles 135, 136, 137, 139, biotechnology 95, 196 148 see also biological weapons Babylonian numerals 131 birds background knowledge 16 and music 356 Bacon, Roger 220 nesting 89–91, 145 bacteria 82, 145, 162, 436 reach and evolution of adaptations Balinski, Michel 334 54–5 Balinski and Young’s theorem 334, see also parrots 339 bits (information) 187 Basalla, George 394 Black Death 208, 385, 437 ‘bat, what is it like to be a’ (Nagel) 367 black holes 2, 3, 173, 178, 203 Bateson, Patrick 320, 321 Blackmore, Susan 394–5, 402, 404, 415 Bear, Greg 202–3 blind spot 80 beauty Bohm, David 310 and attraction 357–9, 360–65 Bohr, Neils 308 and elegance 355 Boltzmann, Ludwig 255, 312 objectivity of 122, 353–68 Book of Nature 4 truth and 355 Bostrom, Nick 453 two kinds of 364, 365 Botticelli, Sandro 219 ‘because I say so’ 311, 391–2, 395 Bradshaw, Elizabeth 320 see also memes, anti-rational; brains 78, 379, 415 quantum theory: shut-up-and- adaptation, and knowledge in human calculate interpretation brains 78–9, 95, 105–6 Beethoven, Ludwig van 355, 356 add-ons 456, 457 beginning of infinity, introductory and the doomsday argument 455–6 explanation of concept vii–viii; encoding of knowledge in 50, 375–7 see also 443 evolutionary process of creativity in behaviour parsing 407–9 373 behaviourism 157–8, 163, 316–20 the human brain and scientific Bell, Jocelyn 38 knowledge 72, 189 Big Bang 3, 6, 11, 96, 175, 197, and the understanding of abstractions 450–51 119 afterglow (microwave radiation) 46, British Enlightenment see Enlightenment: 47, 68 British in a parallel universe 263 Bronowski, Jacob 121, 355, 419–20, Big Crunch 450–51 423, 441, 460 biogeography 426–42 Byrne, Richard 407, 460 biological weapons 196, 204, 205 biosphere 44–5, 48–51, 69–70 Caesar, Julius 423 automated environmental calculus 164, 194 transformation 57–9 calendars 7 environmental control and the human cancer 294, 437 reach 57–63 Cantor, Georg 166, 170–71, 181, 182, environments and knowledge 74–5 195 evolution and the biosphere–culture carbon-dioxide emissions 437–41 analogy 371–2 Carroll, Lewis: Through the Looking and fine-tuning of the laws of physics Glass 282 97 Carter, Brandon 96 global warming and climate change catalysts 143 437–41 cathode-ray tubes 433–5 and the problem of suffering/evil 80 causation 118, 300–301, 428 see also ecosystems celestial sphere theory 8, 10, 112, 133 465 index cells 39–40, 58, 95, 294, 372, 376, 384, common sense 266 393 mistaken 5, 26, 82, 122, 262, 279, single- and multicellular organisms 280, 340, 397, 403 144 see also reason certainty see fallibility complementarity, principle of 308–9 Chaerephon, and ‘a dream of Socrates’ complexity see simplicity and complexity 243–9, 251, 252, 253 computer programs 36, 115–18, 129, chains 414 of interpretation 38–9 AI see artificial intelligence of proxies 72, 317 chess 114, 118, 157 of instantiations of abstractions evolutionary algorithms 160 114–15, 256 and the simulation argument 453–5 of universes 179 computers/computation 36, 60, 95, 107, chatbots 150, 152, 158, 160 119, 194 chemistry 13, 43, 46, 57–8, 61–2, 67, analogue 140 73, 96–7, 142–3, 261, 301–2, 359, Analytical Engine 136–8, 139, 140 362, 425 Colossus 139 humans as chemical scum 44–8, 51, coloured displays 434 72, 73 computational universality 135–42, chess 36, 114, 118, 136, 157 189, 191 choice 326–52 computer science and mathematical apportionment paradoxes 326–33 proof 184 decision-making and social choice see connection between physics and decision-making computation 189–92 devising an electoral system 338–40 Difference Engine 135–6 social-choice theory 335, 337–8, DNA computer 145 342–3, 345, 352; applied to an ENIAC 139 individual mind 340–41 Hofstadter’s domino computer 115– voters’ 342 17, 118 cholera 207 and physics 187, 189–92, 295–6 Churchill, Winston 201, 333 programs see computer programs cimenti 14 quantum computation 187, 295–6 civilization and the silicon chip 139 Athenian 216–18, 224–5, 229–33, and the simulation argument 453–5 244–51, 246 supercomputer simulation predictions of Easter Island 418, 419–23, 439 430–31 Conan Doyle, Arthur 10 extra-terrestrial civilizations 202–4 Condorcet, Nicolas de 66 Florentine 218–20 configurational entities 266–7 optimism and 208–22 conformity 7, 217, 218, 231, 382, 402, pessimism and 196–203 413 Polynesian 419, 421, 427 Congress, US, apportionment 326–33 present and pre-Enlightenment 204 conjecture 2, 9, 10, 17, 26, 78, 239–40 Spartan 218, 230–33, 244–51 and abstractions 119 survival 62–3, 196–7, 202, 204–5, creative 412 206–8 and criticism 192, 239–40, 412; see vulnerability of 201, 202–3, 207–8, also criticism 436; see also disasters, natural mathematical 185–6, 191–3 see also societies memes as conjectural explanations 412 climate change 437–41 conjuring tricks 10, 14–16, 17, 18–19, Cold War 196, 205, 428 29, 41, 79, 82, 113, 155, 214, 315, Colossus computers 139 324, 410 466 index and measurement 40, 229 causing convergence 350 visions, perception and 229, 241–2 creationism and 79–81, 104 consciousness 153–4, 157, 162–3, 318, about environments 74–5 415 and error correction 140–2, 147, 271, test for judging claims to have 302 understood 154 ex nihilo 104, 345 consent 155, 266, 343 fine-tuning of the universe and 96– conspicuous consumption 433 103, 104, 106 constants of nature see physics, constants as a transition process from problems of to better problems 446–7 Constitution, US 335 Lamarckism and 87–9 and apportionment paradoxes 326– and the limitation on predictability 33 104, 193, 197–8, 212 constructors, universal 58–60, 62, 76, neo-Darwinism and 89–96 429 not affected by distance 275, 427 Continental Enlightenment 65–6, 313 open-ended/unbounded vii, 60–65, continuum 43, 140–2, 159, 164, 181, 66, 67, 69, 81, 146, 165, 175, 274, 298, 450 450–52 infinity of the 164, 170, 182, 195 optimism and 196–222, 431 control 45, 55–6, 62, 69–71, 88, 111,
================================================================================other staff assigned to their welfare. However, they are not allowed to ask those staff to do their work for them. That is because, if they all did this, the hotel would grind to a halt. Infinity is not magic. It has logical rules: that is the whole point of the Infinity Hotel thought experiment. The fallacious idea of delegating all one’s work to other staff in 173 the beginning of infinity higher-numbered rooms is called an infinite regress. It is one of the things that one cannot validly do with infinity. There is an old joke about the heckler who interrupts an astrophysics lecture to insist that the Earth is flat and supported on the back of elephants standing on a giant turtle. ‘What supports the turtle?’ asks the lecturer. ‘Another turtle.’ ‘What supports that turtle?’ ‘You can’t fool me,’ replies the heckler triumphantly: ‘it’s turtles from there on down.’ That theory is a bad explanation not because it fails to explain everything (no theory does), but because what it leaves unexplained is effectively the same as what it purports to explain in the first place. (The theory that the designer of the biosphere was designed by another designer, and so on ad infinitum, is another example of an infinite regress.) One day in Infinity Hotel, a guest’s pet puppy happens to climb into a trash bag. The owner does not notice, and passes the bag, with the puppy, to the next room. Within two minutes the puppy is nowhere. The distraught owner phones the front desk. The receptionist announces over the public- address system, ‘We apologize for the inconvenience, but an item of value has been inadvertently thrown away. Will all guests please undo all the trash-moving actions that they have just performed, in reverse order, starting as soon as you receive a trash bag from the next-higher-numbered room.’ But to no avail. None of the guests return any bags, because their fellow guests in the higher- numbered rooms are not returning any either. It was no exaggeration to say that the bags are nowhere. They have not been stuffed into a mythical ‘room number infinity’. They no longer exist; nor does the puppy. No one has done anything to the puppy except move it to another numbered room, within the hotel. Yet it is not in any room. It is not anywhere in the hotel, or anywhere else. In a finite hotel, if you move an object from room to room, in however complicated a pattern, it will end up in one of those rooms. Not so with an infinite number of rooms. Every individual action that the guests performed was both harmless to the puppy and 174 A Window on Infinity perfectly reversible. Yet, taken together, those actions annihilated the puppy and cannot be reversed. Reversing them cannot work, because, if it did, there would be no explanation for why a puppy arrived at its owner’s room and not a kitten. If a puppy did arrive, the explanation would have to be that a puppy was passed down from the next-higher-numbered room – and so on. But that whole infinite sequence of explanations never gets round to explaining ‘why a puppy?’ It is an infinite regress. What if, one day, a puppy did just arrive at room 1, having been passed down through all the rooms? That is not logically impossible: it would merely lack an explanation. In physics, the ‘nowhere’ from which such a puppy would have come is called a ‘naked singularity’. Naked singularities appear in some speculative theories in physics, but such theories are rightly criticized on the grounds that they cannot make predictions. As Hawking once put it, ‘Television sets could come out [of a naked singularity].’ It would be different if there were a law of nature determining what comes out – for in that case there would be no infinite regress and the singularity would not be ‘naked’. The Big Bang may have been a singularity of that relatively benign type. I said that the rooms are identical, but they do differ in one respect: their room numbers. So, given the types of tasks that the management request from time to time, the low-numbered rooms are the most desirable. For instance, the guest in room 1 has the unique privilege of never having to deal with anyone else’s trash. Moving to room 1 feels like winning first prize in a lottery. Moving to room 2 feels only slightly less so. But every guest has a room number that is unusually close to the beginning. So every guest in the hotel is more privileged than almost all other guests. The clichéd politician’s promise to favour everyone can be honoured in Infinity Hotel. Every room is at the beginning of infinity. That is one of the attributes of the unbounded growth of knowledge too: we are only just scratching the surface, and shall never be doing anything else. So there is no such thing as a typical room number at Infinity Hotel. Every room number is untypically close to the beginning. The intuitive idea that there must be ‘typical’ or ‘average’ members of any set of values is false for infinite sets. The same is true of the intuitive ideas of ‘rare’ and ‘common’. We might think that half of all natural numbers 175 the beginning of infinity are odd, and half even – so that odd and even numbers are equally common among the natural numbers. But consider the following rearrangement: 1 2 4 3 6 8 5 10 12 7 14 16 … A rearrangement of the natural numbers that makes it look as though one-third of them are odd That makes it look as though the odd numbers are only half as common as even ones. Similarly, we could make it look as though the odd numbers were one in a million or any other proportion. So the intuitive notion of a proportion of the members of a set
================================================================================infinitesimal changes. The ‘beginning of infinity’ – the possibility of the unlimited growth of knowledge in the future – depends on a number of other infinities. One of them is the universality in the laws of nature which allows finite, local symbols to apply to the whole of time and space – and to all phenomena and all possible phenomena. Another is the existence of physical objects that are universal explainers – people – which, it turns out, are necessarily universal constructors as well, and must contain universal classical computers. Most forms of universality themselves refer to some sort of infinity – though they can always be interpreted in terms of something 164 A Window on Infinity being unlimited rather than actually infinite. This is what opponents of infinity call a ‘potential infinity’ rather than a ‘realized’ one. For instance, the beginning of infinity can be described either as a condition where ‘progress in the future will be unbounded’ or as the condition where ‘an infinite amount of progress will be made’. But I use those concepts interchangeably, because in this context there is no substantive difference between them. There is a philosophy of mathematics called finitism, the doctrine that only finite abstract entities exist. So, for instance, there are infinitely many natural numbers, but finitists insist that that is just a manner of speaking. They say that the literal truth is only that there is a finite rule for generating each natural number (or, more precisely, each numeral) from the previous one, and nothing literally infinite is involved. But this doctrine runs into the following problem: is there a largest natural number or not? If there is, then that contradicts the statement that there is a rule that defines a larger one. If there is not, then there are not finitely many natural numbers. Finitists are then obliged to deny a principle of logic: the ‘law of the excluded middle’, which is that, for every meaningful proposition, either it or its negation is true. So finitists say that, although there is no largest number, there is not an infinity of numbers either. Finitism is instrumentalism applied to mathematics: it is a principled rejection of explanation. It attempts to see mathematical entities purely as procedures that mathematicians follow, rules for making marks on paper and so on – useful in some situations, but not referring to anything real other than the finite objects of experience such as two apples or three oranges. And so finitism is inherently anthropocentric – which is not surprising, since it regards parochialism as a virtue of a theory rather than a vice. It also suffers from another fatal flaw that instrumentalism and empiricism have in regard to science, which is that it assumes that mathematicians have some sort of privileged access to finite entities which they do not have for infinite ones. But that is not the case. All observation is theory-laden. All abstract theorizing is theory-laden too. All access to abstract entities, finite or infinite, is via theory, just as for physical entities. In other words finitism, like instrumentalism, is nothing but a project for preventing progress in understanding the entities beyond our direct 165 the beginning of infinity experience. But that means progress generally, for, as I have explained, there are no entities within our ‘direct experience’. The whole of the above discussion assumes the universality of reason. The reach of science has inherent limitations; so does mathematics; so does every branch of philosophy. But if you believe that there are bounds on the domain in which reason is the proper arbiter of ideas, then you believe in unreason or the supernatural. Similarly, if you reject the infinite, you are stuck with the finite, and the finite is parochial. So there is no way of stopping there. The best explanation of anything eventually involves universality, and therefore infinity. The reach of explanations cannot be limited by fiat. One expression of this within mathematics is the principle, first made explicit by the mathematician Georg Cantor in the nineteenth century, that abstract entities may be defined in any desired way out of other entities, so long as the definitions are unambiguous and consistent. Cantor founded the modern mathematical study of infinity. His principle was defended and further generalized in the twentieth century by the mathematician John Conway, who whimsically but appropriately named it the mathematicians’ liberation movement. As those defences suggest, Cantor’s discoveries encountered vitriolic opposition among his contem- poraries, including most mathematicians of the day and also many scientists, philosophers – and theologians. Religious objections, ironically, were in effect based on the Principle of Mediocrity. They characterized attempts to understand and work with infinity as an encroachment on the prerogatives of God. In the mid twentieth century, long after the study of infinity had become a routine part of mathematics and had found countless applications there, the philosopher Ludwig Wittgenstein still contemptuously denounced it as ‘meaningless’. (Though eventually he also applied that accusation to the whole of philosophy, including his own work – see Chapter 12.) I have already mentioned other examples of the principled rejection of infinity. There was the strange aversion of Archimedes, Apollonius and others to universal systems of numerals. There are doctrines such as instrumentalism and finitism. The Principle of Mediocrity sets out to escape parochialism and to reach for infinity, but ends up confining science to an infinitesimal and unrepresentative bubble of compre- hensibility. There is also pessimism, which (as I shall discuss in the 166 A Window on Infinity following chapter) wants to attribute failure to the existence of a finite bound on improvement. One instance of pessimism is the paradoxical parochialism of Spaceship Earth – a vehicle that would be far better suited as a metaphor for infinity. Whenever we refer to infinity, we are making use of the infinite reach of some idea. For whenever an idea of infinity makes sense, that is because there is an explanation of why some finite set of rules for
================================================================================was self-evidently true of nature. Hence he believed that it was impossible rationally to doubt that the angles of a real triangle add up to 180 degrees. And in this way he elevated that formerly harmless misconception into a central flaw in his philosophy, namely the doctrine that certain truths about the physical world could be ‘known a priori’ – that is to say, without doing science. And of course, to make matters worse, by ‘known’ he unfortunately meant ‘justified’. Yet, even before Kant had declared it impossible to doubt that the geometry of real space is Euclidean, mathematicians had already doubted it. Soon afterwards the mathematician and physicist Carl Friedrich Gauss went so far as to measure the angles of a large triangle – but found no deviation from Euclid’s predictions. Eventually Einstein’s theory of curved space and time, which contradicted Euclid’s, was vindicated by experiments that were more accurate than Gauss’s. In the space near the Earth, the angles of a large triangle can add up to as much as 180.0000002 degrees, a variation from Euclid’s geometry 183 the beginning of infinity which, for instance, satellite navigation systems nowadays have to take into account. In other situations – such as near black holes – the differences between Euclidean and Einsteinian geometry are so pro - found that they can no longer be described in terms of ‘deviations’ of one from the other. Another example of the same mistake was in computer science. Turing initially set up the theory of computation not for the purpose of building computers, but to investigate the nature of mathematical proof. Hilbert in 1900 had challenged mathematicians to formulate a rigorous theory of what constitutes a proof, and one of his conditions was that proofs must be finite: they must use only a fixed and finite set of rules of inference; they must start with a finite number of finitely expressed axioms, and they must contain only a finite number of elementary steps – where the steps are themselves finite. Computations, as understood in Turing’s theory, are essentially the same thing as proofs: every valid proof can be converted to a computation that computes the conclusion from the premises, and every correctly exe - cuted computation is a proof that the output is the outcome of the given operations on the input. Now, a computation can also be thought of as computing a function that takes an arbitrary natural number as its input and delivers an output that depends in a particular way on that input. So, for instance, doubling a number is a function. Infinity Hotel typically tells guests to change rooms by specifying a function and telling them all to compute it with different inputs (their room numbers). One of Turing’s conclusions was that almost all mathematical functions that exist logically cannot be computed by any program. They are ‘non-computable’ for the same reason that most logically possible reallocations of rooms in Infinity Hotel cannot be effected by any instruction by the management: the set of all functions is uncountably infinite, while the set of all programs is merely countably infinite. (That is why it is meaningful to say that ‘almost all’ members of the infinite set of all functions have a particular property.) Hence also – as the mathematician Kurt Gödel had discovered using a different approach to Hilbert’s challenge – almost all mathematical truths have no proofs. They are unprovable truths. It also follows that almost all mathematical statements are undecid- 184 A Window on Infinity able: there is no proof that they are true, and no proof that they are false. Each of them is either true or false, but there is no way of using physical objects such as brains or computers to discover which is which. The laws of physics provide us with only a narrow window through which we can look out on the world of abstractions. All undecidable statements are, directly or indirectly, about infinite sets. To the opponents of infinity in mathematics, this is due to the meaninglessness of such statements. But to me it is a powerful argument – like Hofstadter’s 641 argument – that abstractions exist objectively. For it means that the truth value of an undecidable statement is certainly not just a convenient way of describing the behaviour of some physical object like a computer or a collection of dominoes. Interestingly, very few questions are known to be undecidable, even though most are – and I shall return to that point. But there are many unsolved mathematical conjectures, and some of those may well be undecidable. Take, for instance, the ‘prime-pairs conjecture’. A prime pair is a pair of prime numbers that differ by 2 – such as 5 and 7. The conjecture is that there is no largest prime pair: there are infinitely many of them. Suppose for the sake of argument that that is undecidable – using our physics. Under many other laws of physics it is decidable. The laws of Infinity Hotel are an example. Again, the details of how the management would settle the prime-pairs issue are not essential to my argument, but I present them here for the benefit of mathematically minded readers. The management would announce: First: Please check within the next minute whether your room number and the number two above it are both primes. Next: If they are, then send a message back through lower-numbered rooms saying that you have found a prime pair. Use the usual method for sending rapid messages (allow one minute for the first step and thereafter each step must be completed in half the time of the previous one). Store a record of this message in the lowest-numbered room that is not already storing a record of a previous such message. Next: Check with the room numbered one more than yours. If that guest is not storing such a record and you are, then send a message to room 1 saying that there is a largest prime pair.
================================================================================simple operations. In contrast, human ‘computers’ had to use (or be used by) both the definition and the general rules of arithmetic thousands of times per table, each time being an opportunity for human error. Unfortunately, despite pouring a fortune of his own money and that of the British government into the project, Babbage was such a poor organizer that he never succeeded in building a Difference Engine. But his design was sound (apart from a few trivial mistakes), and in 1991 a team led by the engineer Doron Swade at London’s Science Museum successfully implemented it, using engineering tolerances achievable in Babbage’s time. By the standards of today’s computers and even calculators, the Difference Engine had an extremely limited repertoire. But the reason it could exist at all is that there is a regularity among all the mathematical functions that occur in physics, and hence in navigation and engineering. These are known as analytic functions, and in 1710 the mathematician Brook Taylor had discovered that they can all be approximated arbitrarily well using only repeated additions and multiplications – the operations that the Difference Engine performs. (Special cases had been 135 the beginning of infinity known before that, but the jump to universality was proved by Taylor.) Thus, to solve the parochial problem of computing the handful of functions that needed to be tabulated, Babbage created a calculator that was universal for calculating analytic functions. It also made use of the universality of movable type, in its typewriter-like printer, without which the process of printing the tables could not have been fully automated. Babbage originally had no conception of computational universality. Nevertheless, the Difference Engine already comes remarkably close to it – not in its repertoire of computations, but in its physical constitution. To program it to print out a given table, one initializes certain cogs. Babbage eventually realized that this programming phase could itself be automated: the settings could be prepared on punched cards like Jacquard’s, and transferred mechanically into the cogs. This would not only remove the main remaining source of error, but also increase the machine’s repertoire. Babbage then realized that if the machine could also punch new cards for its own later use, and could control which punched card it would read next (say, by choosing from a stack of them, depending on the position of its cogs), then something qualitatively new would happen: the jump to universality. Babbage called this improved machine the Analytical Engine. He and his colleague the mathematician Ada, Countess of Lovelace, knew that it would be capable of computing anything that human ‘computers’ could, and that this included more than just arithmetic: it could do algebra, play chess, compose music, process images and so on. It would be what is today called a universal classical computer. (I shall explain the significance of the proviso ‘classical’ in Chapter 11, when I discuss quantum computers, which operate at a still higher level of universality.) Neither they nor anyone else for over a century afterwards imagined today’s most common uses of computation, such as the internet, word processing, database searching, and games. But another important application that they did foresee was making scientific predictions. The Analytical Engine would be a universal simulator – able to predict the behaviour, to any desired accuracy, of any physical object, given the relevant laws of physics. This is the universality that I mentioned in Chapter 3, through which physical objects that are unlike each other 136 The Jump to Universality and dominated by different laws of physics (such as brains and quasars) can exhibit the same mathematical relationships. Babbage and Lovelace were Enlightenment people, and so they understood that the universality of the Analytical Engine would make it an epoch-making technology. Even so, despite great efforts, they failed to pass their enthusiasm on to more than a handful of others, who in turn failed to pass it to anyone. And so the Analytical Engine became one of the tragic might-have-beens of history. If only they had looked around for other implementations, they might have realized that the perfect one was already waiting for them: electrical relays (switches controlled by electric currents). These had been one of the first applica- tions of fundamental research into electromagnetism, and they were about to be mass produced for the technological revolution of telegraphy. A redesigned Analytical Engine, using on/off electrical currents to represent binary digits and relays to do the computation, would have been faster than Babbage’s and also cheaper and easier to construct. (Binary numbers were already well known. The mathematician and philosopher Gottfried Wilhelm Leibniz had even suggested using them for mechanical calculation in the seventeenth century.) So the computer revolution would have happened a century earlier than it did. Because of the technologies of telegraphy and printing that were being developed concurrently, an internet revolution might well have followed. The science-fiction authors William Gibson and Bruce Sterling, in their novel The Difference Engine, have given an exciting account of what that might have been like. The journalist Tom Standage, in his book The Victorian Internet, maintains that the early telegraph system, even without computers, did create an internet-like phenomenon among the operators, with ‘hackers, on-line romances and weddings, chat-rooms, flame wars . . . and so on’. Babbage and Lovelace also thought about one application of uni - versal computers that has not been achieved to this day, namely so-called artificial intelligence (AI). Since human brains are physical objects obeying the laws of physics, and since the Analytical Engine is a universal simulator, it could be programmed to think, in every sense that humans can (albeit very slowly and requiring an impractically vast number of punched cards). Nevertheless, Babbage and Lovelace denied that it could. Lovelace argued that ‘The Analytical Engine has no 137 the beginning of infinity pretensions whatever to originate anything. It can do whatever we know how to order it to perform. It can follow analysis; but it has no power of anticipating any analytical
================================================================================the piano’ (in British English), but never ‘I am learning to play the baseball.’ We know how to form such sentences correctly, but, until we think about it, very few of us know that the inexplicit 374 The Evolution of Culture grammatical rule we are following even exists, let alone what it is. In American English the rule is slightly different, so the phrase ‘learning to play piano’ is acceptable. We may wonder why, and guess that the British are more fond of the definite article. But, again, that is not the explanation: in British English a patient is ‘in hospital’, and in American English ‘in the hospital’. The same is true of memes in general: they implicitly contain infor- mation that is not known to the holders, but which nevertheless causes the holders to behave alike. Hence, just as native English speakers may be mistaken about why they have said ‘the’ in a given sentence, people enacting all sorts of other memes often give false explanations, even to themselves, of why they are behaving in that way. Like genes, all memes contain knowledge (often inexplicit) of how to cause their own replication. This knowledge is encoded in strands of DNA or remembered by brains respectively. In both cases, the knowledge is adapted to causing itself to be replicated: it causes that more reliably than nearly all its variants do. In both cases, this adaptation is the outcome of alternating rounds of variation and selection. However, the logic of the copying mechanism is very different for genes and memes. In organisms that reproduce by dividing, either all the genes are copied into the next generation or (if the individual fails to reproduce) none are. In sexual reproduction, a full complement of genes randomly chosen from both parents is copied, or none are. In all cases, the DNA duplication process is automatic: genes are copied indiscriminately. One consequence is that some genes can be replicated for many generations without ever being ‘expressed’ (causing any behaviour) at all. Whether your parents ever broke a bone or not, genes for repairing broken bones will (barring unlikely mutations) be passed on to you and your descendants. The situation faced by memes is utterly different. Each meme has to be expressed as behaviour every time it is replicated. For it is that behaviour, and only that behaviour (given the environment created by all the other memes), that effects the replication. That is because a recipient cannot see the representation of the meme in the holder’s mind. A meme cannot be downloaded like a computer program. If it is not enacted, it will not be copied. 375 the beginning of infinity The upshot of this is that memes necessarily become embodied in two different physical forms alternately: as memories in a brain, and as behaviour: A meme exists in a brain form and a behaviour form, and each is copied to the other. Each of the two forms has to be copied (specifically, translated into the other form) in each meme generation. (Meme ‘generations’ are simply successive instances of copying to another individual.) Tech- nology can add further stages to a meme’s life cycle. For instance, the behaviour may be to write something down – thus embodying the meme in a third physical form, which may later cause a person who reads it to enact other behaviour, which then causes the meme to appear in someone’s brain. But all memes must have at least two physical forms. In contrast, for genes the replicator exists in only one physical form – the DNA strand (of a germ cell). Even though it may be copied to other locations in the organism, translated into RNA, and expressed as behaviour, none of those forms is a replicator. The idea that the behaviour might be a replicator is a form of Lamarckism, since it implies that behaviours that had been modified by circumstances would be inherited. 376 The Evolution of Culture A gene exists in only one physical form, which is copied. Because of the alternating physical forms of a meme, it has to survive two different, and potentially unrelated, mechanisms of selection in every generation. The brain-memory form has to cause the holder to enact the behaviour; and the behaviour form has to cause the new recipient to remember it – and to enact it. So, for example, although religions prescribe behaviours such as educating one’s children to adopt the religion, the mere intention to transmit a meme to one’s children or anyone else is quite insufficient to make that happen. That is why the overwhelming majority of attempts to start a new religion fail, even if the founder members try hard to propagate it. In such cases, what has happened is that an idea that people have adopted has succeeded in causing them to enact various behaviours including ones intended to cause their children and others to do the same – but the behaviour has failed to cause the same idea to be stored in the minds of those recipients. The existence of long-lived religions is sometimes explained from the premise that ‘children are gullible’, or that they are ‘easily frightened’ by tales of the supernatural. But that is not the explanation. The overwhelming majority of ideas simply do not have what it takes to persuade (or frighten or cajole or otherwise cause) children or anyone else into doing the same to other people. If establishing a faithfully replicating meme were that easy, the whole adult population in our society would be proficient at algebra, thanks to the efforts made to 377 the beginning of infinity teach it to them when they were children. To be exact, they would all be proficient algebra teachers. To be a meme, an idea has to contain quite sophisticated knowledge of how to cause humans to do at least two independent things: assimi- late the meme faithfully, and enact it. That some memes can replicate themselves with great fidelity for many generations is
================================================================================other biochemical molecules could be synthesized and experimented on. And, although 67 the beginning of infinity biology field trips would be difficult (because the closest natural eco - system would be millions of light years away), arbitrary life forms could be created and studied in artificial ecosystems, or in virtual-reality simulations of them. As for astronomy – the sky there is pitch black to the human eye, but to an observer with a telescope, even one of present-day design, it would be packed with galaxies. A somewhat bigger telescope could see stars in those galaxies in sufficient detail to test most of our present-day theories of astrophysics and cosmology. Even aside from those billion tonnes of matter, the cube is not empty. It is full of faint light, and the amount of evidence in that light is staggering: enough to construct a map of every star, planet and moon in all the nearest galaxies to a resolution of about ten kilometres. To extract that evidence in full, the telescope would need to use something like a mirror of the same width as the cube itself, which would require at least as much matter as building a planet. But even that would not be beyond the bounds of possibility, given the level of technology we are considering. To gather that much matter, those intergalactic scientists would merely have to trawl out to a distance of a few thousand cube-widths – still a piffling distance by intergalactic stand- ards. But even with a mere million-tonne telescope they could do a lot of astronomy. The fact that planets with tilted axes have annual seasons would be plain to see. They could detect life if it was present on any of the planets, via the composition of its atmosphere. With more subtle measurements they could test theories about the nature and history of life – or intelligence – on the planet. At any instant, a typical cube contains evidence, at that level of detail, about more than a trillion stars and their planets, simultaneously. And that is only one instant. Additional evidence of all those kinds is pouring into the cube all the time, so astronomers there could track changes in the sky just as we do. And visible light is only one band of the electromagnetic spectrum. The cube is receiving evidence in every other band too – gamma rays, X-rays, all the way down to the micro- wave background radiation and radio waves, as well as a few cosmic- ray particles. In short, nearly all the channels by which we on Earth currently receive evidence about any of the fundamental sciences are available in intergalactic space too. And they carry much the same content: not only is the universe full 68 The Spark of evidence, it is full of the same evidence everywhere. All people in the universe, once they have understood enough to free themselves from parochial obstacles, face essentially the same opportunities.This is an underlying unity in the physical world more significant than all the dissimilarities I have described between our environment and a typical one: the fundamental laws of nature are so uniform, and evidence about them so ubiquitous, and the connections between understanding and control so intimate, that, whether we are on our parochial home planet or a hundred million light years away in the intergalactic plasma, we can do the same science and make the same progress. So a typical location in the universe is amenable to the open-ended creation of knowledge. And therefore so are almost all other kinds of environment, since they have more matter, more energy and easier access to evidence than intergalactic space. The thought experiment considered almost the worst possible case. Perhaps the laws of physics do not allow knowledge-creation inside, say, the jet of a quasar. Or perhaps they do. But either way, in the universe at large, knowledge- friendliness is the rule, not the exception. That is to say, the rule is person-friendliness to people who have the relevant knowledge. Death is the rule for those who do not. These are the same rules that prevailed in the Great Rift Valley from whence we came, and have prevailed ever since. Oddly enough, that quixotic space station in our thought experiment is none other than the ‘generation ship’ in the Spaceship Earth metaphor – except that we have removed the unrealistic assumption that the inhabitants never improve it. Hence presumably they have long since solved the problem of how to avoid dying, and so ‘generations’ are no longer essential to the way their ship works. In any case, with hindsight, a generation ship was a poor choice for dramatizing the claim that the human condition is fragile and dependent on support from an unaltered biosphere, for that claim is contradicted by the very possibility of such a spaceship. If it is possible to live indefinitely in a spaceship in space, then it would be much more possible to use the same technology to live on the surface of the Earth – and to make continuing progress which would make it ever easier. It would make little practical difference whether the biosphere had been ruined or not. Whether or not it could 69 the beginning of infinity support any other species, it could certainly accommodate people – including humans – if they had the right knowledge. Now I can turn to the significance of knowledge – and therefore of people – in the cosmic scheme of things. Many things are more obviously significant than people. Space and time are significant because they appear in almost all explanations of other physical phenomena. Similarly, electrons and atoms are signifi- cant. Humans seem to have no place in that exalted company. Our history and politics, our science, art and philosophy, our aspirations and moral values – all these are tiny side effects of a supernova ex - plosion a few billion years ago, which could be extinguished tomorrow by another such explosion. Supernovae, too, are
================================================================================various existing theories of what art is. Ancient fine art, for instance in Greece, was initially concerned with the skill of reproducing the shapes of human bodies and other objects. That is not the same as the pursuit of objective beauty, because, among other things, it is perfectible (in the bad sense that it can reach a state that cannot be much improved on). But it is a skill that can allow artists to pursue pure art as well, and they did so in the ancient world, and then again during the revival of that tradition in the Renaissance. There are utilitarian theories of the purpose of art. These theories deprecate pure art, just as pure science and mathematics are deprecated by the same arguments. But one has no choice about what constitutes an artistic improvement any more than one has a choice as to what is true and false in mathematics. And if one tries to tune one’s scientific theories or philosophical positions to meet a political agenda, or a personal preference, then one is at cross purposes. Art can be used for many purposes. But artistic values are not subordinate to, or derived from, anything else. The same critique applies to the theory that art is self-expression. 366 Why are Flowers Beautiful? Expression is conveying something that is already there, while objective progress in art is about creating something new. Also, self-expression is about expressing something subjective, while pure art is objective. For the same reason, any kind of art that consists solely of spontaneous or mechanical acts, such as throwing paint on to canvas, or of pickling sheep, lacks the means of making artistic progress, because real progress is difficult and involves many errors for every success. If I am right, then the future of art is as mind-boggling as the future of every other kind of knowledge: art of the future can create unlimited increases in beauty. I can only speculate, but we can presumably expect new kinds of unification too. When we understand better what elegance really is, perhaps we shall find new and better ways to seek truth using elegance or beauty. I guess that we shall also be able to design new senses, and design new qualia, that can encompass beauty of new kinds literally inconceivable to us now. ‘What is it like to be a bat?’ is a famous question asked by the philosopher Thomas Nagel. (More precisely, what would it be like for a person to have the echo-location senses of a bat?) Perhaps the full answer is that in future it will be not so much be the task of philosophy to discover what that is like, but the task of technological art to give us the experience itself. terminology Aesthetics The philosophy of beauty. Elegance The beauty in explanations, mathematical formulae and so on. Explicit Expressed in words or symbols. Inexplicit Not explicit. Implicit Implied or otherwise contained in other information. meanings of ‘the beginning of infinity’ encountered in this chapter – The fact that elegance is a heuristic guide to truth. – The need to create objective knowledge in order to allow different people to communicate. 367 the beginning of infinity summary There are objective truths in aesthetics. The standard argument that there cannot be is a relic of empiricism. Aesthetic truths are linked to factual ones by explanations, and also because artistic problems can emerge from physical facts and situations. The fact that flowers reliably seem beautiful to humans when their designs evolved for an apparently unrelated purpose is evidence that beauty is objective. Those convergent criteria of beauty solve the problem of creating hard-to-forge signals where prior shared knowledge is insufficient to provide them. 368 15 The Evolution of Culture Ideas that survive A culture is a set of ideas that cause their holders to behave alike in some ways. By ‘ideas’ I mean any information that can be stored in people’s brains and can affect their behaviour. Thus the shared values of a nation, the ability to communicate in a particular language, the shared knowledge of an academic discipline and the appreciation of a given musical style are all, in this sense, ‘sets of ideas’ that define cultures. Many of them are inexplicit; in fact all ideas have some inexplicit component, since even our knowledge of the meanings of words is held largely inexplicitly in our minds. Physical skills, such as the ability to ride a bicycle, have an especially high inexplicit content, as do philosophical concepts such as freedom and knowledge. The distinction between explicit and inexplicit is not always sharp. For instance, a poem or a satire may be explicitly about one subject, while the audience in a particular culture will reliably, and without being told, interpret it as being about a different one. The world’s major cultures – including nations, languages, philo- sophical and artistic movements, social traditions and religions – have been created incrementally over hundreds or even thousands of years. Most of the ideas that define them, including the inexplicit ones, have a long history of being passed from one person to another. That makes these ideas memes – ideas that are replicators. Nevertheless, cultures change. People modify cultural ideas in their minds, and sometimes they pass on the modified versions. Inevitably, there are unintentional modifications as well, partly because of straight- forward error, and partly because inexplicit ideas are hard to convey accurately: there is no way to download them directly from one brain 369 the beginning of infinity to another like computer programs. Even native speakers of a language will not give identical definitions of every word. So it can be only rarely, if ever, that two people hold precisely the same cultural idea in their minds. That is why, when the founder of a political or philosophical movement or a religion dies, or even before, schisms typically happen. The movement’s most devoted followers are often shocked to discover that they disagree about what its doctrines ‘really’ are.
================================================================================Another denizen of Florence at this time was Niccolò Machiavelli, the first secular political philosopher since antiquity. The Medici were soon promoting the new philosophy of ‘humanism’, which valued knowledge above dogma, and virtues such as intellectual independence, curiosity, good taste and friendship over piety and humility. They sent agents all over the known world to obtain copies of ancient books, many of which had not been seen in the West since the fall of the Western Roman Empire. The Medici library made copies which it supplied to scholars in Florence and elsewhere. Florence became a powerhouse of newly revived ideas, new interpretations of ideas, and brand-new ideas. But that rapid progress lasted for only a generation or so. A charismatic monk, Girolamo Savonarola, began to preach apocalyptic sermons against humanism and every other aspect of the Florentine enlightenment. Urging a return to medieval conformism and self-denial, he proclaimed prophecies of doom if Florence continued on its path. Many citizens were persuaded, and in 1494 Savonarola managed to seize power. He reimposed all the traditional restrictions on art, literature, thought and behaviour. Secular music was banned. Clothing had to be plain. Frequent fasting became effectively compulsory. Homosexuality and prostitution were violently suppressed. The Jews of Florence were expelled. Gangs of ruffians inspired by Savonarola roamed the city searching for taboo artefacts such as mirrors, cosmetics, musical instruments, secular books, and almost anything beautiful. A huge pile of such treasures was ceremonially burned in the so-called ‘Bonfire of the Vanities’ in the centre of the city. Botticelli is said to have thrown some of his own paintings into the fire. It was the bonfire of optimism. Eventually Savonarola was himself discarded and burned at the stake. But, although the Medici regained control of Florence, optimism did not. As in Athens, the tradition of art and science continued for a while, and, even a century later, Galileo was sponsored (and then abandoned) 219 the beginning of infinity by the Medici. But by that time Florence had became just another Renaissance city-state lurching from one crisis to another under the rule of despots. Fortunately, somehow that mini-enlightenment was never quite extinguished. It continued to smoulder in Florence and several other Italian city-states, and finally ignited the Enlightenm ent itself in northern Europe. There may have been many enlightenments in history, shorter-lived and shining less brilliantly than those, perhaps in obscure subcultures, families or individuals. For example, the philosopher Roger Bacon (1214–94) is noted for rejecting dogma, advocating observation as a way of discovering the truth (albeit by ‘induction’), and making several scientific discoveries. He foresaw the invention of microscopes, tele- scopes, self-powered vehicles and flying machines – and that math- ematics would be a key to future scientific discoveries. He was thus an optimist. But he was not part of any tradition of criticism, and so his optimism died with him. Bacon studied the works of ancient Greek scientists and of scholars of the ‘Islamic Golden Age’ – such as Alhazen (965–1039), who made several original discoveries in physics and mathematics. During the Islamic Golden Age (between approximately the eighth and thirteenth centuries), there was a strong tradition of scholarship that valued and drew upon the science and philosophy of European antiquity. Whether there was also a tradition of criticism in science and philosophy is currently controversial among historians. But, if there was, it was snuffed out like the others. It may be that the Enlightenment has ‘tried’ to happen countless times, perhaps even all the way back to prehistory. If so, those mini- enlightenments put our recent ‘lucky escapes’ into stark perspective. It may be that there was progress every time – a brief end to stagnation, a brief glimpse of infinity, always ending in tragedy, always snuffed out, usually without trace. Except this once. The inhabitants of Florence in 1494 or Athens in 404 bce could be forgiven for concluding that optimism just isn’t factually true. For they knew nothing of such things as the reach of explanations or the power of science or even laws of nature as we understand them, let alone the moral and technological progress that was to follow when the Enlightenment got under way. At the moment of defeat, it must have 220 Optimism seemed at least plausible to the formerly optimistic Athenians that the Spartans might be right, and to the formerly optimistic Florentines that Savonarola might be. Like every other destruction of optimism, whether in a whole civilization or in a single individual, these must have been unspeakable catastrophes for those who had dared to expect progress. But we should feel more than sympathy for those people. We should take it personally. For if any of those earlier experiments in optimism had succeeded, our species would be exploring the stars by now, and you and I would be immortal. terminology Blind optimism (recklessness, overconfidence) Proceeding as if one knew that bad outcomes will not happen. Blind pessimism (precautionary principle) Avoiding everything not known to be safe. The principle of optimism All evils are caused by insufficient know- ledge. Wealth The repertoire of physical transformations that one is capable of causing. meanings of ‘the beginning of infinity’ encountered in this chapter – Optimism. (And the end of pessimism.) – Learning how not to fool ourselves. – Mini-enlightenments like those of Athens and Florence were p otential beginnings of infinity. summary Optimism (in the sense that I have advocated) is the theory that all failures – all evils – are due to insufficient knowledge. This is the key to the rational philosophy of the unknowable. It would be contentless if there were fundamental limitations to the creation of knowledge, but there are not. It would be false if there were fields – especially philosophical fields such as morality – in which there were no such 221 the beginning of infinity thing as objective progress. But truth does exist in all those fields, and progress towards it is made by seeking good explanations. Problems are inevitable, because
================================================================================more fascinating problem or unless, indeed, you should obtain a solution. But even if you do obtain a solution, you may then discover, to your delight, the existence of a whole family of enchanting, though perhaps difficult, problem children . . . Realism and the Aim of Science (1983) Experimental testing involves many prior explanations in addition to the ones being tested, such as theories of how measuring instruments work. The refutation of a scientific theory has, from the point of view of someone who expected it to be true, the same logic as a conjuring trick – the only difference being that a conjurer does not normally have access to unknown laws of nature to make a trick work. Since theories can contradict each other, but there are no contra- dictions in reality, every problem signals that our knowledge must be flawed or inadequate. Our misconception could be about the reality we are observing, or about how our perceptions are related to it, or both. For instance, a conjuring trick presents us with a problem only because we have misconceptions about what ‘must’ be happening – which implies that the knowledge that we used to interpret what we were seeing is defective. To an expert steeped in conjuring lore, it may be obvious what is happening – even if the expert did not observe the trick at all but merely heard a misleading account of it from a person who was fooled by it. This is another general fact about scientific explanation: if one has a misconception, observations that conflict with one’s expectations may (or may not) spur one into making further conjectures, but no amount of observing will correct the misconception until after one has thought of a better idea; in contrast, if one has the right idea one can explain the phenomenon even if there are large errors in the data. Again, the very term ‘data’ (‘givens’) is misleading. Amend- ing the ‘data’, or rejecting some as erroneous, is a frequent concomitant of scientific discovery, and the crucial ‘data’ cannot even be obtained until theory tells us what to look for and how and why. A new conjuring trick is never totally unrelated to existing tricks. Like a new scientific theory, it is formed by creatively modifying, rearranging and combining the ideas from existing tricks. It requires 18 The Reach of Explanations pre-existing knowledge of how objects work and how audiences work, as well as how existing tricks work. So where did the earliest conjuring tricks come from? They must have been modifications of ideas that were not originally conjuring tricks – for instance, ideas for hiding objects in earnest. Similarly, where did the first scientific ideas come from? Before there was science there were rules of thumb, and explanatory assumptions, and myths. So there was plenty of raw material for criticism, conjecture and experiment to work with. Before that, there were our inborn assumptions and expectations: we are born with ideas, and with the ability to make progress by changing them. And there were patterns of cultural behaviour – about which I shall say more in Chapter 15. But even testable, explanatory theories cannot be the crucial ingre- dient that made the difference between no-progress and progress. For they, too, have always been common. Consider, for example, the ancient Greek myth for explaining the annual onset of winter. Long ago, Hades, god of the underworld, kidnapped and raped Persephone, goddess of spring. Then Persephone’s mother, Demeter, goddess of the earth and agriculture, negotiated a contract for her daughter’s release, which specified that Persephone would marry Hades and eat a magic seed that would compel her to visit him once a year thereafter. Whenever Persephone was away fulfilling this obligation, Demeter became sad and would command the world to become cold and bleak so that nothing could grow. That myth, though comprehensively false, does constitute an ex - planation of seasons: it is a claim about the reality that brings about our experience of winter. It is also eminently testable: if the cause of winter is Demeter’s periodic sadness, then winter must happen every- where on Earth at the same time. Therefore, if the ancient Greeks had known that a warm growing season occurs in Australia at the very moment when, as they believed, Demeter is at her saddest, they could have inferred that there was something wrong with their explanation of seasons. Yet, when myths were altered or superseded by other myths over the course of centuries, the new ones were almost never any closer to the truth. Why? Consider the role that the specific elements of the Persephone myth play in the explanation. For example, the gods 19 the beginning of infinity provide the power to affect a large-scale phenomenon (Demeter to command the weather, and Hades and his magic seed to command Persephone and hence to affect Demeter). But why those gods and not others? In Nordic mythology, seasons are caused by the changing fortunes of Freyr, the god of spring, in his eternal war with the forces of cold and darkness. Whenever Freyr is winning, the Earth is warm; when he is losing, it is cold. That myth accounts for the seasons about as well as the Persephone myth. It is slightly better at explaining the randomness of weather, but worse at explaining the regularity of seasons, because real wars do not ebb and flow so regularly (except insofar as that is due to seasons themselves). In the Persephone myth, the role of the marriage contract and the magic seed is to explain that regularity. But why is it specifically a magic seed and not any other kind of magic? Why is it a conjugal- visits contract and not some other reason for someone to repeat an action annually? For instance, here is a variant explanation that fits the facts just as well: Persephone was not released – she escaped. Each year in spring, when her powers are at their height, she takes
================================================================================were believed to be the only two possibilities. I discus- sed them in The Fabric of Reality because they were relevant to the question: is there a bound on the number of computational steps that a computer can execute during the lifetime of the universe? If there is, then physics will also impose a bound on the amount of knowledge that can be created – knowledge-creation being a form of computation. Everyone’s first thought was that unbounded knowledge-creation is possible only in a universe that does not recollapse. However, on analysis it turned out that the reverse is true: in universes that expand for ever, the inhabitants would run out of energy. But the cosmologist Frank Tipler discovered that in certain types of recollapsing universes the Big Crunch singularity is suitable for performing the faster-and- faster trick that we used in Infinity Hotel: an infinite sequence of computational steps could be executed in a finite time before the singularity, powered by the ever-increasing tidal effects of the gravi- tational collapse itself. To the inhabitants – who would eventually have to upload their personalities into computers made of something like pure tides – the universe would last for ever because they would be thinking faster and faster, without limit, as it collapsed, and storing their memories in ever smaller volumes so that access times could also 450 The Beginning be reduced without limit. Tipler called such universes ‘omega-point universes’. At the time, the observational evidence was consistent with the real universe being of that type. A small part of the revolution that is currently overtaking cosmology is that the omega-point models have been ruled out by observation. Evidence – including a remarkable series of studies of supernovae in distant galaxies – has forced cosmologists to the unexpected conclusion that the universe not only will expand for ever but has been expanding at an accelerating rate. Something has been counteracting its gravity. We do not know what. Pending the discovery of a good explanation, the unknown cause has been named ‘dark energy’. There are several proposals for what it might be, including effects that merely give the appearance of acceleration. But the best working hypothesis at present is that in the equations for gravity there is an additional term, of a form first mooted by Einstein in 1915 and then dropped because he realized that his explanation for it was bad. It was proposed again in the 1980s as a possible effect of quantum field theory, but again there is no theory of the physical meaning of such a term that is good enough to predict, for instance, its magnitude. The problem of the nature and effects of dark energy is no minor detail, nor does anything about it suggest a perpetually unfathomable mystery. So much for cosmology being a fundamentally completed science. Depending on what dark energy turns out to be, it may well be possible to harness it in the distant future, to provide energy for knowledge-creation to continue for ever. Because this energy would have to be collected over ever greater distances, the computation would have to become ever slower. In a mirror image of what would happen in omega-point cosmologies, the inhabitants of the universe would notice no slowdown, because, again, they would be instantiated as computer programs whose total number of steps would be unbounded. Thus dark energy, which has ruled out one scenario for the unlimited growth of knowledge, would provide the literal driving force of another. The new cosmological models describe universes that are infinite in their spatial dimensions. Because the Big Bang happened a finite time ago, and because of the finiteness of the speed of light, we shall only ever see a finite portion of infinite space – but that portion will continue to grow for ever. Thus, eventually, ever more unlikely phenomena will 451 the beginning of infinity come into view. When the total volume that we can see is a million times larger than it is now, we shall see things that have a probability of one in a million of existing in space as we see it today. Everything physically possible will eventually be revealed: watches that came into existence spontaneously; asteroids that happen to be good likenesses of William Paley; everything. According to the prevailing theory, all those things exist today, but many times too far away for light to have reached us from them – yet. Light becomes fainter as it spreads out: there are fewer photons per unit area. That means that ever larger telescopes are needed to detect a given object at ever larger distances. So there may be a limit to how distant – and therefore how unlikely – a phenomenon we shall ever be able to see. Except, that is, for one type of phenomenon: a beginning of infinity. Specifically, any civilization that is colonizing the universe in an unbounded way will eventually reach our location. Hence a single infinite space could play the role of the infinitely many universes postulated by anthropic explanations of the fine-tuning coincidences. In some ways it could play that role better: if the prob- ability that such a civilization could form is not zero, there must be infinitely many such civilizations in space, and they will eventually encounter each other. If they could estimate that probability from theory, they could test the anthropic explanation. Furthermore, anthropic arguments could not only dispense with all those parallel universes,* they could dispense with the variant laws of physics too. Recall from Chapter 6 that all the mathematical functions that occur in physics belong to a relatively narrow class, the analytic functions. They have a remarkable property: if an analytic function is non-zero at even one point, then over its entire range it can pass through zero only at isolated points. So this must be true of ‘the probability that an astrophysicist exists’ expressed as a function of the constants of physics. We know little about this function, but we do know
================================================================================adaptations do have enough reach to make the species viable on the new island, they will set up a colony there. In subsequent generations, mutants slightly better adapted to the new island will end up having slightly more offspring on average, so evolution will adapt the population more accurately to contain the knowledge needed to make a living there. The ancestor species of humans colonized new habitats and embarked on new lifestyles in exactly that way. But by the time our species had evolved, our fully human ancestors were achieving much the same thing thousands of times faster, by evolving their cultural knowledge instead. Because they did not yet know how to do science, their knowledge was only a little less parochial than biological knowledge. It consisted of rules of thumb. And so progress, though rapid compared to biological evolution, was sluggish compared to what the Enlightenment has accustomed us to. Since the Enlightenment, technological progress has depended specifically on the creation of explanatory knowledge. People had dreamed for millennia of flying to the moon, but it was only with the advent of Newton’s theories about the behaviour of invisible entities such as forces and momentum that they began to understand what was needed in order to go there. This increasingly intimate connection between explaining the world and controlling it is no accident, but is part of the deep structure of the world. Consider the set of all conceivable transformations of physical objects. Some of those (like faster-than-light communication) 55 the beginning of infinity never happen because they are forbidden by laws of nature; some (like the formation of stars out of primordial hydrogen) happen spontan- eously; and some (such as converting air and water into trees, or converting raw materials into a radio telescope) are possible, but happen only when the requisite knowledge is present – for instance, embodied in genes or brains. But those are the only possibilities. That is to say, every putative physical transformation, to be performed in a given time with given resources or under any other conditions, is either – impossible because it is forbidden by the laws of nature; or – achievable, given the right knowledge. That momentous dichotomy exists because if there were transform- ations that technology could never achieve regardless of what know- ledge was brought to bear, then this fact would itself be a testable regularity in nature. But all regularities in nature have explanations, so the explanation of that regularity would itself be a law of nature, or a consequence of one. And so, again, everything that is not forbidden by laws of nature is achievable, given the right knowledge. This fundamental connection between explanatory knowledge and technology is why the Haldane–Dawkins queerer-than-we-can-suppose argument is mistaken – why the reach of human adaptations does have a different character from that of all the other adaptations in the biosphere. The ability to create and use explanatory knowledge gives people a power to transform nature which is ultimately not limited by parochial factors, as all other adaptations are, but only by universal laws. This is the cosmic significance of explanatory knowledge – and hence of people, whom I shall henceforward define as entities that can create explanatory knowledge. For every other species on Earth, we can determine its reach simply by making a list of all the resources and environmental conditions on which its adaptations depend. In principle one could determine those from a study of its DNA molecules – because that is where all its genetic information is encoded (in the form of sequences of small constituent molecules called ‘bases’). As Dawkins has pointed out: A gene pool is carved and whittled through generations of ancestral natural selection to fit [a particular] environment. In theory a knowledge- able zoologist, presented with the complete transcript of a genome [the 56 The Spark set of all the genes of an organism], should be able to reconstruct the environmental circumstances that did the carving. In this sense the DNA is a coded description of ancestral environments. In Art Wolfe, The Living Wild, ed. Michelle A. Gilders (2000) To be precise, the ‘knowledgeable zoologist’ would be able to reconstruct only those aspects of the organism’s ancestral environment that exerted selection pressure – such as the types of prey that existed there, what behaviours would catch them, what chemicals would digest them and so on. Those are all regularities in the environment. A genome contains coded descriptions of them, and hence implicitly specifies the environ- ments in which the organism can survive. For example, all primates require vitamin C. Without it, they fall ill and die of the disease scurvy, but their genes do not contain the knowledge of how to synthesize it. So, whenever any non-human primate is in an environment that does not supply vitamin C for an extended period, it dies. Any account that overlooks this fact will overestimate the reach of those species. Humans are primates, yet their reach has nothing to do with which environments supply vitamin C. Humans can create and apply new knowledge of how to cause it to be synthesized from a wide range of raw materials, by agriculture or in chemical factories. And, just as essentially, humans can discover for themselves that, in most environments, they need to do that in order to survive. Similarly, whether humans could live entirely outside the biosphere – say, on the moon – does not depend on the quirks of human bio- chemistry. Just as humans currently cause over a tonne of vitamin C to appear in Oxfordshire every week (from their farms and factories), so they could do the same on the moon – and the same goes for breathable air, water, a comfortable temperature and all their other parochial needs. Those needs can all be met, given the right knowledge, by transforming other resources. Even with present-day technology, it would be possible to build a self-sufficient colony on the moon, powered by sunlight, recycling its waste, and obtaining
================================================================================(such as energy and spin) are present in the cavity, there is no such thing as which one was there first, nor which one will be the next to leave. There is only such a thing as the attributes of any one of them, and how many of them there are. If the two universes of our fictional multiverse are initially fungible, our transporter malfunction can make them acquire different attributes in the same way that a bank’s computer can withdraw one of two fungible dollars and not the other from an account containing two dollars. The laws of physics could, for instance, say that, when the transporter malfunctions, then in one of the universes and not the other there will be a small voltage surge in the transported objects. The laws, being symmetrical, could not possibly specify which universe the surge will take place in. But, precisely because the universes are initially fungible, they do not have to. It is a rather counter-intuitive fact that if objects are merely identical (in the sense of being exact copies), and obey deterministic laws that 267 the beginning of infinity make no distinction between them, then they can never become different; but fungible objects, which on the face of it are even more alike, can. This is the first of those weird properties of fungibility that Leibniz never thought of, and which I consider to be at the heart of the phenomena of quantum physics. Here is another. Suppose that your account contains a hundred dollars and you have instructed your bank to transfer one dollar from this account to the tax authority on a specified date in the future. So the bank’s computer now contains a deterministic rule to that effect. Suppose that you have done this because the dollar already belongs to the tax authority. (Say it had mistakenly sent you a tax refund, and has given you a deadline to repay it.) Since the dollars in the account are fungible, there is no such thing as which one belongs to the tax authority and which belong to you. So we now have a situation in which a collection of objects, though fungible, do not all have the same owner! Everyday language struggles to describe this situation: each dollar in the account shares literally all its attributes with the others, yet it is not the case that all of them have the same owner. So, could we say that in this situation they have no owner? That would be misleading, because evidently the tax authority does own one of them and you do own the rest. Could one say that they all have two owners? Perhaps, but only because that is a vague term. Certainly there is no point in saying that one cent of each of the dollars is owned by the tax authority, because that simply runs into the problem that the cents in the account are all fungible too. But, in any case, notice that the problem raised by this ‘diversity within fungibility’ is one of language only. It is a problem of how to describe some aspects of the situation in words. No one finds the situation itself paradoxical: the computer has been instructed to execute definite rules, and there will never be any ambiguity about what will happen as a result. Diversity within fungibility is a widespread phenomenon in the multiverse, as I shall explain. One big difference from the case of fungible money is that in the latter case we never have to wonder about – or predict – what it would be like to be a dollar. That is to say, what it would be like to be fungible, and then to become differentiated. Many applications of quantum theory require us to do exactly that. But first: I suggested temporarily visualizing our two universes as 268 The Multiverse being next to each other in space – just as some science-fiction stories refer to doppelgänger universes as being ‘in other dimensions’. But now we have to abandon that image and make them coincide: whatever that ‘extra dimension’ was supposed to denote, it would make them non-fungible.* It is not that they coincide in anything, such as an external space: they are not in space. An instance of space is part of each of them. That they ‘coincide’ means only that they are not separate in any way. It is hard to imagine perfectly identical things coinciding. For instance, as soon as you imagine just one of them, your imagination has already violated their fungibility. But, although imagination may baulk, reason does not. Now our story can begin to have a non-trivial plot. For example, the voltage surge that happens in one of the two universes when the transporter malfunctions could cause some of the neurons in a pas - senger’s brain to misfire in that universe. As a result, in that universe, that passenger spills a cup of coffee on another passenger. As a result, they have a shared experience which they do not have in the other universe, and this leads to romance – just as in Sliding Doors. The voltage surges need not be ‘malfunctions’ of the transporter. They could be a regular effect of the way it works. We accept much larger unpredictable jolts during others forms of travel such as flying or bronco-riding. Let us imagine that a tiny surge is produced in one of the universes whenever the transporter is operated in both, but that it is too small to be noticeable unless measured with a sensitive voltmeter, or unless it nudges something that happens to be on the brink of changing but would recede from the brink if not nudged. In principle, a phenomenon could appear unpredictable to observers for one or more of three reasons. The first is that it is affected by some fundament ally random (indeterministic) variable. I have excluded that possibility from our story because there are no such variables in real physics. The
================================================================================for you: it makes it harder for you to fool yourself. For instance, it may occur to you to modify your theory as follows: ‘In the known world, the seasons happen at the times of year predicted by the axis-tilt theory; everywhere else on Earth, they also happen at those times of year.’ This theory correctly predicts all evidence known to you. And it is just as testable as your real theory. But now, in order to deny what the axis-tilt theory predicts in the faraway places, you have had to deny what it says about reality, everywhere. The modified 27 the beginning of infinity theory is no longer an explanation of seasons, just a (purported) rule of thumb. So denying that the original explanation describes the true cause of seasons in the places about which you have no evidence has forced you to deny that it describes the true cause even on your home island. Suppose for the sake of argument that you thought of the axis-tilt theory yourself. It is your conjecture, your own original creation. Yet because it is a good explanation – hard to vary – it is not yours to modify. It has an autonomous meaning and an autonomous domain of applicability. You cannot confine its predictions to a region of your choosing. Whether you like it or not, it makes predictions about places both known to you and unknown to you, predictions that you have thought of and ones that you have not thought of. Tilted planets in similar orbits in other solar systems must have seasonal heating and cooling – planets in the most distant galaxies, and planets that we shall never see because they were destroyed aeons ago, and also planets that have yet to form. The theory reaches out, as it were, from its finite origins inside one brain that has been affected only by scraps of patchy evidence from a small part of one hemisphere of one planet – to infinity. This reach of explanations is another meaning of ‘the beginning of infinity’. It is the ability of some of them to solve problems beyond those that they were created to solve. The axis-tilt theory is an example: it was originally proposed to explain the changes in the sun’s angle of elevation during each year. Combined with a little knowledge of heat and spinning bodies, it then explained seasons. And, without any further modification, it also explained why seasons are out of phase in the two hemispheres, and why tropical regions do not have them, and why the summer sun shines at midnight in polar regions – three phenomena of which its creators may well have been unaware. The reach of an explanation is not a ‘principle of induction’; it is not something that the creator of the explanation can use to obtain or justify it. It is not part of the creative process at all. We find out about it only after we have the explanation – sometimes long after. So it has nothing to do with ‘extrapolation’, or ‘induction’, or with ‘deriving’ a theory in any other alleged way. It is exactly the other way round: the reason that the explanation of seasons reaches far outside the experience of its 28 The Reach of Explanations creators is precisely that it does not have to be extrapolated. By its nature as an explanation, when its creators first thought of it, it already applied in our planet’s other hemisphere, and throughout the solar system, and in other solar systems, and at other times. Thus the reach of an explanation is neither an additional assumption nor a detachable one. It is determined by the content of the explanation itself. The better an explanation is, the more rigidly its reach is determined – because the harder it is to vary an explanation, the harder it is in particular to construct a variant with a different reach, whether larger or smaller, that is still an explanation. We expect the law of gravity to be the same on Mars as on Earth because only one viable explanation of gravity is known – Einstein’s general theory of relativity – and that is a universal theory; but we do not expect the map of Mars to resemble the map of Earth, because our theories about how Earth looks, despite being excellent explanations, have no reach to the appearance of any other astronomical object. Always, it is explanatory theories that tell us which (usually few) aspects of one situation can be ‘extrapolated’ to others. It also makes sense to speak of the reach of non-explanatory forms of knowledge – rules of thumb, and also knowledge that is implicit in the genes for biological adaptations. So, as I said, my rule of thumb about cups-and-balls tricks has reach to a certain class of tricks; but I could not know what that class is without the explanation for why the rule works. Old ways of thought, which did not seek good explanations, permitted no process such as science for correcting errors and misconceptions. Improvements happened so rarely that most people never experienced one. Ideas were static for long periods. Being bad explanations, even the best of them typically had little reach and were therefore brittle and unreliable beyond, and often within, their traditional applications. When ideas did change, it was seldom for the better, and when it did happen to be for the better, that seldom increased their reach. The emergence of science, and more broadly what I am calling the Enlightenment, was the beginning of the end of such static, parochial systems of ideas. It initiated the present era in human history, unique for its sustained, rapid creation of knowledge with ever-increasing reach. Many have wondered how long this can continue. Is it inherently bounded? Or is this the 29 the beginning of infinity beginning of infinity – that is to say, do these methods have unlimited potential to create further knowledge? It may seem paradoxical to claim
================================================================================139, 196 mathematics and 164, 166, 167–77, transmutation of 1, 61, 67 186 measuring instruments and 181 ideas physics and 164, 173, 175, 177–81, conjectural see conjecture 182–3, 193–4 replicating see memes potential 165 see also explanations principled rejections of 132–3, 165–7, ignorance, infinite 447 459 imagination 26, 264–5 and probability 176–7 see also fiction; science fiction religious objections to study of 166 imitation 402, 403–10, 417 uncountable 171–2, 177, 181, 182 aping 405 and universality 164–5 behaviour parsing 407–9 see also Zeno’s mistake parroting 405, 406–7 information flow 238, 263, 265, 266, immortality 63, 214, 455, 459 281, 282, 292 impartiality see fairness people as channels of 302 incredulity, argument from personal in quantum theory 282, 287, 295, 164 304 474 index see also histories (sequences of events Jefferson, Thomas 330 in a multiverse) Jews 219, 385 initial state 107, 118, 280 joke, hideous, played on humans 416 innovation 125, 127, 133, 147, 197, jokes see humour 202, 204, 205, 392, 394, 398–401, jump to universality see universality 402, 410, 413–14, 435 justificationism 9, 31, 120, 187, 189 and catastrophes 201 see also authority and knowledge and criticism 222 Florentine 218–19 Kant, Immanuel 183 rapid 397, 399, 457 Keats, John 355 suppression of 202, 204, 384, 416, Kennedy, John F. 215 423, 427 Kepler, Johannes 112 see also universality, the jump to Kepler’s laws 112, 113, 256, 446 insoluble problems 53, 193, 213 knowledge 78 see also problems are soluble; in adaptation 55, 56–65, 78–81, 88; undecidable questions and the problem of creationism inspiration 36, 37, 41, 42, 58, 158–60, 79–81 333, 341, 440 and authority see authority and inspiration/perspiration 36, 37, 41, 58, knowledge 76, 158–60, 341–2, 456 creation of see creation of knowledge see also automation cultural 50, 51, 55, 59, 422 instrumentalism 15–16, 26, 31, 110, and deduction 5 112, 210, 325, 356 certain see fallibilism and quantum theory 307–9 and ‘a dream of Socrates’ 226–43, see also behaviourism; finitism 245, 252–3 instruments, scientific see measuring effects on an environment 74–5; see instruments also under biosphere intelligence 2, 47, 60, 86 encoded/embodied in matter 50, 56, artificial see artificial intelligence (AI) 74–5, 266–7, 375–7 and explanations 30 and evolution 77, 78–105 extraterrestrial see extraterrestrials explanatory see explanations; scientific see also fine-tuning theories interference, quantum 282–8, 291, 293, genetic see DNA; genes; genomes 295–8, 301–2, 303 inexplicit see inexplicit knowledge see also Mach–Zehnder infinite ignorance as potential for 447 interferometers moral see moral knowledge interpretation 36, 45, 65, 115, 127, 144, as ‘nearly there’ 445–6 164, 178, 216, 219, 253, 255, 301, non-explanatory 29, 73, 78, 94; see 311, 318–19, 329n, 330, 337, 344, also inexplicit knowledge; rules of 423, 428–9, 436 thumb of experiences 7–10, 17, 18, 22, 30, objective vii, 15, 31, 122, 185, 193, 38, 151, 317, 359, 369, 370, 403, 203, 209, 221–2, 226, 236, 238, 404, 407, 410, 448 242, 253, 255, 308, 314, 345, 350, of quantum theory 263, 266, 306–10, 353–4, 358–68, 388, 394, 448 312, 322, 325, 460 Plato’s theory of 119, 252, 252–3 split from prediction in scientific as a replicator 95, 114, 266–7 theories 315–16, 323, 324–5, 449 significance of people and 70–75, introspection 154 76 ‘ironic science’ 448–9 and survival 202, 207 see also epistemology Jacquard, Joseph Marie 134 Kuhn, Thomas 313 Jacquard loom 134–5 Kurrild-Klitgaard, Peter 339 475 index Lagrange, Joseph-Louis 198–9, 206, wizards 260 445, 446 see also conjuring tricks Lamarck, Jean-Baptiste 87–8, 89 Malthus, Thomas 201, 205–7, 421, 435, Lamarckism 87–9, 96, 103, 105, 106, 436 158, 210, 376, 411, 446 Malthusian prophetic fallacy 206, language 93, 94, 125–6, 142, 154, 268, 214, 432 280, 309, 311, 315, 323, 363, 365, Marx, Karl 371, 426, 428, 430, 442 366, 369–70, 405, 407, 409, 413, mathematical proof see proof 414, 428 mathematical truth see truth other than natural language 144, 154, mating 90, 91, 144, 359, 360, 362, 400, 159–62, 199, 292, 361, 365, 366, 401, 402, 413, 415 399 matter 14, 16, 40, 45–6, 61–2, 66, 68–9, see also universality: the jump to; 74, 75, 85, 97, 134, 203, 290–91, writing systems 305 Laplace, Pierre Simon 133 dark 36, 46, 67 lasers 73, 266, 267, 273–4, 294, 393, ordinary 45–6 446 prominent 73 see also atomic lasers Maxwell, James Clerk 255 laws of nature see nature, laws of measure theory for infinite sets 102, laws of physics see physics, laws of 178–83, 277–8, 281, 283, 287, 303, Leibniz, Gottfried Wilhelm 137, 164, 453, 458 181, 199–200, 265–6, 268, 269 for histories 301, 303, 307, 454, 455 Leonardo da Vinci 219 measurement 11, 35, 62, 68, 72, 99, liberty see freedom 108, 158, 183, 274, 299, 309, 316, life-support system 44–51, 45, 64, 338, 340, 357, 443 71 see also Spaceship Earth; errors 140–42, 298, 321–3; see also sustainability fallibility; fooling ourselves light 2, 3, 8, 11, 16, 38, 46, 47, 54, 61, see also proxies 68, 80, 85, 208, 228, 240n, 261, measuring instruments 18, 34–41, 179, 273, 305, 314, 357, 413, 433, 452 192, 269, 294–5, 308, 446 faster-than-light communication 55– human sensory systems as 40 6, 275–6, 283, 434 SETI 72–3 speed of 192, 199, 262, 263, 273, see also microscopes; telescopes 291, 293, 294, 451 Medawar, Peter 193 sunlight 8, 47, 57, 441 Medici, Lorenzo de’ 218, 429 see also photons Medici family 218–20 Littlefield, John E. 333 Mediocrity, Principle of 43–4, 45, 51–4, llamas 426–7, 429 64, 76, 101, 110, 166, 434 Locke, John 4, 134 memes 93, 94–5, 105, 369–72 Loebner, Hugh (Prize) 150–51 in animals see aping; parroting logical positivism 313, 314, 325 anti-rational 81, 381, 385, 388–90, Lovelace, Ada, Countess of 136, 137, 148 391–3, 394–396, 397, 413, 428, ‘Lady Lovelace’s objection’ 138 457 low-level phenomena 109–10, 111, 138 compared with viruses 384 creativity and in meme replication Mach, Ernst 312, 324 402–15, 416 Mach, Ludwig 312 evolution of 372–8, 383, 390, 393, Mach–Zehnder interferometers 286–7, 400, 412–13 296–7, 305, 309, 312 faithful replication of 257, 370, 374, Machiavelli, Niccolò 219 377, 378–80, 382–4, 390, 405,
================================================================================david deutsch The Beginning of Infinity Explanations that Transform the World VIKING The Beginning of Infinity david deutsch The Beginning of Infinity Explanations that Transform the World VIKING VIKING Published by the Penguin Group Penguin Group (USA) Inc., 375 Hudson Street, New York, New York 10014, U.S.A. Penguin Group (Canada), 90 Eglinton Avenue East, Suite 700, Toronto, Ontario, Canada M4P 2Y3 (a division of Pearson Penguin Canada Inc.) Penguin Books Ltd, 80 Strand, London WC2R 0RL, England Penguin Ireland, 25 St. Stephen’s Green, Dublin 2, Ireland (a division of Penguin Books Ltd) Penguin Books Australia Ltd, 250 Camberwell Road, Camberwell, Victoria 3124, Australia (a division of Pearson Australia Group Pty Ltd) Penguin Books India Pvt Ltd, 11 Community Centre, Panchsheel Park, New Delhi – 110 017, India Penguin Group (NZ), 67 Apollo Drive, Rosedale, Auckland 0632, New Zealand (a division of Pearson New Zealand Ltd) Penguin Books (South Africa) (Pty) Ltd, 24 Sturdee Avenue, Rosebank, Johannesburg 2196, South Africa Penguin Books Ltd, Registered Offices: 80 Strand, London WC2R 0RL, England Published in 2011 by Viking Penguin, a member of Penguin Group (USA) Inc. Copyright © David Deutsch, 2011 All rights reserved Excerpts from The World of Parmenides by Karl Popper, edited by Arne F. Petersen (Routledge, 1998). Used by permission of the University of Klagenfurt, Karl Popper Library. Illustration on page 34: Starfield image from the Digitized Sky Survey (© AURA) courtesy of the Palomar Observatory and Digitized Sky Survey, created by the Space Telescope Science Institute, operated by AURA, Inc. for NASA. Reproduced with permission of AURA/STScI. Illustration on page 426: © Bettmann/Corbis LIBRARY OF CONGRESS CATALOGING IN PUBLICATION DATA Deutsch, David. The beginning of infinity : explanations that transform the world / David Deutsch. p. cm. Includes bibliographical references and index. ISBN: 978-1-101-54944-5 1. Explanation. 2. Infinite. 3. Science—Philosophy. I. Title. Q175.32.E97D48 2011 501—dc22 2011004120 Without limiting the rights under copyright reserved above, no part of this publication may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any form or by any means (electronic, mechanical, photocopying, recording or otherwise), without the prior written permission of both the copyright owner and the above publisher of this book. The scanning, uploading, and distribution of this book via the Internet or via any other means without the permission of the publisher is illegal and punishable by law. Please purchase only authorized electronic editions and do not participate in or encourage electronic piracy of copyrightable materials. Your support of the author’s rights is appreciated. Contents Acknowledgements vi Introduction vii 1. The Reach of Explanations 1 2. Closer to Reality 34 3. The Spark 42 4. Creation 78 5. The Reality of Abstractions 107 6. The Jump to Universality 125 7. Artificial Creativity 148 8. A Window on Infinity 164 9. Optimism 196 10. A Dream of Socrates 223 11. The Multiverse 258 12. A Physicist’s History of Bad Philosophy 305 13. Choices 326 14. Why are Flowers Beautiful? 353 15. The Evolution of Culture 369 16. The Evolution of Creativity 398 17. Unsustainable 418 18. The Beginning 443 Bibliography 460 Index 463 Acknowledgements I am grateful to my friends and colleagues Sarah Fitz-Claridge, Alan Forrester, Herbert Freudenheim, David Johnson-Davies, Paul Tappen- den and especially Elliot Temple and my copy-editor, Bob Davenport, for reading earlier drafts of this book and suggesting many corrections and improvements, and also to those who have read and helpfully commented on parts of it, namely Omri Ceren, Artur Ekert, Michael Golding, Alan Grafen, Ruti Regan, Simon Saunders and Lulie Tanett. I also want to thank the illustrators Nick Lockwood, Tommy Robin and Lulie Tanett for translating explanations into images more accurately than I could have hoped for. vi Introduction Progress that is both rapid enough to be noticed and stable enough to continue over many generations has been achieved only once in the history of our species. It began at approximately the time of the scientific revolution, and is still under way. It has included improve- ments not only in scientific understanding, but also in technology, political institutions, moral values, art, and every aspect of human welfare. Whenever there has been progress, there have been influential thinkers who denied that it was genuine, that it was desirable, or even that the concept was meaningful. They should have known better. There is indeed an objective difference between a false explanation and a true one, between chronic failure to solve a problem and solving it, and also between wrong and right, ugly and beautiful, suffering and its alleviation – and thus between stagnation and progress in the fullest sense. In this book I argue that all progress, both theoretical and practical, has resulted from a single human activity: the quest for what I call good explanations. Though this quest is uniquely human, its effective- ness is also a fundamental fact about reality at the most impersonal, cosmic level – namely that it conforms to universal laws of nature that are indeed good explanations. This simple relationship between the cosmic and the human is a hint of a central role of people in the cosmic scheme of things. Must progress come to an end – either in catastrophe or in some sort of completion – or is it unbounded? The answer is the latter. That unboundedness is the ‘infinity’ referred to in the title of this book. Explaining it, and the conditions under which progress can and cannot vii introduction happen, entails a journey through virtually every fundamental field of science and philosophy. From each such field we learn that, although progress has no necessary end, it does have a necessary beginning: a cause, or an event with which it starts, or a necessary condition for it to take off and to thrive. Each of these beginnings is ‘the beginning of infinity’ as viewed from the perspective of that field. Many seem, superficially, to be unconnected. But they are all facets of a single attribute of reality, which I call the beginning of infinity. 1 The
================================================================================on specific types of chemicals, such as proteins. Could it be a universal constructor? Perhaps. It does manage to build with inorganic materials sometimes, such as the calcium phosphate in bones, or the magnetite in the navigation system inside a pigeon’s brain. Biotechnologists are already using it to manufacture hydrogen and to extract uranium from seawater. It can also program organisms to perform constructions outside their bodies: birds build nests; beavers build dams. Perhaps it would it be possible to specify, in the genetic code, an organism whose life cycle includes building a nuclear-powered spaceship. Or perhaps not. I guess it has some lesser, and not yet understood, universality. In 1994 the computer scientist and molecular biologist Leonard Adleman designed and built a computer composed of DNA together with some simple enzymes, and demonstrated that it was capable of performing some sophisticated computations. At the time, Adleman’s DNA computer was arguably the fastest computer in the world. Further, it was clear that a universal classical computer could be made in a similar way. Hence we know that, whatever that other universality of the DNA system was, the universality of computation had also been 145 the beginning of infinity inherent in it for billions of years, without ever being used – until Adleman used it. The mysterious universality of DNA as a constructor may have been the first universality to exist. But, of all the different forms of univer- sality, the most significant physically is the characteristic universality of people, namely that they are universal explainers, which makes them universal constructors as well. The effects of that universality are, as I have explained, explicable only by means of the full gamut of fundamental explanations. It is also the only kind of universality capable of transcending its parochial origins: universal computers cannot really be universal unless there are people present to provide energy and maintenance – indefinitely. And the same is true of all those other technologies. Even life on Earth will eventually be extinguished, unless people decide otherwise. Only people can rely on themselves into the unbounded future. terminology The jump to universality The tendency of gradually improving systems to undergo a sudden large increase in functionality, becoming uni v ersal in some domain. meanings of ‘the beginning of infinity’ encountered in this chapter – The existence of universality in many fields. – The jump to universality. – Error-correction in computation. – The fact that people are universal explainers. – The origin of life. – The mysterious universality to which the genetic code jumped. summary All knowledge growth is by incremental improvement, but in many fields there comes a point when one of the incremental improvements in a system of knowledge or technology causes a sudden increase in 146 The Jump to Universality reach, making it a universal system in the relevant domain. In the past, innovators who brought about such a jump to universality had rarely been seeking it, but since the Enlightenment they have been, and universal explanations have been valued both for their own sake and for their usefulness. Because error-correction is essential in processes of potentially unlimited length, the jump to universality only ever happens in digital systems. 147 7 Artificial Creativity Alan Turing founded the theory of classical computation in 1936 and helped to construct one of the first universal classical computers during the Second World War. He is rightly known as the father of modern computing. Babbage deserves to be called its grandfather, but, unlike Babbage and Lovelace, Turing did understand that artificial intelligence (AI) must in principle be possible because a universal computer is a universal simulator. In 1950, in a paper entitled ‘Computing Machinery and Intelligence’, he famously addressed the question: can a machine think? Not only did he defend the proposition that it can, on the grounds of universality, he also proposed a test for whether a program had achieved it. Now known as the Turing test, it is simply that a suitable (human) judge be unable to tell whether the program is human or not. In that paper and subsequently, Turing sketched protocols for carrying out his test. For instance, he suggested that both the program and a genuine human should separately interact with the judge via some purely textual medium such as a teleprinter, so that only the thinking abilities of the candidates would be tested, not their appearance. Turing’s test, and his arguments, set many researchers thinking, not only about whether he was right, but also about how to pass the test. Programs began to be written with the intention of investigating what might be involved in passing it. In 1964 the computer scientist Joseph Weizenbaum wrote a program called Eliza, designed to imitate a psychotherapist. He deemed psycho- therapists to be an especially easy type of human to imitate because the program could then give opaque answers about itself, and only ask questions based on the user’s own questions and statements. It was a remarkably simple program. Nowadays such programs are popular 148 Artificial Creativity projects for students of programming, because they are fun and easy to write. A typical one has two basic strategies. First it scans the input for certain keywords and grammatical forms. If this is successful, it replies based on a template, filling in the blanks using words in the input. For instance, given the input I hate my job, the program might recognize the grammar of the sentence, involving a possessive pronoun ‘my’, and might also recognize ‘hate’ as a keyword from a built-in list such as ‘love/hate/like/dislike/want’, in which case it could choose a suitable template and reply: What do you hate most about your job? If it cannot parse the input to that extent, it asks a question of its own, choosing randomly from a stock pattern which may or may not depend on the input sentence. For instance, if asked How does a television work?, it might reply, What is so interesting about “How does a television work?”? Or it
================================================================================theory by including creative processes such as explanation and persuasion in its mathematical model of decision-making? Because it is not known how to model a creative process. Such a model would be a creative process: an AI. The conditions of ‘fairness’ as conceived in the various social-choice problems are misconceptions analogous to empiricism: they are all about the input to the decision-making process – who participates, and how their opinions are integrated to form the ‘preference of the group’. A rational analysis must concentrate instead on how the rules and institutions contribute to the removal of bad policies and rulers, and to the creation of new options. 345 the beginning of infinity Sometimes such an analysis does endorse one of the traditional requirements, at least in part. For instance, it is indeed important that no member of the group be privileged or deprived of representation. But this is not so that all members can contribute to the answer. It is because such discrimination entrenches in the system a preference among their potential criticisms. It does not make sense to include everyone’s favoured policies, or parts of them, in the new decision; what is necessary for progress is to exclude ideas that fail to survive criticism, and to prevent their entrenchment, and to promote the creation of new ideas. Proportional representation is often defended on the grounds that it leads to coalition governments and compromise policies. But com - promises – amalgams of the policies of the contributors – have an undeservedly high reputation. Though they are certainly better than immediate violence, they are generally, as I have explained, bad policies. If a policy is no one’s idea of what will work, then why should it work? But that is not the worst of it. The key defect of compromise policies is that when one of them is implemented and fails, no one learns anything because no one ever agreed with it. Thus compromise policies shield the underlying explanations which do at least seem good to some faction from being criticized and abandoned. The system used to elect members of the legislatures of most countries in the British political tradition is that each district (or ‘constituency’) in the country is entitled to one seat in the legislature, and that seat goes to the candidate with the largest number of votes in that district. This is called the plurality voting system (‘plurality’ meaning ‘largest number of votes’) – often called the ‘first-past-the-post’ system, because there is no prize for any runner-up, and no second round of voting (both of which feature in other electoral systems for the sake of increasing the proportionality of the outcomes). Plurality voting typically ‘over- represents’ the two largest parties, compared with the proportion of votes they receive. Moreover, it is not guaranteed to avoid the population paradox, and is even capable of bringing one party to power when another has received far more votes in total. These features are often cited as arguments against plurality voting and in favour of a more proportional system – either literal proportional representation or other schemes such as transferable-vote systems and 346 Choices run-off systems which have the effect of making the representation of voters in the legislature more proportional. However, under Popper’s criterion, that is all insignificant in comparison with the greater ef fective n ess of plurality voting at removing bad governments and policies. Let me trace the mechanism of that advantage more explicitly. Following a plurality-voting election, the usual outcome is that the party with the largest total number of votes has an overall majority in the legislature, and therefore takes sole charge. All the losing parties are removed entirely from power. This is rare under proportional representation, because some of the parties in the old coalition are usually needed in the new one. Consequently, the logic of plurality is that politicians and political parties have little chance of gaining any share in power unless they can persuade a substantial proportion of the population to vote for them. That gives all parties the incentive to find better explanations, or at least to convince more people of their existing ones, for if they fail they will be relegated to powerlessness at the next election. In the plurality system, the winning explanations are then exposed to criticism and testing, because they can be implemented without mixing them with the most important claims of opposing agendas. Similarly, the winning politicians are solely responsible for the choices they make, so they have the least possible scope for making excuses later if those are deemed to have been bad choices. If, by the time of the next election, they are less convincing to the voters than they were, there is usually no scope for deals that will keep them in power regardless. Under a proportional system, small changes in public opinion seldom count for anything, and power can easily shift in the opposite direction to public opinion. What counts most is changes in the opinion of the leader of the third-largest party. This shields not only that leader but most of the incumbent politicians and policies from being removed from power through voting. They are more often removed by losing support within their own party, or by shifting alliances between parties. So in that respect the system badly fails Popper’s criterion. Under plurality voting, it is the other way round. The all-or-nothing nature of the constituency elections, and the consequent low representation of small parties, makes the overall outcome sensitive to small changes 347 the beginning of infinity in opinion. When there is a small shift in opinion away from the ruling party, it is usually in real danger of losing power completely. Under proportional representation, there are strong incentives for the system’s characteristic unfairnesses to persist, or to become worse, over time. For example, if a small faction defects from a large party, it may then end up with more chance of having its policies tried out than it would if its
================================================================================