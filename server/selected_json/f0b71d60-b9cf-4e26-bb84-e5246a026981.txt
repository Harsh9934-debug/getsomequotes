creativity is an unlikely target for sexual selection. It is a sophis- ticated adaptation which, to this day, we are unable to reproduce artificially. So it is presumably much harder to evolve than attributes like coloration or the size and shape of body parts – some of which, it is thought, did indeed evolve by sexual selection in humans and many other animals. Creativity, as far as we know, evolved only once. More- over, its most visible effects are cumulative: it would be hard to detect small differences in the creativity of potential mates on any one oc - casion, especially if that creativity was not being used for practical purposes. (Consider how hard it would be, today, to detect tiny genetic differences in people’s artistic abilities by means of an art competition. In practice, any such differences would be swamped by other factors.) So why did we not evolve multi-coloured hair or fingernails instead of the capacity to create new knowledge, or any one of countless other attributes that would have been far easier to evolve, and far easier to assess reliably? A more plausible variant of the sexual-selection theory is that people chose mates according to social status, rather than favouring creativity directly. Perhaps the most creative individuals were able to gain status more effectively though intrigue or other social manipulation. This could have given them an evolutionary advantage without producing any progress of which we would see evidence. However, all such theories still face the problem of explaining why, if creativity was being used intensively for any purpose, it was not also used for functional 401 the beginning of infinity purposes. Why would a chief who had gained power through creative intrigue not be thinking about better spears for hunting? Why wouldn’t a subordinate who invented such a thing have been favoured? Similarly, wouldn’t potential mates who were impressed by artistic displays also have been impressed by practical innovations? In any case, some practical innovations would themselves have helped the discoverers to produce better displays. And innovations sometimes have reach: a new skill of making a string of decorative beads in one generation might become the skill of making a slingshot in the next. So why were practical innovations originally so rare? From the discussion in the previous chapter, one might guess that it was because the tribes or families in which people were living were static societies, in which any noticeable innovation would reduce one’s status and hence presumably one’s eligibility to mate. So how does one gain status, specifically by exercising more creativity than anyone else, without becoming noticeable as a taboo-violator? I think there is only one way: it is to enact that society’s memes more faithfully than the norm. To display exceptional conformity and obedi- ence. To refrain exceptionally well from innovation. A static society has no choice but to reward that sort of conspicuousness. So – can enhanced creativity help one to be less innovative than other people? That turns out to be a pivotal question, to which I shall return below. But first I must address a second puzzle. How do you replicate a meaning? Meme replication is often characterized (for example by Blackmore) as imitation. But that cannot be so. A meme is an idea, and we cannot observe ideas inside other people’s brains. Nor do we have the hardware to download them from one brain to another like computer programs, nor to replicate them like DNA molecules. So we cannot literally copy or imitate memes. The only access we have to their content is through their holders’ behaviour (including their speech, and consequences of their behaviour such as their writings). Meme replication always follows this pattern: one observes the holders’ behaviour, directly or indirectly. Then, later – sometimes immediately, sometimes after years of such observation – memes from 402 The Evolution of Creativity the holders’ brains are present in one’s own brain. How do they get there? It looks a bit like induction, does it not? But induction is impossible. The process often seems to involve imitating the holders. For instance, we learn words by imitating their sounds; we learn how to wave by being waved to and imitating what we see. Thus, outwardly, and even to our own introspection, we appear to be copying aspects of what other people do, and remembering what they say and write. This common-sense misconception is even corroborated by the fact that our species’ closest living relatives, the great apes, also have a (much more limited, but nevertheless striking) ability to imitate. But, as I shall explain, the truth is that imitating people’s actions and remembering their utterances could not possibly be the basis of human meme rep - lication. In reality these play only a small – and for the most part inessential – role. Meme acquisition comes so naturally to us that it is hard to see what a miraculous process it is, or what is really happening. It is especially hard to see where the knowledge is coming from. There is a great deal of knowledge in even the simplest of human memes. When we learn to wave, we learn not only the gesture but also which aspects of the situation made it appropriate to wave, and how, and to whom. We are not told most of this, yet we learn it anyway. Similarly, when we learn a word, we also learn its meaning, including highly inexplicit subtleties. How do we acquire that knowledge? Not by imitating the holders. Popper used to begin his lecture course on the philosophy of science by asking the students simply to ‘observe’. Then he would wait in silence for one of them to ask what they were supposed to observe. This was his way of demonstrating one of many flaws in the empiricism that is still part of common sense today. So he would explain to them that scientific observation is impossible without pre-existing knowledge about what to look at, what to look for,
================================================================================is a kind of con - structor – it promotes a change among other chemicals while remaining unchanged itself. Those catalysts in turn control all the chemical production and regulatory functions of an organism, and hence define the organism itself, crucially including a process that makes a copy of the DNA. How that intricate mechanism evolved is not essential here, but for definiteness let me sketch one possibility. About four billion years ago – soon after the surface of the Earth had cooled sufficiently for liquid water to condense – the oceans were being churned by volcanoes, meteor impacts, storms and much stronger tides than today’s (because the moon was closer). They were also highly active chemically, with many kinds of molecules being continually formed and transformed, some spontaneously and some by catalysts. One such catalyst happened to catalyse the formation of some of the very kinds of molecules from which it itself was formed. That catalyst was not alive, but it was the first hint of life. It had not yet evolved to be a well-targeted catalyst, so it also accelerated the production of some other chemicals, including variants of itself. Those that were best at promoting their own production (and inhibiting their own destruction) relative to other variants became more numerous. They too promoted the construction of variants of themselves, and so evolution continued. Gradually, the ability of these catalysts to promote their own pro - duction became robust and specific enough for it to be worth calling them replicators. Evolution produced replicators that caused themselves to be replicated ever faster and more reliably. Different replicators began to join forces in groups, each of whose members specialized in causing one part of a complex web of chemical reactions whose net effect was to construct more copies of the entire group. Such a group was a rudimentary organism. At that point, life was at a stage roughly analogous to that of non-universal printing, or Roman numerals: it was no longer a case of each replicator for itself, but there was still no universal system being customized or programmed to produce specific substances. The most successful replicators may have been RNA molecules. They have catalytic properties of their own, depending on the precise sequence of their constituent molecules (or bases, which are similar to 143 the beginning of infinity those of DNA). As a result, the replication process became ever less like straightforward catalysis and ever more like programming – in a language, or genetic code, that used bases as its alphabet. Genes are replicators that can be interpreted as instructions in a genetic code. Genomes are groups of genes that are dependent on each other for replication. The process of copying a genome is called a living organism. Thus the genetic code is also a language for specifying organisms. At some point, the system switched to replicators made of DNA, which is more stable than RNA and therefore more suitable for storing large amounts of information. The familiarity of what happened next can obscure how remarkable and mysterious it is. Initially, the genetic code and the mechanism that interpreted it were both evolving along with everything else in the organisms. But there came a moment when the code stopped evolving yet the organisms continued to do so. At that moment the system was coding for nothing more complex than primitive, single-celled creatures. Yet virtually all subsequent organisms on Earth, to this day, have not only been based on DNA replicators but have used exactly the same alphabet of bases, grouped into three-base ‘words’, with only small variations in the meanings of those ‘words’. That means that, considered as a language for specifying organisms, the genetic code has displayed phenomenal reach. It evolved only to specify organisms with no nervous systems, no ability to move or exert forces, no internal organs and no sense organs, whose lifestyle consisted of little more than synthesizing their own structural constituents and then dividing in two. And yet the same language today specifies the hardware and software for countless multicellular behaviours that had no close analogue in those organisms, such as running and flying and breathing and mating and recognizing predators and prey. It also specifies engineering structures such as wings and teeth, and nano- technology such as immune systems, and even a brain that is capable of explaining quasars, designing other organisms from scratch, and wondering why it exists. During the entire evolution of the genetic code, it was displaying far less reach. It may be that each successive variant of it was used to specify only a few species that were very similar to each other. At any rate, it must have been a frequent occurrence that a species embodying 144 The Jump to Universality new knowledge was specified in a new variant of the genetic code. But then the evolution stopped, at a point when it had already attained enormous reach. Why? It looks like a jump to some sort of universality, does it not? What happened next followed the same sad pattern that I have described in other stories of universality: for well over a billion years after the system had reached universality and stopped evolving, it was still only being used to make bacteria. That means that the reach that we can now see that the system had was to remain unused for longer than the system itself had taken to evolve from non-living precursors. If intelligent extraterrestrials had visited Earth at any time during those billion years they would have seen no evidence that the genetic code could specify anything significantly different from the organisms that it had specified when it first appeared. Reach always has an explanation. But this time, to the best of my knowledge, the explanation is not yet known. If the reason for the jump in reach was that it was a jump to universality, what was the universality? The genetic code is presumably not universal for specify- ing life forms, since it relies
================================================================================instances of a physical object, some of their attributes must be diverse. Quantum computation Computation in which the flow of in - formation is not confined to a single history. summary The physical world is a multiverse, and its structure is determined by how information flows in it. In many regions of the multiverse, information flows in quasi-autonomous streams called histories, one of which we call our ‘universe’. Universes approximately obey the laws of classical (pre-quantum) physics. But we know of the rest of the multiverse, and can test the laws of quantum physics, because of the phenomenon of quantum interference. Thus a universe is not an exact but an emergent feature of the multiverse. One of the most unfamiliar and counter-intuitive things about the multiverse is fungibility. The laws of motion of the multiverse are deterministic, and apparent randomness is due to initially fungible instances of objects becoming different. In quantum physics, variables are typically discrete, and how they change from one value to another is a multiversal process involving interference and fungibility. 304 12 A Physicist’s History of Bad Philosophy With Some Comments on Bad Science By the way, what I have just outlined is what I call a ‘physi- cist’s history of physics’, which is never correct . . . Richard Feynman, QED: The Strange Theory of Light and Matter (1985) reader: So, I am an emergent, quasi-autonomous flow of information in the multiverse. david: You are. reader: And I exist in multiple instances, some of them different from each other, some not. And those are the least weird things about the world according to quantum theory. david: Yes. reader: But your argument is that we have no option but to accept the theory’s implications, because it is the only known explanation of many phenomena and has survived all known experimental tests. david: What other option would you like to have? reader: I’m just summarizing. david: Then yes: quantum theory does have universal reach. But if all you want to explain is how we know that there are other universes, you don’t have to go via the full theory. You need look no further than what a Mach–Zehnder interferometer does to a single photon: the path that was not taken affects the one that was. Or, if you want the same thing writ large, just think of a quantum computer: its output will depend on intermediate results being computed in vast numbers of different histories of the same few atoms. 305 the beginning of infinity reader: But that’s just a few atoms existing in multiple instances. Not people. david: Are you claiming to be made of something other than atoms? reader: Ah, I see. david: Also, imagine a vast cloud of instances of a single photon, some of which are stopped by a barrier. Are they absorbed by the barrier that we see, or is each absorbed by a different, quasi- autonomous barrier at the same location? reader: Does it make a difference? david: Yes. If they were all absorbed by the barrier we see, it would vaporize. reader: So it would. david: And we can ask – as I did in the story of the starship and the twilight zone – what is holding up those barriers? It must be other instances of the floor. And of the planet. And then we can consider the experimenters who set all this up and who observe the results, and so on. reader: So that trickle of photons through the interferometer really does provide a window on a vast multiplicity of universes. david: Yes. It’s another example of reach – just a small portion of the reach of quantum theory. The explanation of those experiments in isolation isn’t as hard to vary as the full theory. But in regard to the existence of other universes it’s incontrovertible all the same. reader: And that’s all there is to it? david: Yes. reader: But then why is it that only a small minority of quantum physicists agree? david: Bad philosophy. reader: What’s that? Quantum theory was discovered independently by two physicists who reached it from different directions: Werner Heisenberg and Erwin Schrödinger. The latter gave his name to the Schrödinger equation, which is a way of expressing the quantum-mechanical laws of motion. Both versions of the theory were formulated between 1925 and 1927, and both explained motion, especially within atoms, in new and as - tonishingly counter-intuitive ways. Heisenberg’s theory said that the 306 A Physicist’s History of Bad Philosophy physical variables of a particle do not have numerical values. Instead, they are matrices: large arrays of numbers which are related in com - plicated, probabilistic ways to the outcomes of observations of those variables. With hindsight, we now know that that multiplicity of information exists because a variable has different values for different instances of the object in the multiverse. But, at the time, neither Heisenberg nor anyone else believed that his matrix-valued quantities literally described what Einstein called ‘elements of reality’. The Schrödinger equation, when applied to the case of an individual particle, described a wave moving through space. But Schrödinger soon realized that for two or more particles it did not. It did not represent a wave with multiple crests, nor could it be resolved into two or more waves; mathematically, it was a single wave in a higher-dimensional space. With hindsight, we now know that such waves describe what proportion of the instances of each particle are in each region of space, and also the entanglement information among the particles. Although Schrödinger’s and Heisenberg’s theories seemed to describe very dissimilar worlds, neither of which was easy to relate to existing conceptions of reality, it was soon discovered that, if a certain simple rule of thumb was added to each theory, they would always make identical predictions. Moreover, these predictions turned out to be very successful. With hindsight, we can state the rule of thumb like this: whenever a measurement is made, all the histories but one cease
================================================================================david deutsch The Beginning of Infinity Explanations that Transform the World VIKING The Beginning of Infinity david deutsch The Beginning of Infinity Explanations that Transform the World VIKING VIKING Published by the Penguin Group Penguin Group (USA) Inc., 375 Hudson Street, New York, New York 10014, U.S.A. Penguin Group (Canada), 90 Eglinton Avenue East, Suite 700, Toronto, Ontario, Canada M4P 2Y3 (a division of Pearson Penguin Canada Inc.) Penguin Books Ltd, 80 Strand, London WC2R 0RL, England Penguin Ireland, 25 St. Stephen’s Green, Dublin 2, Ireland (a division of Penguin Books Ltd) Penguin Books Australia Ltd, 250 Camberwell Road, Camberwell, Victoria 3124, Australia (a division of Pearson Australia Group Pty Ltd) Penguin Books India Pvt Ltd, 11 Community Centre, Panchsheel Park, New Delhi – 110 017, India Penguin Group (NZ), 67 Apollo Drive, Rosedale, Auckland 0632, New Zealand (a division of Pearson New Zealand Ltd) Penguin Books (South Africa) (Pty) Ltd, 24 Sturdee Avenue, Rosebank, Johannesburg 2196, South Africa Penguin Books Ltd, Registered Offices: 80 Strand, London WC2R 0RL, England Published in 2011 by Viking Penguin, a member of Penguin Group (USA) Inc. Copyright © David Deutsch, 2011 All rights reserved Excerpts from The World of Parmenides by Karl Popper, edited by Arne F. Petersen (Routledge, 1998). Used by permission of the University of Klagenfurt, Karl Popper Library. Illustration on page 34: Starfield image from the Digitized Sky Survey (© AURA) courtesy of the Palomar Observatory and Digitized Sky Survey, created by the Space Telescope Science Institute, operated by AURA, Inc. for NASA. Reproduced with permission of AURA/STScI. Illustration on page 426: © Bettmann/Corbis LIBRARY OF CONGRESS CATALOGING IN PUBLICATION DATA Deutsch, David. The beginning of infinity : explanations that transform the world / David Deutsch. p. cm. Includes bibliographical references and index. ISBN: 978-1-101-54944-5 1. Explanation. 2. Infinite. 3. Science—Philosophy. I. Title. Q175.32.E97D48 2011 501—dc22 2011004120 Without limiting the rights under copyright reserved above, no part of this publication may be reproduced, stored in or introduced into a retrieval system, or transmitted, in any form or by any means (electronic, mechanical, photocopying, recording or otherwise), without the prior written permission of both the copyright owner and the above publisher of this book. The scanning, uploading, and distribution of this book via the Internet or via any other means without the permission of the publisher is illegal and punishable by law. Please purchase only authorized electronic editions and do not participate in or encourage electronic piracy of copyrightable materials. Your support of the author’s rights is appreciated. Contents Acknowledgements vi Introduction vii 1. The Reach of Explanations 1 2. Closer to Reality 34 3. The Spark 42 4. Creation 78 5. The Reality of Abstractions 107 6. The Jump to Universality 125 7. Artificial Creativity 148 8. A Window on Infinity 164 9. Optimism 196 10. A Dream of Socrates 223 11. The Multiverse 258 12. A Physicist’s History of Bad Philosophy 305 13. Choices 326 14. Why are Flowers Beautiful? 353 15. The Evolution of Culture 369 16. The Evolution of Creativity 398 17. Unsustainable 418 18. The Beginning 443 Bibliography 460 Index 463 Acknowledgements I am grateful to my friends and colleagues Sarah Fitz-Claridge, Alan Forrester, Herbert Freudenheim, David Johnson-Davies, Paul Tappen- den and especially Elliot Temple and my copy-editor, Bob Davenport, for reading earlier drafts of this book and suggesting many corrections and improvements, and also to those who have read and helpfully commented on parts of it, namely Omri Ceren, Artur Ekert, Michael Golding, Alan Grafen, Ruti Regan, Simon Saunders and Lulie Tanett. I also want to thank the illustrators Nick Lockwood, Tommy Robin and Lulie Tanett for translating explanations into images more accurately than I could have hoped for. vi Introduction Progress that is both rapid enough to be noticed and stable enough to continue over many generations has been achieved only once in the history of our species. It began at approximately the time of the scientific revolution, and is still under way. It has included improve- ments not only in scientific understanding, but also in technology, political institutions, moral values, art, and every aspect of human welfare. Whenever there has been progress, there have been influential thinkers who denied that it was genuine, that it was desirable, or even that the concept was meaningful. They should have known better. There is indeed an objective difference between a false explanation and a true one, between chronic failure to solve a problem and solving it, and also between wrong and right, ugly and beautiful, suffering and its alleviation – and thus between stagnation and progress in the fullest sense. In this book I argue that all progress, both theoretical and practical, has resulted from a single human activity: the quest for what I call good explanations. Though this quest is uniquely human, its effective- ness is also a fundamental fact about reality at the most impersonal, cosmic level – namely that it conforms to universal laws of nature that are indeed good explanations. This simple relationship between the cosmic and the human is a hint of a central role of people in the cosmic scheme of things. Must progress come to an end – either in catastrophe or in some sort of completion – or is it unbounded? The answer is the latter. That unboundedness is the ‘infinity’ referred to in the title of this book. Explaining it, and the conditions under which progress can and cannot vii introduction happen, entails a journey through virtually every fundamental field of science and philosophy. From each such field we learn that, although progress has no necessary end, it does have a necessary beginning: a cause, or an event with which it starts, or a necessary condition for it to take off and to thrive. Each of these beginnings is ‘the beginning of infinity’ as viewed from the perspective of that field. Many seem, superficially, to be unconnected. But they are all facets of a single attribute of reality, which I call the beginning of infinity. 1 The
================================================================================that ‘infinite’ means something like ‘bigger than any finite combination of finite things’. But that informal notion is rather circular unless we have some independent idea of what makes something finite, and what makes a single act of ‘combination’ finite. The intuitive answer would be anthropocentric: something is definitely finite if it could in principle be encompassed by a human experience. But what does it mean to ‘experience’ something? Was Cantor experiencing infinity when he proved theorems about it? Or was he experiencing only symbols? But we only ever experience symbols. One can avoid this anthropocentrism by referring instead to measur- ing instruments: a quantity is definitely neither infinite nor infinitesimal if it could, in principle, register on some measuring instrument. How- ever, by that definition a quantity can be finite even if the underlying explanation refers to an infinite set in the mathematical sense. To display the result of a measurement the needle on a meter might move by one centimetre, which is a finite distance, but it consists of an uncountable infinity of points. This can happen because, although points appear in lowest-level explanations of what is happening, the number of points never appears in predictions. Physics deals in distances, not numbers of points. Similarly, Newton and Leibniz were able to use infinitesimal distances to explain physical quantities like instantaneous velocity, yet there is nothing physically infinitesimal or infinite in, say, the continuous motion of a projectile. To the management of Infinity Hotel, issuing a finite public-address announcement is a finite operation, even though it causes a trans- formation involving an infinite number of events in the hotel. On the other hand, most logically possible transformations could be achieved only with an infinite number of such announcements – which the laws of physics in their world do not allow. Remember, no one in Infinity Hotel – neither staff nor guest – ever performs more than a finite number of actions. Similarly in the Lyra multiverse, a measuring instrument can take the average of an infinite number of values during a finite, two-minute expedition. So that is a physically 181 the beginning of infinity finite operation in that world. But taking the ‘average’ of the same infinite set in a different order would require an infinite number of such trips, which, again, would not be possible under those laws of physics. Only the laws of physics determine what is finite in nature. Failure to realize this has often caused confusion. The paradoxes of Zeno of Elea, such as that of Achilles and the tortoise, were early examples. Zeno managed to conclude that, in a race against a tortoise, Achilles will never overtake the tortoise if it has a head start – because, by the time Achilles reaches the point where the tortoise began, the tortoise will have moved on a little. By the time he reaches that new point, it will have moved a little further, and so on ad infinitum. Thus the ‘catching-up’ procedure requires Achilles to perform an infinite number of catching-up steps in a finite time, which as a finite being he presumably cannot do. Do you see what Zeno did there? He just presumed that the math- ematical notion that happens to be called ‘infinity’ faithfully captures the distinction between finite and infinite that is relevant to that physical situation. That is simply false. If he is complaining that the mathematical notion of infinity does not make sense, then we can refer him to Cantor, who showed that it does. If he is complaining that the physical event of Achilles overtaking the tortoise does not make sense, then he is claiming that the laws of physics are inconsistent – but they are not. But if he is complaining that there is something inconsistent about motion because one could not experience each point along a continuous path, then he is simply confusing two different things that both happen to be called ‘infinity’. There is nothing more to all his paradoxes than that mistake. What Achilles can or cannot do is not deducible from mathematics. It depends only on what the relevant laws of physics say. If they say that he will overtake the tortoise in a given time, then overtake it he will. If that happens to involve an infinite number of steps of the form ‘move to a particular location’, then an infinite number of such steps will happen. If it involves his passing through an uncountable infinity of points, then that is what he does. But nothing physically infinite has happened. Thus the laws of physics determine the distinction not only between 182 A Window on Infinity rare and common, probable and improbable, fine-tuned or not, but even between finite and infinite. Just as the same set of universes can be packed with astrophysicists when measured under one set of laws of physics but have almost none when measured under another, so exactly the same sequence of events can be finite or infinite depending on what the laws of physics are. Zeno’s mistake has been made with various other mathematical abstractions too. In general terms, the mistake is to confuse an abstract attribute with a physical one of the same name. Since it is possible to prove theorems about the mathematical attribute, which have the status of absolutely necessary truths, one is then misled into assuming that one possesses a priori knowledge about what the laws of physics must say about the physical attribute. Another example was in geometry. For centuries, no clear distinction was made between its status as a mathematical system and as a physical theory – and at first that did little harm, because the rest of science was very unsophisticated compared with geometry, and Euclid’s theory was an excellent approximation for all purposes at the time. But then the philosopher Immanuel Kant (1724–1804), who was well aware of the distinction between the absolutely necessary truths of mathematics and the contingent truths of science, nevertheless concluded that Euclid’s theory of geometry
================================================================================future as to the past. Today on Earth, in the short run, there are still countless problems to be solved to eliminate even starvation and other forms of extreme human suffering that date back to prehistory. On a timescale of decades, we shall be faced with choices to make substantial modifi- cations to the biosphere, or to keep it the same, or anything in between. Whichever option we choose, it will be a project of planet-wide control, requiring the creation of a great deal of scientific and techn ological knowledge as well as knowledge about how to make such decisions rationally (see Chapter 13). In the even longer run, it is not only our comfort and aesthetic sensibilities, and the suffering of individ uals, that are problematic, but, as always, the survival of our species. For instance, at present during any given century there is about one chance in a thousand that the Earth will be struck by a comet or asteroid large enough to kill at least a substantial proportion of all human beings. That means that a typical child born in the United States today is more 62 The Spark likely to die as a result of an astronomical event than a car accident. Both are very low-probability events, but, unless we create a great deal more scientific and technological knowledge than we have now, we shall have no defence against those and other forms of natural disaster that must, eventually, strike. Arguably there are more immediate existential threats too – see Chapter 9. Setting up self-sufficient colonies on the moon and elsewhere in the solar system – and eventually in other solar systems – will be a good hedge against the extinction of our species or the destruction of civil- ization, and is a highly desirable goal for that reason among others. As Hawking has said: I don’t think the human race will survive the next thousand years, unless we spread into space. There are too many accidents that can befall life on a single planet. But I’m an optimist. We will reach out to the stars. Daily Telegraph, 16 October 2001 But even that will be far from an unproblematic state. And most people are not satisfied merely to be confident in the survival of the species: they want to survive personally. Also, like our earliest human ancestors, they want to be free from physical danger and suffering. In future, as various causes of suffering and death such as disease and ageing are successively addressed and eliminated, and human life spans increase, people will care about ever longer-term risks. In fact people will always want still more than that: they will want to make progress. For, in addition to threats, there will always be problems in the benign sense of the word: errors, gaps, inconsistencies and inadequacies in our knowledge that we wish to solve – including, not least, moral knowledge: knowledge about what to want, what to strive for. The human mind seeks explanations; and now that we know how to find them, we are not going to stop voluntarily. Here is another misconception in the Garden of Eden myth: that the supposed unproblematic state would be a good state to be in. Some theologians have denied this, and I agree with them: an unproblematic state is a state without creative thought. Its other name is death. All those kinds of problem (survival-related, progress-related, moral, and sheer-curiosity-driven problems) are connected. We can, for in - stance, expect that our ability to cope with existential threats will 63 the beginning of infinity continue to depend on knowledge that was originally created for its own sake. And we can expect disagreements about goals and values always to exist, because, among other reasons, moral explanations depend partly on facts about the physical world. For instance, the moral stances in the Principle of Mediocrity and the Spaceship Earth idea depend on the physical world not being explicable in the sense that I have argued it must be. Nor will we ever run out of problems. The deeper an explanation is, the more new problems it creates. That must be so, if only because there can be no such thing as an ultimate explanation: just as ‘the gods did it’ is always a bad explanation, so any other purported foundation of all explanations must be bad too. It must be easily variable because it cannot answer the question: why that foundation and not another? Nothing can be explained only in terms of itself. That holds for philosophy just as it does for science, and in particular it holds for moral philosophy: no utopia is possible, but only because our values and our objectives can continue to improve indefinitely. Thus fallibilism alone rather understates the error-prone nature of knowledge-creation. Knowledge-creation is not only subject to error: errors are common, and significant, and always will be, and correcting them will always reveal further and better problems. And so the maxim that I suggested should be carved in stone, namely ‘The Earth’s biosphere is incapable of supporting human life’ is actually a special case of a much more general truth, namely that, for people, problems are inevitable. So let us carve that in stone: PPRROOBBLLEEMMSS AARREE IINNEEVVIITTAABBLLEE It is inevitable that we face problems, but no particular problem is inevitable. We survive, and thrive, by solving each problem as it comes 64 The Spark up. And, since the human ability to transform nature is limited only by the laws of physics, none of the endless stream of problems will ever constitute an impassable barrier. So a complementary and equally important truth about people and the physical world is that problems are soluble. By ‘soluble’ I mean that the right knowledge would solve them. It is not, of course, that we can possess knowledge just by wishing for it; but it is in principle accessible to us. So let us carve that in stone too: PPPRRROOOBBBLLLEEEMMMSSS AAARRREEE SSSOOOLLLUUUBBBLLLEEE That progress is both possible and
================================================================================all improvement. Thus, since the beginning of civilization and before, both the principal opportunities for progress and the principal obstacles to progress have consisted of ideas alone. These are the determinants of the broad sweep of history. The primeval distribution of horses or llamas or flint or uranium can affect only the details, and then only after some human being has had an idea for how to use those things. The effects of ideas and decisions almost entirely determine which biogeographical factors have a bearing on the next chapter of human history, and what that effect will be. Marx, Engels and Diamond have it the wrong way round. A thousand years is a long time for a static society to survive. We 429 the beginning of infinity think of the great centralized empires of antiquity which lasted even longer; but that is a selection effect: we have no record of most static societies, and they must have been much shorter-lived. A natural guess is that most were destroyed by the first challenge that would have required the creation of a significantly new pattern of behaviour. The isolated location of Easter Island, and the relatively hospitable nature of its environment, might have given its static society a longer lifespan than it would have had if it had been exposed to more tests by nature and by other societies. But even those factors are still largely human, not biogeographical: if the islanders had known how to make long-range ocean voyages, the island would not have been ‘isolated’ in the relevant sense. Likewise, how ‘hospitable’ Easter Island is depends on what the inhabitants know. If its settlers had known as little about survival techniques as I do, then they would not have survived their first week on the island. And, on the other hand, today thousands of people live on Easter Island without starving and without a forest – though now they are planting one because they want to and know how. The Easter Island civilization collapsed because no human situation is free of new problems, and static societies are inherently unstable in the face of new problems. Civilizations rose and collapsed on other South Pacific islands too – including Pitcairn Island. That was part of the broad sweep of history in the region. And, in the big picture, the cause was that they all had problems that they failed to solve. The Easter Islanders failed to navigate their way off the island, just as the Romans failed to solve the problem of how to change governments peacefully. If there was a forestry disaster on Easter Island, that was not what brought its inhabitants down: it was that they were chronically unable to solve the problem that this raised. If that problem had not dispatched their civilization, some other problem eventually would have. Sustaining their civilization in its static, statue-obsessed state was never an option. The only options were whether it would collapse suddenly and painfully, destroying most of what little knowledge they had, or change slowly and for the better. Perhaps they would have chosen the latter if only they had known how. We do not know what horrors the Easter Island civilization per - petrated in the course of preventing progress. But apparently its fall did not improve anything. Indeed, the fall of tyranny is never enough. 430 Unsustainable The sustained creation of knowledge depends also on the presence of certain kinds of idea, particularly optimism, and an associated tradition of criticism. There would have to be social and political institutions that incorporated and protected such traditions: a society in which some degree of dissent and deviation from the norm was tolerated, and whose educational practices did not entirely extinguish creativity. None of that is trivially achieved. Western civilization is the current conse quence of achieving it – which is why, as I said, it already has what it takes to avoid an Easter Island disaster. If it really is facing a crisis, it must be some other crisis. If it ever collapses, it will be in some other way and if it needs to be saved, it will have to be by its own, unique methods. In 1971, while I was still at school, I attended a lecture for high-school students entitled ‘Population, Resources, Environment’. It was given by the population scientist Paul Ehrlich. I do not remember what I was expecting – I don’t think I had ever heard of ‘the environment’ before – but nothing had prepared me for such a bravura display of raw pessimism. Ehrlich starkly described to his young audience the living hell we would be inheriting. Half a dozen varieties of resource- management catastrophe were just around the corner, and it was already too late to avoid some of them. People would be starving to death by the billion in ten years, twenty at best. Raw materials were running out: the Vietnam War, then in progress, was a last-ditch struggle for the region’s tin, rubber and petroleum. (Notice how his biogeographical explanation blithely shrugged off the political dis- agreements that were in fact causing the conflict.) The troubles of the day in American inner cities, rising crime, mental illness – all were part of the same great catastrophe. All were linked by Ehrlich to over- population, pollution and the reckless overuse of finite resources: we had created too many power stations and factories, and mines, and intensive farms – too much economic growth, far more than the planet could sustain. And, worst of all, too many people – the ultimate source of all the other ills. In this respect, Ehrlich was following in the footsteps of Malthus, making the same error: setting predictions of one process against prophecies of another. Thus he calculated that, if the United States was to sustain even its 1971 standard of living, it would have 431 the beginning of infinity to reduce its population by three-quarters, to 50 million – which was of course impossible in the time available.
================================================================================Fine-tuning The physicist Brandon Carter calculated in 1974 that if the strength of the interaction between charged particles were a few per cent smaller, no planets would ever have formed and the only condensed objects in the universe would be stars; and if it were a few per cent greater, then no stars would ever explode, and so no elements other than hydrogen and helium would exist outside them. In either case there would be no complex chemistry and hence presumably no life. Another example: if the initial expansion rate of the universe at the Big Bang had been slightly higher, no stars would have formed and there would be nothing in the universe but hydrogen – at an extremely low and ever-decreasing density. If it had been slightly lower, the 96 Creation universe would have recollapsed soon after the Big Bang. Similar results have been since obtained for other constants of physics that are not determined by any known theory. For most, if not all of them, it seems that if they had been slightly different, there would have been no possibility for life to exist. This is a remarkable fact which has even been cited as evidence that those constants were intentionally fine-tuned, i.e. designed, by a super- natural being. This is a new version of creationism, and of the design argument, now based on the appearance of design in the laws of physics. (Ironically, given the history of this controversy, the new argument is that the laws of physics must have been designed to create a biosphere by Darwinian evolution.) It even persuaded the philosopher Antony Flew – formerly an enthusiastic advocate of atheism – of the existence of a supernatural designer. But it should not have. As I shall explain in a moment, it is not even clear that this fine-tuning constitutes an appearance of design in Paley’s sense; but, even if it does, that does not alter the fact that invoking the supernatural makes for a bad explanation. And, in any case, arguing for supernatural explanations on the grounds that a current scientific explanation is flawed or lacking is just a mistake. As we carved in stone in Chapter 3, problems are inevitable – there are always unsolved problems. But they get solved. Science continues to make progress even, or especially, after making great discoveries, because the discoveries themselves reveal further problems. Therefore the existence of an unsolved problem in physics is no more evidence for a supernatural explanation than the existence of an unsolved crime is evidence that a ghost committed it. A simple objection to the idea that fine-tuning requires an explanation at all is that we have no good explanation implying that planets are essential to the formation of life, or that chemistry is. The physicist Robert Forward wrote a superb science-fiction story, Dragon’s Egg, based on the premise that information could be stored and processed – and life and intelligence could evolve – through the interactions between neutrons on the surface of a neutron star (a star that has collapsed gravitationally to a diameter of only a few kilometres, making it so dense that most of its matter has been transmuted into neutrons). It is not known whether this hypothetical neutron analogue of chemistry exists – nor whether it could exist if the laws of physics were slightly 97 the beginning of infinity different. Nor do we have any idea what other sorts of environment permitting the emergence of life would exist under those variant laws. (The idea that similar laws of physics can be expected to give rise to similar environments is undermined by the very existence of fine-tuning.) Nevertheless, regardless of whether the fine-tuning constitutes an appearance of design or not, it does constitute a legitimate and significant scientific problem, for the following reason. If the truth is that the constants of nature are not fine-tuned to produce life after all, because most slight variations in them do still permit life and intelligence to evolve somehow, though in dramatically different types of environment, then this would be an unexplained regularity in nature and hence a problem for science to address. If the laws of physics are fine-tuned, as they seem to be, then there are two possibilities: either those laws are the only ones to be instantiated in reality (as universes) or there are other regions of reality – parallel universes* – with different laws. In the former case, we must expect there to be an explanation of why the laws are as they are. It would either refer to the existence of life or not. If it did, that would take us back to Paley’s problem: it would mean that the laws had the ‘appearance of design’ for creating life, but had not evolved. Or the explanation would not refer to the existence of life, in which case it would leave unexplained why, if the laws are as they are for non-life- related reasons, they are fine-tuned to create life. If there are many parallel universes, each with its own laws of physics, most of which do not permit life, then the idea would be that the observed fine-tuning is only a matter of parochial perspective. It is only in the universes that contain astrophysicists that anyone ever wonders why the constants seem fine-tuned. This type of explanation is known as ‘anthropic reasoning’. It is said to follow from a principle known as the ‘weak anthropic principle’, though really no principle is required: it is just logic. (The qualifier ‘weak’ is there because several other anthropic principles have been proposed, which are more than just logic, but they need not concern us here.) *These are not the ‘parallel universes’ of the quantum multiverse, which I shall describe in Chapter 11. Those universes all obey the same laws of physics and are in constant slight interaction with each other. They are also much less speculative. 98 Creation However, on closer examination, anthropic arguments never quite finish the explanatory job.
================================================================================of stars and planets in our night sky have no significance for human affairs. We know that we are not at the centre of the universe – it does not even have a geometrical centre. And we know that, although some of the titanic astrophysical phenomena that I have described played a significant role in our past, we have never been significant to them. We call a phenomenon significant (or fundamental) if parochial theories are inadequate to explain it, or if it appears in the explanation of many other phenomena; so it may seem that human beings and their wishes and actions are extremely insignificant in the universe at large. Anthropocentric misconceptions have also been overturned in every other fundamental area of science: our knowledge of physics is now expressed entirely in terms of entities that are as impersonal as Euclid’s points and lines, such as elementary particles, forces and spacetime – a four-dimensional continuum with three dimensions of space and one of time. Their effects on each other are explained not in terms of feelings and intentions, but through mathematical equations expressing laws of nature. In biology, it was once thought that living things must have been designed by a supernatural person, and that they must contain some special ingredient, a ‘vital principle’, to make them behave with apparent purposefulness. But biological science discovered new modes of explanation through such impersonal things as chemical reactions, genes and evolution. So we now know that living things, including humans, all consist of the same ingredients as rocks and stars, and obey the same laws, and that they were not designed by anyone. Modern science, far from explaining physical phenomena in terms of the thoughts and intentions of unseen people, considers our own thoughts and intentions to be aggregates of unseen (though not un - seeable) microscopic physical processes in our brains. So fruitful has this abandonment of anthropocentric theories been, and so important in the broader history of ideas, that anti-anthro- pocentrism has increasingly been elevated to the status of a universal principle, sometimes called the ‘Principle of Mediocrity’: there is 43 the beginning of infinity nothing significant about humans (in the cosmic scheme of things). As the physicist Stephen Hawking put it, humans are ‘just a chemical scum on the surface of a typical planet that’s in orbit round a typical star on the outskirts of a typical galaxy’. The proviso ‘in the cosmic scheme of things’ is necessary because the chemical scum evidently does have a special significance according to values that it applies to itself, such as moral values. But the Principle says that all such values are them- selves anthropocentric: they explain only the behaviour of the scum, which is itself insignificant. It is easy to mistake quirks of one’s own, familiar environment or perspective (such as the rotation of the night sky) for objective features of what one is observing, or to mistake rules of thumb (such as the prediction of daily sunrises) for universal laws. I shall refer to that sort of error as parochialism. Anthropocentric errors are examples of parochialism, but not all parochialism is anthropocentric. For instance, the prediction that the seasons are in phase all over the world is a parochial error but not an anthropocentric one: it does not involve explaining seasons in terms of people. Another influential idea about the human condition is sometimes given the dramatic name Spaceship Earth. Imagine a ‘generation ship’ – a spaceship on a journey so long that many generations of passengers live out their lives in transit. This has been proposed as a means of colonizing other star systems. In the Spaceship Earth idea, that generation ship is a metaphor for the biosphere – the system of all living things on Earth and the regions they inhabit. Its passengers represent all humans on Earth. Outside the spaceship, the universe is implacably hostile, but the interior is a vastly complex life-support system, capable of providing everything that the passengers need to thrive. Like the spaceship, the biosphere recycles all waste and, using its capacious nuclear power plant (the sun), it is completely self-sufficient. Just as the spaceship’s life-support system is designed to sustain its passengers, so the biosphere has the ‘appearance of design’: it seems highly adapted to sustaining us (claims the metaphor) because we were adapted to it by evolution. But its capacity is finite: if we overload it, either by our sheer numbers or by adopting lifestyles too different from 44 The Spark those that we evolved to live (the ones that it is ‘designed’ to support), it will break down. And, like the passengers on that spaceship, we get no second chances: if our lifestyle becomes too careless or profligate and we ruin our life-support system, we have nowhere else to go. The Spaceship Earth metaphor and the Principle of Mediocrity have both gained wide acceptance among scientifically minded people – to the extent of becoming truisms. This is despite the fact that, on the face of it, they argue in somewhat opposite directions: the Principle of Mediocrity stresses how typical the Earth and its chemical scum are (in the sense of being unremarkable), while Spaceship Earth stresses how untypical they are (in the sense of being uniquely suited to each other). But when the two ideas are interpreted in broad, philosophical ways, as they usually are, they can easily converge. Both see themselves as correcting much the same parochial misconceptions, namely that our experience of life on Earth is representative of the universe, and that the Earth is vast, fixed and permanent. They both stress instead that it is tiny and ephemeral. Both oppose arrogance: the Principle of Mediocrity opposes the pre-Enlightenment arrogance of believing ourselves significant in the world; the Spaceship Earth metaphor opposes the Enlightenment arrogance of aspiring to control the world. Both have a moral element: we should not consider ourselves signifi- cant, they assert; we should not expect the world to submit indefinitely to our depredations. Thus
================================================================================a token of how much knowledge they contain. The selfish meme If a gene is in a genome at all, then, when suitable circumstances arise, it will definitely be expressed as an enzyme, as I described in Chapter 6, and will then cause its characteristic effects. Nor can it be left behind if the rest of its genome is successfully replicated. But merely being present in a mind does not automatically get a meme expressed as behaviour: the meme has to compete for that privilege with other ideas – memes and non-memes, about all sorts of subjects – in the same mind. And merely being expressed as behaviour does not automatically get the meme copied into a recipient along with other memes: it has to compete for the recipients’ attention and acceptance with all sorts of behaviours by other people, and with the recipient’s own ideas. All that is in addition to the analogue of the type of selection that genes face, each meme competing with rival versions of itself across the population, perhaps by containing the knowledge for some useful function. Memes are subject to all sorts of random and intentional variation in addition to all that selection, and so they evolve. So to this extent the same logic holds as for genes: memes are ‘selfish’. They do not necessarily evolve to benefit their holders, or their society – or, again, even themselves, except in the sense of replicating better than other memes. (Though now most other memes are their rivals, not just variants of themselves.) The successful meme variant is the one that changes the behaviour of its holders in such a way as to make itself best at displacing other memes from the population. This variant may well benefit its holders, or their culture, or the species as a whole. But if it harms them, or destroys them, it will spread anyway. Memes that harm society are a familiar phenomenon. You need only consider the harm done by adherents of political views, or religions, that you 378 The Evolution of Culture especially abhor. Societies have been destroyed because some of the memes that were best at spreading through the population were bad for a society. I shall discuss one example in Chapter 17. And countless individuals have been harmed or killed by adopting memes that were bad for them – such as irrational political ideologies or dangerous fads. Fortunately, in the case of memes, that is not the whole story. To understand the rest of the story, we have to consider the basic strategies by which memes cause themselves to be faithfully replicated. Static societies As I have explained, a human brain – quite unlike a genome – is itself an arena of intense variation, selection and competition. Most ideas within a brain are created by it for the very purpose of trying them out in imagination, criticizing them, and varying them until they meet the person’s preferences. In other words, meme replication itself in - volves evolution, within individual brains. In some cases there can be thousands of cycles of variation and selection before any of the variants is ever enacted. Then, even after a meme has been copied into a new holder, it has not yet completed its life cycle. It still has to survive a further selection process, namely the holder’s choice of whether to enact it or not. Some of the criteria that a mind uses to make such choices are themselves memes. Some are ideas that it has created for itself (by altering memes, or otherwise), and which will never exist in any other mind. Such ideas are potentially highly variable between different people, yet they can decisively affect whether any given meme does or does not survive via a given person. Since a person can enact and transmit a meme soon after receiving it, a meme generation can be much shorter than a human generation. And many cycles of variation and selection can take place inside the minds concerned even during one meme generation. Also, memes can be passed to people other than the holders’ biological descendants. Those factors make meme evolution enormously faster than gene evolution, which partly explains how memes can contain so much knowledge. Hence the frequently cited metaphor of the history of life on Earth, in which human civilization occupies only the final ‘second’ 379 the beginning of infinity of the ‘day’ during which life has so far existed, is misleading. In reality, a substantial proportion of all evolution on our planet to date has occurred in human brains. And it has barely begun. The whole of biological evolution was but a preface to the main story of evolution, the evolution of memes. But, for the same reason, on the face of it meme replication is inherently less reliable than gene replication. Since the inexplicit content of memes cannot be literally copied but has to be guessed from the holders’ behaviour, and since a meme can be subjected to large intentional variations inside every holder, it could be considered some- thing of a miracle that any meme manages to be transmitted faithfully even once. And indeed the survival strategies of all long-lived memes are dominated by this problem. Another way of stating the problem is that people think and try to improve upon their ideas – which entails changing them. A long-lived meme is an idea that runs that gauntlet again and again, and survives. How is that possible? The post-Enlightenment West is the only society in history that for more than a couple of lifetimes has ever undergone change rapid enough for people to notice. Short-lived rapid changes have always happened: famines, plagues and wars have begun and ended; maverick kings have attempted radical change. Occasionally empires were rapidly created or whole civilizations were rapidly destroyed. But, while a society lasted, all important areas of life seemed changeless to the participants: they could expect to die under much the same moral values, personal lifestyles, conceptual framework,
================================================================================of it ever causes any changes. The transformed cube contains even more evidence, most of it having been created locally, and is detecting it with ever- improving instruments and changing rapidly as a result. A typical cube is not emitting any energy; the transformed cube may well be broad- casting explanations into space. But perhaps the biggest physical difference is that, like all knowledge-creating systems, the transformed cube corrects errors. You would notice this if you tried to modify or harvest the matter in it: it would resist! It appears, nevertheless, that most environments are not yet creating any knowledge. We know of none that is, except on or near the Earth, and what we see happening elsewhere is radically different from what would happen if knowledge-creation were to become widespread. But the universe is still young. An environment that is not currently creating anything may do so in the future. What will be typical in the distant future could be very different from what is typical now. Like an explosive awaiting a spark, unimaginably numerous environ- ments in the universe are waiting out there, for aeons on end, doing nothing at all or blindly generating evidence and storing it up or pouring it out into space. Almost any of them would, if the right knowledge ever reached it, instantly and irrevocably burst into a radically different type of physical activity: intense knowledge-creation, displaying all the various kinds of complexity, universality and reach that are inherent in the laws of nature, and transforming that environ- ment from what is typical today into what could become typical in the future. If we want to, we could be that spark. terminology Person An entity that can create explanatory knowledge. Anthropocentric Centred on humans, or on persons. Fundamental or significant phenomenon: One that plays a necessary 75 the beginning of infinity role in the explanation of many phenomena, or whose distinctive features require distinctive explanation in terms of fundamental theories. Principle of Mediocrity ‘There is nothing significant about humans.’ Parochialism Mistaking appearance for reality, or local regularities for universal laws. Spaceship Earth ‘The biosphere is a life-support system for humans.’ Constructor A device capable of causing other objects to undergo transformations without undergoing any net change itself. Universal constructor A constructor that can cause any raw materials to undergo any physically possible transformation, given the right information. meanings of ‘the beginning of infinity’ encountered in this chapter – The fact that everything that is not forbidden by laws of nature is achievable, given the right knowledge. ‘Problems are soluble.’ – The ‘perspiration’ phase can always be automated. – The knowledge-friendliness of the physical world. – People are universal constructors. – The beginning of the open-ended creation of explanations. – The environments that could create an open-ended stream of know- ledge, if suitably primed – i.e. almost all environments. – The fact that new explanations create new problems. summary Both the Principle of Mediocrity and the Spaceship Earth idea are, contrary to their motivations, irreparably parochial and mistaken. From the least parochial perspectives available to us, people are the most significant entities in the cosmic scheme of things. They are not ‘supported’ by their environments, but support themselves by creating knowledge. Once they have suitable knowledge (essentially, the know- ledge of the Enlightenment), they are capable of sparking unlimited further progress. Apart from the thoughts of people, the only process known to be 76 The Spark capable of creating knowledge is biological evolution. The knowledge it creates (other than via people) is inherently bounded and parochial. Yet it also has close similarities with human knowledge. The similarities and the differences are the subject of the next chapter. 77 4 Creation The knowledge in human brains and the knowledge in biological adaptations are both created by evolution in the broad sense: the variation of existing information, alternating with selection. In the case of human knowledge, the variation is by conjecture, and the selection is by criticism and experiment. In the biosphere, the variation consists of mutations (random changes) in genes, and natural selection favours the variants that most improve the ability of their organisms to reproduce, thus causing those variant genes to spread through the population. That a gene is adapted to a given function means that few, if any, small changes would improve its ability to perform that function. Some changes might make no practical difference to that ability, but most of those that did would make it worse. In other words good adaptations, like good explanations, are distinguished by being hard to vary while still fulfilling their functions. Human brains and DNA molecules each have many functions, but among other things they are general-purpose information-storage media: they are in principle capable of storing any kind of information. Moreover, the two types of information that they respectively evolved to store have a property of cosmic significance in common: once they are physically embodied in a suitable environment, they tend to cause themselves to remain so. Such information – which I call knowledge – is very unlikely to come into existence other than through the error- correcting processes of evolution or thought. There are also important differences between those two kinds of knowledge. One is that biological knowledge is non-explanatory, and therefore has limited reach; explanatory human knowledge can have 78 Creation broad or even unlimited reach. Another difference is that mutations are random, while conjectures can be constructed intentionally for a purpose. Nevertheless, the two kinds of knowledge share enough of their underlying logic for the theory of evolution to be highly relevant to human knowledge. In particular, some historic misconceptions about biological evolution have counterparts in misconceptions about human knowledge. So in this chapter I shall describe some of those misconceptions in addition to the actual explanation of biological adaptations, namely modern Darwinian evolutionary theory, sometimes known as ‘neo-Darwinism’. Creationism Creationism is the idea that some supernatural being or beings designed and created all biological adaptations. In other words, ‘the gods did it.’
================================================================================bizarre occurrences and its entanglement information – would collapse into nothing, like the galaxy in Chapter 2 that became an emulsion flaw. The multiverse explanation of the same events would be a bad *That this information is carried entirely locally in objects is currently somewhat controversial. For a detailed technical discussion see the paper ‘Information Flow in Entangled Quantum Systems’ by myself and Patrick Hayden (Proceedings of the Royal Society A456 (2000)). 281 the beginning of infinity explanation, and so the world would be inexplicable to the inhabitants if it were true. It may seem that, by imposing all those conditions on information flow, we have gone to a lot of trouble to achieve that very attribute – to hide, from the inhabitants, the Byzantine intricacies of their world. In the words of Lewis Carroll’s White Knight in Through the Looking Glass, it is as if we were . . . thinking of a plan To dye one’s whiskers green, And always use so large a fan That they could not be seen. Now it is time to start removing the fan. In quantum physics, information flow in the multiverse is not as tame as in that branching tree of histories I have described. That is because of one further quantum phenomenon: under certain circum- stances, the laws of motion allow histories to rejoin (becoming fungible again). This is the time-reverse of the splitting (differentiation of history into two or more histories) that I have already described, so a natural way to implement it in our fictional multiverse is for the transporter to be capable of undoing its own history-splitting. If we represent the original splitting like this (cid:3514) X X Y where X is the normal voltage and Y is the anomalous one introduced by the transporter, then the rejoining of histories can be represented as X inter(cid:3514)ference X Y In an interference phenomenon, differentiated histories rejoin. 282 The Multiverse This phenomenon is known as interference: the presence of the Y-history interferes with what the transporter usually does to an X-history. Instead, the X and Y histories merge. This is rather like the doppelgängers merging with their originals in some phantom-zone stories, except that here we do not need to repeal the principle of the conservation of mass or any other conservation law: the total measure of all the histories remains constant. Interference is the phenomenon that can provide the inhabitants of the multiverse with evidence of the existence of multiple histories in their world without allowing the histories to communicate. For example, suppose that they run the transporter twice in quick succession (I shall explain in a moment what ‘quick’ means): (cid:3514) X (cid:3514) X X Y An interference experiment If they did this repeatedly (with, say, different copies of the transporter on each occasion), they could soon infer that the intermediate result could not be just randomly X or Y, because if it were then the final outcome would sometimes be Y (because of ), while in fact it is always X. Thus the inhabitants would no longer be able to explain away what they see by assuming that only one, randomly chosen, value of the voltage is real at the intermediate stage. Although such an experiment would provide evidence that multiple histories not only exist but affect each other strongly (in the sense that they behave differently according to whether the other is present or absent), it does not involve inter-history communication (sending a message of one’s choice to the other history). In our story, just as we did not allow splitting to happen in a way that would allow communication faster than light, so we must ensure the same for interference. The simplest way is to require that the rejoining take place only if no wave of differentiation has happened. That is to say, the transporter can undo the voltage surge only if this has not yet caused any differential effects on anything else. When a 283 the beginning of infinity wave of differentiation, set off by two different values X and Y of some variable, has left an object, the object is entangled with all the differentially affected objects. Object Rest of world Object Rest of world X Not differentially (cid:3450) X Affected by X Y affected by X and Y Y Affected (differently) by Y not entangled entangled Entanglement So our rule, in short, is that interference can happen only in objects that are unentangled with the rest of the world. This is why, in the interference experiment, the two applications of the transporter have to be ‘in quick succession’. (Alternatively, the object in question has to be sufficiently well isolated for its voltages not to affect its surround- ings.) So we can represent a generic interference experiment symbolically as follows: Object Object Rest of world Rest of sp(cid:3514)litting X Not differentially X world Y affected by X and Y interference (cid:3515) Not differentially X affected by X and Y If an object is unentangled, it can be made to undergo interference by something acting on it alone. (The arrows ‘ ’ and ‘(cid:2)’ represent the action of the transporter.) Once the object is entangled with the rest of the world in regard to the values X and Y, no operation on the object alone can create interference between those values. Instead, the histories are merely split further, in the usual way: 284 The Multiverse ObjectRest of world Object Rest of world Object Rest of world X Unaffected sp(cid:3514)litting X Y afN feo ct t ed dif f be yre Xn t aia nl dly Y entan(cid:3450)glement X Y AffecteA df f (e dc it fe fed r eb ny t lX y) by Y no interference, just splitting (cid:3515) Rest of world X Affected by X Y Y X Affected (differently) by Y In entangled objects, further splitting happens instead of interference. When two or more values of a physical variable have differently affected something in the rest of the world, knock-on
================================================================================though the situations themselves are quite straightforward. Dawkins gives an example in his book Unweaving the Rainbow, analysing the claim that a television psychic was making accurate predictions: There are about 100,000 five-minute periods in a year. The probability that any given watch, say mine, will stop in a designated five-minute period is about 1 in 100,000. Low odds, but there are 10 million people watching the [television psychic’s] show. If only half of them are wearing watches, we could expect about 25 of those watches to stop in any given minute. If only a quarter of these ring in to the studio, that is 6 calls, more than enough to dumbfound a naive audience. Especially when you add in the calls from people whose watches stopped the day before, people whose watches didn’t stop but whose grandfather clocks did, people who died of heart attacks and their bereaved relatives phoned in to say that their ‘ticker’ gave out, and so on. As this example shows, the fact that certain circumstances can explain other events without being in any way involved in causing them is very familiar despite being counter-intuitive. The ‘naive’ audience’s mistake is a form of parochialism: they observe a phenomenon – people phoning in because their watches stopped – but they are failing to understand 279 the beginning of infinity it as part of a wider phenomenon, most of which they do not observe. Though the unobserved parts of that wider phenomenon have in no way affected what we, the viewers, observe, they are essential to its explanation. Similarly, common sense and classical physics contain the parochial error that only one history exists. This error, built into our language and conceptual framework, makes it sound odd to say that an event can be in one sense extremely unlikely and in another certain to happen. But there is nothing odd about it in reality. We are now seeing the interior of the spaceship as an overwhelmingly complex jumble of superposed objects. Most locations on board are packed with people, some of them on very unusual errands, and all unable to perceive each other. The spaceship itself is on many slightly different courses, due to slightly different behaviours of the crew. Of course we are ‘seeing’ this only in our mind’s eye. Our fictional laws of physics ensure that no observer in the multiverse itself would see anything like that. Consequently, on closer inspection (in our mind’s eye), we also see that there is great order and regularity in that apparent chaos. For instance, although there is a flurry of human figures in the Captain’s chair, we see that most of them are the Captain; and although there is a flurry of human figures in the Navigator’s chair, we see that few of them are the Captain. Regularities of that kind are ultimately due to the fact that all the universes, despite their differences, obey the same laws of physics (including their initial conditions). We also see that any particular instance of the Captain only ever interacts with one instance of the Navigator, and one instance of the First Officer; and those instances of the Navigator and First Officer are precisely the ones that interact with each other. These regularities are due to the fact that the histories are nearly autonomous: what happens in each of them depends almost entirely on previous events in that history alone – with transporter-induced voltage surges being the only exceptions. In the story so far, this autonomy of the histories is rather a trivial fact, since we began by making the universes autonomous. But it is going to be worth becoming even more pedantic for a moment: what exactly is the difference between the instance of you that I can interact with and the ones that are imperceptible to me? The latter are ‘in other universes’ – but, remember, universes consist only of the objects in them, so that amounts only to saying I can see 280 The Multiverse the ones that I can see. The upshot is that our laws of physics must also say that every object carries within it information about which instances of it could interact with which instances of other objects (except when the instances are fungible, when there is no such thing as ‘which’). Quantum theory describes such information. It is known as entanglement information.* So far in the story we have set up a vast, complex world which looks very unfamiliar in our mind’s eye, but to the overwhelming majority of the inhabitants looks almost exactly like the single universe of our everyday experience and of classical physics, plus some apparently random jiggling whenever the transporter operates. A tiny minority of the histories have been significantly affected by very ‘unlikely’ events, but even in those the information flow – what affects what – is still very tame and familiar. For instance, a version of the ship’s log that contains records of bizarre coincidences will be perceptible to people who remember those coincidences, but not to other instances of those people. Thus the information in the fictional multiverse flows along a branching tree, whose branches – histories – have different thicknesses (measures) and never rejoin once they have separated. Each behaves exactly as if the others did not exist. If that were the whole story, that multiverse’s imaginary laws of physics would still be fatally flawed as explanations in the same way that they have been all along: there would be no difference between their predictions and those of much more straightforward laws saying that there is only one universe – one history – in which the transporter randomly introduces a change in the objects that it teleports. Under those laws, instead of branching into two autonomous histories on such occasions, the single history randomly does or does not undergo such a change. Thus the entire stupendously complicated multiverse that we have imagined – with its multiplicity of entities including people walking through each other and its
================================================================================shall see if we look at the sky), but about what stars are: their composition and what makes them shine, and how they formed, and the universal laws of physics under which that happened. Most of that has never been observed: no one has experienced a billion years, or a light year; no one could have been present at the Big Bang; no one will ever touch a law of physics – except in their minds, through theory. All our predictions of how things will look are deduced from such explanations of how things are. So inductivism fails even to address how we can know about stars and the universe, as distinct from just dots in the sky. The second fundamental misconception in inductivism is that scientific theories predict that ‘the future will resemble the past’, and that ‘the unseen resembles the seen’ and so on. (Or that it ‘probably’ will.) But in reality the future is unlike the past, the unseen very different from the seen. Science often predicts – and brings about – phenomena spectacularly different from anything that has been experienced before. For millennia people dreamed about flying, but they experienced only falling. Then they discovered good explanatory theories about flying, and then they flew – in that order. Before 1945, no human being had ever observed a nuclear-fission (atomic-bomb) explosion; there may never have been one in the history of the universe. Yet the first such explosion, and the conditions under which it would occur, had been accurately predicted – but not from the assumption that the future would be like the past. Even sunrise – that favourite example of inductivists – is not always observed every twenty-four hours: when viewed from orbit it may happen every ninety minutes, or not at all. And that was known from theory long before anyone had ever orbited the Earth. It is no defence of inductivism to point out that in all those cases the future still does ‘resemble the past’ in the sense that it obeys the 6 The Reach of Explanations same underlying laws of nature. For that is an empty statement: any purported law of nature – true or false – about the future and the past is a claim that they ‘resemble’ each other by both conforming to that law. So that version of the ‘principle of induction’ could not be used to derive any theory or prediction from experience or anything else. Even in everyday life we are well aware that the future is unlike the past, and are selective about which aspects of our experience we expect to be repeated. Before the year 2000, I had experienced thousands of times that if a calendar was properly maintained (and used the standard Gregorian system), then it displayed a year number beginning with ‘19’. Yet at midnight on 31 December 1999 I expected to have the experience of seeing a ‘20’ on every such calendar. I also expected that there would be a gap of 17,000 years before anyone experienced a ‘19’ under those conditions again. Neither I nor anyone else had ever observed such a ‘20’, nor such a gap, but our explanatory theories told us to expect them, and expect them we did. As the ancient philosopher Heraclitus remarked, ‘No man ever steps in the same river twice, for it is not the same river and he is not the same man.’ So, when we remember seeing sunrise ‘repeatedly’ under ‘the same’ circumstances, we are tacitly relying on explanatory theories to tell us which combinations of variables in our experience we should interpret as being ‘repeated’ phenomena in the underlying reality, and which are local or irrelevant. For instance, theories about geometry and optics tell us not to expect to see a sunrise on a cloudy day, even if a sunrise is really happening in the unobserved world behind the clouds. Only from those explanatory theories do we know that failing to see the sun on such days does not amount to an experience of its not rising. Similarly, theory tells us that if we see sunrise reflected in a mirror, or in a video or a virtual-reality game, that does not count as seeing it twice. Thus the very idea that an experience has been repeated is not itself a sensory experience, but a theory. So much for inductivism. And since inductivism is false, empiricism must be as well. For if one cannot derive predictions from experience, one certainly cannot derive explanations. Discovering a new explanation is inherently an act of creativity. To interpret dots in the sky as white- hot, million-kilometre spheres, one must first have thought of the idea of such spheres. And then one must explain why they look small and 7 the beginning of infinity cold and seem to move in lockstep around us and do not fall down. Such ideas do not create themselves, nor can they be mechanically derived from anything: they have to be guessed – after which they can be criticized and tested. To the extent that experiencing dots ‘writes’ something into our brains, it does not write explanations but only dots. Nor is nature a book: one could try to ‘read’ the dots in the sky for a lifetime – many lifetimes – without learning anything about what they really are. Historically, that is exactly what happened. For millennia, most careful observers of the sky believed that the stars were lights embedded in a hollow, rotating ‘celestial sphere’ centred on the Earth (or that they were holes in the sphere, through which the light of heaven shone). This geocentric – Earth-centred – theory of the universe seemed to have been directly derived from experience, and repeatedly confirmed: anyone who looked up could ‘directly observe’ the celestial sphere, and the stars maintaining their relative positions on it and being held up just as the theory predicts. Yet in reality, the solar system is heliocentric – centred on the sun, not the Earth – and
================================================================================parochial error. Civilizations starved, long before Malthus, because of what they thought of as the ‘natural disasters’ of drought and famine. But it was really because of what we would call poor methods of irrigation and farming – in other words, lack of knowledge. Before our ancestors learned how to make fire artificially (and many times since then too), people must have died of exposure literally on top of the means of making the fires that would have saved their lives, because they did not know how. In a parochial sense, the weather killed them; but the deeper explanation is lack of knowledge. Many of the hundreds of millions of victims of cholera throughout history must have died within sight of the hearths that could have boiled their drinking water and saved their lives; but, again, they did not know that. Quite generally, the distinction between a ‘natural’ disaster and one brought about by ignorance is parochial. Prior to every natural disaster that people once used to think of as ‘just happening’, or being ordained by gods, we now see many options that the people affected failed to take – or, rather, to create. And all those options add up to the overarching option that they failed to create, namely that of form- ing a scientific and technological civilization like ours. Traditions of criticism. An Enlightenment. If a one-kilometre asteroid had approached the Earth on a collision course at any time in human history before the early twenty-first century, it would have killed at least a substantial proportion of all humans. In that respect, as in many others, we live in an era of un - precedented safety: the twenty-first century is the first ever moment when we have known how to defend ourselves from such impacts, which occur once every 250,000 years or so. This may sound too rare to care about, but it is random. A probability of one in 250,000 of such an impact in any given year means that a typical person on Earth would have a far larger chance of dying of an asteroid impact than in an aeroplane crash. And the next such object to strike us is already out there at this moment, speeding towards us with nothing to stop it except human knowledge. Civilization is vulnerable to several other known types of disaster with similar levels of risk. For instance, ice 207 the beginning of infinity ages occur more frequently than that, and ‘mini ice ages’ much more frequently – and some climatologists believe that they can happen with only a few years’ warning. A ‘super-volcano’ such as the one lurking under Yellowstone National Park could blot out the sun for years at a time. If it happened tomorrow our species could survive, by growing food using artificial light, and civilization could recover. But many would die, and the suffering would be so tremendous that such events should merit almost as much preventative effort as an extinction. We do not know the probability of a spontaneously occurring incurable plague, but we may guess that it is unacceptably high, since pandemics such as the Black Death in the fourteenth century have already shown us the sort of thing that can happen on a timescale of centuries. Should any of those catastrophes loom, we now have at least a chance of creating the knowledge required to survive, in time. We have such a chance because we are able to solve problems. Problems are inevitable. We shall always be faced with the problem of how to plan for an unknowable future. We shall never be able to afford to sit back and hope for the best. Even if our civilization moves out into space in order to hedge its bets, as Rees and Hawking both rightly advise, a gamma-ray burst in our galactic vicinity would still wipe us all out. Such an event is thousands of times rarer than an asteroid collision, but when it does finally happen we shall have no defence against it without a great deal more scientific knowledge and an enormous increase in our wealth. But first we shall have to survive the next ice age; and, before that, other dangerous climate change (both spontaneous and human-caused), and weapons of mass destruction and pandemics and all the countless unforeseen dangers that are going to beset us. Our political institutions, ways of life, personal aspirations and morality are all forms or embodi- ments of knowledge, and all will have to be improved if civilization – and the Enlightenment in particular – is to survive every one of the risks that Rees describes and presumably many others of which we have no inkling. So – how? How can we formulate policies for the unknown? If we cannot derive them from our best existing knowledge, or from dog - matic rules of thumb like blind optimism or pessimism, where can we derive them from? Like scientific theories, policies cannot be derived 208 Optimism from anything. They are conjectures. And we should choose between them not on the basis of their origin, but according to how good they are as explanations: how hard to vary. Like the rejection of empiricism, and of the idea that knowledge is ‘justified, true belief’, understanding that political policies are conjectures entails the rejection of a previously unquestioned philosophical as - sumption. Again, Popper was a key advocate of this rejection. He wrote: The question about the sources of our knowledge . . . has always been asked in the spirit of: ‘What are the best sources of our knowledge – the most reliable ones, those which will not lead us into error, and those to which we can and must turn, in case of doubt, as the last court of appeal?’ I propose to assume, instead, that no such ideal sources exist – no more than ideal rulers – and that all ‘sources’ are liable to lead us into error at times. And I propose to replace, therefore, the
================================================================================other staff assigned to their welfare. However, they are not allowed to ask those staff to do their work for them. That is because, if they all did this, the hotel would grind to a halt. Infinity is not magic. It has logical rules: that is the whole point of the Infinity Hotel thought experiment. The fallacious idea of delegating all one’s work to other staff in 173 the beginning of infinity higher-numbered rooms is called an infinite regress. It is one of the things that one cannot validly do with infinity. There is an old joke about the heckler who interrupts an astrophysics lecture to insist that the Earth is flat and supported on the back of elephants standing on a giant turtle. ‘What supports the turtle?’ asks the lecturer. ‘Another turtle.’ ‘What supports that turtle?’ ‘You can’t fool me,’ replies the heckler triumphantly: ‘it’s turtles from there on down.’ That theory is a bad explanation not because it fails to explain everything (no theory does), but because what it leaves unexplained is effectively the same as what it purports to explain in the first place. (The theory that the designer of the biosphere was designed by another designer, and so on ad infinitum, is another example of an infinite regress.) One day in Infinity Hotel, a guest’s pet puppy happens to climb into a trash bag. The owner does not notice, and passes the bag, with the puppy, to the next room. Within two minutes the puppy is nowhere. The distraught owner phones the front desk. The receptionist announces over the public- address system, ‘We apologize for the inconvenience, but an item of value has been inadvertently thrown away. Will all guests please undo all the trash-moving actions that they have just performed, in reverse order, starting as soon as you receive a trash bag from the next-higher-numbered room.’ But to no avail. None of the guests return any bags, because their fellow guests in the higher- numbered rooms are not returning any either. It was no exaggeration to say that the bags are nowhere. They have not been stuffed into a mythical ‘room number infinity’. They no longer exist; nor does the puppy. No one has done anything to the puppy except move it to another numbered room, within the hotel. Yet it is not in any room. It is not anywhere in the hotel, or anywhere else. In a finite hotel, if you move an object from room to room, in however complicated a pattern, it will end up in one of those rooms. Not so with an infinite number of rooms. Every individual action that the guests performed was both harmless to the puppy and 174 A Window on Infinity perfectly reversible. Yet, taken together, those actions annihilated the puppy and cannot be reversed. Reversing them cannot work, because, if it did, there would be no explanation for why a puppy arrived at its owner’s room and not a kitten. If a puppy did arrive, the explanation would have to be that a puppy was passed down from the next-higher-numbered room – and so on. But that whole infinite sequence of explanations never gets round to explaining ‘why a puppy?’ It is an infinite regress. What if, one day, a puppy did just arrive at room 1, having been passed down through all the rooms? That is not logically impossible: it would merely lack an explanation. In physics, the ‘nowhere’ from which such a puppy would have come is called a ‘naked singularity’. Naked singularities appear in some speculative theories in physics, but such theories are rightly criticized on the grounds that they cannot make predictions. As Hawking once put it, ‘Television sets could come out [of a naked singularity].’ It would be different if there were a law of nature determining what comes out – for in that case there would be no infinite regress and the singularity would not be ‘naked’. The Big Bang may have been a singularity of that relatively benign type. I said that the rooms are identical, but they do differ in one respect: their room numbers. So, given the types of tasks that the management request from time to time, the low-numbered rooms are the most desirable. For instance, the guest in room 1 has the unique privilege of never having to deal with anyone else’s trash. Moving to room 1 feels like winning first prize in a lottery. Moving to room 2 feels only slightly less so. But every guest has a room number that is unusually close to the beginning. So every guest in the hotel is more privileged than almost all other guests. The clichéd politician’s promise to favour everyone can be honoured in Infinity Hotel. Every room is at the beginning of infinity. That is one of the attributes of the unbounded growth of knowledge too: we are only just scratching the surface, and shall never be doing anything else. So there is no such thing as a typical room number at Infinity Hotel. Every room number is untypically close to the beginning. The intuitive idea that there must be ‘typical’ or ‘average’ members of any set of values is false for infinite sets. The same is true of the intuitive ideas of ‘rare’ and ‘common’. We might think that half of all natural numbers 175 the beginning of infinity are odd, and half even – so that odd and even numbers are equally common among the natural numbers. But consider the following rearrangement: 1 2 4 3 6 8 5 10 12 7 14 16 … A rearrangement of the natural numbers that makes it look as though one-third of them are odd That makes it look as though the odd numbers are only half as common as even ones. Similarly, we could make it look as though the odd numbers were one in a million or any other proportion. So the intuitive notion of a proportion of the members of a set
================================================================================amusing stories – some fictional, some factual. They are not jokes, but some become memes: they are interesting enough for the listeners to retell them to other people, and some of those people retell them in turn. But they rarely recite them word for word; nor do they preserve every detail of the content. Hence an often- retold story will come to exist in different versions. Some of those versions will be retold more often than others – in some cases because people find them amusing. When that is the main reason for retelling them, successive versions that remain in circulation will tend to be ever more amusing. So the conditions are there for evolution: repeated cycles of imperfect copying of information, alternating with selection. Eventually the story becomes amusing enough to make people laugh, and a fully fledged joke has evolved. 372 The Evolution of Culture It is conceivable that a joke could evolve through variations that were not intended to improve upon the funniness. For example, people who hear a story can mishear or misunderstand aspects of it, or change it for pragmatic reasons, and in a small proportion of cases, by sheer luck, that will produce a funnier version of the story, which will then propagate better. If a joke has evolved in that way from a non-joke, it truly has no author. Another possibility is that most of the people who altered the amusing story on its way to becoming a joke designed their contributions, using creativity to make it funnier intentionally. In such cases, although the joke was indeed created by variation and selection, its funniness was the result of human creativity. In that case it would be misleading to say that ‘no one created it.’ It had many co-authors, each of whom contributed creative thought to the outcome. But it may still be that literally no one understands why the joke is as funny as it is, and hence that no one could create another joke of similar quality at will. Although we do not know exactly how creativity works, we do know that it is itself an evolutionary process within individual brains. For it depends on conjecture (which is variation) and criticism (for the purpose of selecting ideas). So, somewhere inside brains, blind vari - ations and selections are adding up to creative thought at a higher level of emergence. The idea of memes has come in for a great deal of radical, and in my view mistaken, criticism to the effect that it is vague and pointless, or else tendentious. For example, when the ancient Greek religion was suppressed, but the stories of its gods continued to be told, though now only as fiction, were those stories still the same memes despite now causing new behaviours? When Newton’s laws were translated into English from the original Latin, they caused different words to be spoken and written. Were they the same memes? But in fact such questions cast no doubt on the existence of memes, nor on the useful- ness of the concept. It is like the controversy about which objects in the solar system should be called ‘planets’. Is Pluto a ‘real’ planet even though it is smaller than some of the moons in our solar system? Is Jupiter really not a planet but an un-ignited star? It is not important. What is important is what is really there. And memes are really there, regardless of what we call them or how we classify them. Just as the 373 the beginning of infinity basic theory of genes was developed long before the discovery of DNA, so today, without knowing how ideas are stored in brains, we do know that some ideas can be passed from one person to another and affect people’s behaviour. Memes are those ideas. Another line of criticism is that memes, unlike genes, are not stored in identical physical forms in every holder. But, as I shall explain, that does not necessarily make it impossible for memes to be transmitted ‘faithfully’ in the sense that matters for evolution. It is indeed meaning- ful to think of memes as retaining their identity as they pass from one holder to the next. Just as genes often work together in groups to achieve what we might think of as a single adaptation, so there are memeplexes consisting of several ideas which can, alternatively, be thought of as a single more complex idea, such as quantum theory or neo-Darwinism. So it does not matter if we refer to a memeplex as a meme, just as it does not matter if we refer to quantum theory as a single theory or a group of theories. However, ideas, including memes, cannot be indefinitely analysed into sub-memes, because there comes a point where replacing a meme by part of itself would result in its not being copied. So, for instance, ‘2 + 3 = 5’ is not a meme, because it does not have what it takes to cause itself reliably to be copied, except under circumstances which would also copy some theory of arithmetic with universal reach, which itself could not be transmitted without also transmitting the knowledge that 2 + 3 = 5. Laughing at a joke and retelling it are both behaviours caused by the joke, but we often do not know why we are enacting them. That reason is objectively there in the meme, but we do not know it. We may try to guess, but our guess will not necessarily be true. For instance, we may guess that the humour in a particular joke lay in the un - expectedness of its punchline. But further experience with the same joke may reveal that it remains funny when we hear it again. In such a case, we are in the counter-intuitive (but common) position of having been mistaken about the reason for our own behaviour. The same sort of thing happens with rules of grammar. We say, ‘I am learning to play
================================================================================need for writing in the first place. In cases where the rule could be applied instead, it was more efficient: any scribe could write ‘(cid:2)(cid:1)’ and be understood even by a reader who had never seen the word written before. However, the rule could not be applied in all cases: it could not 125 the beginning of infinity represent any new single-syllable words, nor many other words. It seems clumsy and inadequate compared to modern writing systems. Yet there was already something significant about it which no purely pictographic system could achieve: it brought words into the writing system that no one had explicitly added. That means that it had reach. And reach always has an explanation. Just as in science a simple formula may summarize a mass of facts, so a simple, easily remembered rule can bring many additional words into a writing system, but only if it reflects an underlying regularity. The regularity in this case is that all the words in any given language are built out of only a few dozen ‘elementary sounds’, with each language using a different set chosen from the enormous range of sounds that the human voice can produce. Why? I shall come to that below. As the rules of a writing system were improved, a significant threshold could be crossed: the system could become universal for that language – capable of representing every word in it. For example, consider the following variant of the rule that I have just described: instead of building words out of other words, build them out of the initial sounds of other words. So, if English were written in pictograms, the new rule would allow ‘treason’ to be spelled with the pictograms for ‘Tent’, ‘Rock’, ‘EAgle’, ‘Zebra’, ‘Nose’. That tiny change in the rules would make the system universal. It is thought that the earliest alphabets evolved from rules like that. Universality achieved through rules has a different character from that of a completed list (such as the hypothetical complete set of pictograms). One difference is that the rules can be much simpler than the list. The individual symbols can be simpler too, because there are fewer of them. But there is more to it than that. Since a rule works by exploiting regularities in the language, it implicitly encodes those regularities, and so contains more knowledge than the list. An alphabet, for instance, contains knowledge of what words sound like. That allows it to be used by a foreigner to learn to speak the language, while pictograms could at most be used to learn to write it. Rules can also accommodate inflections such as prefixes and suffixes without adding complexity to the writing system, thus allowing written texts to encode more of the grammar of sentences. Also, a writing system based on an alphabet can cover not only every word but every possible word in its language, so that words that 126 The Jump to Universality have yet to be coined already have a place in it. Then, instead of each new word temporarily breaking the system, the system can itself be used to coin new words, in an easy and decentralized way. Or, at least, it could have been. It would be nice to think that the unknown scribe who created the first alphabet knew that he was making one of the greatest discoveries of all time. But he may not have. If he did, he certainly failed to pass his enthusiasm on to many others. For, in the event, the power of universality that I have just described was rarely used in ancient times, even when it was available. Although pictographic writing systems were invented in many societies, and universal alphabets did sometimes evolve from them in the way I have just described, the ‘obvious’ next step – namely to use the alphabet universally and to drop the pictograms – was almost never taken. Alphabets were confined to special purposes such as writing rare words or transliterating foreign names. Some historians believe that the idea of an alphabet-based writing system was conceived only once in human history – by some unknown predecessors of the Phoenicians, who then spread it throughout the Mediterranean – so that every alphabet-based writing system that has ever existed is either descended from or inspired by that Phoenician one. But even the Phoenician system had no vowels, which diminished some of the advantages I have mentioned. The Greeks added vowels. It is sometimes suggested that scribes deliberately limited the use of alphabets for fear that their livelihoods would be threatened by a system that was too easy to learn. But perhaps that is forcing too modern an interpretation on them. I suspect that neither the opportunities nor the pitfalls of universality ever occurred to anyone until much later in history. Those ancient innovators only ever cared about the specific probl ems they were confronting – to write particular words – and, in order to do that, one of them invented a rule that happened to be universal. Such an attitude may seem implausibly parochial. But things were parochial in those days. And indeed it seems to be a recurring theme in the early history of many fields that universality, when it was achieved, was not the primary objective, if it was an objective at all. A small change in a system to meet a parochial purpose just happened to make the system universal as well. This is the jump to universality. 127 the beginning of infinity Just as writing dates back to the dawn of civilization, so do numerals. Mathematicians nowadays distinguish between numbers, which are abstract entities, and numerals, which are physical symbols that repre- sent numbers; but numerals were discovered first. They evolved from ‘tally marks’ (⎥,⎥⎥,⎥⎥⎥,⎥⎥⎥⎥, . . . ) or tokens such as stones, which had been used since prehistoric times to keep track of discrete entities such as animals or days. If one made a mark for each goat released from a pen, and
================================================================================139, 196 mathematics and 164, 166, 167–77, transmutation of 1, 61, 67 186 measuring instruments and 181 ideas physics and 164, 173, 175, 177–81, conjectural see conjecture 182–3, 193–4 replicating see memes potential 165 see also explanations principled rejections of 132–3, 165–7, ignorance, infinite 447 459 imagination 26, 264–5 and probability 176–7 see also fiction; science fiction religious objections to study of 166 imitation 402, 403–10, 417 uncountable 171–2, 177, 181, 182 aping 405 and universality 164–5 behaviour parsing 407–9 see also Zeno’s mistake parroting 405, 406–7 information flow 238, 263, 265, 266, immortality 63, 214, 455, 459 281, 282, 292 impartiality see fairness people as channels of 302 incredulity, argument from personal in quantum theory 282, 287, 295, 164 304 474 index see also histories (sequences of events Jefferson, Thomas 330 in a multiverse) Jews 219, 385 initial state 107, 118, 280 joke, hideous, played on humans 416 innovation 125, 127, 133, 147, 197, jokes see humour 202, 204, 205, 392, 394, 398–401, jump to universality see universality 402, 410, 413–14, 435 justificationism 9, 31, 120, 187, 189 and catastrophes 201 see also authority and knowledge and criticism 222 Florentine 218–19 Kant, Immanuel 183 rapid 397, 399, 457 Keats, John 355 suppression of 202, 204, 384, 416, Kennedy, John F. 215 423, 427 Kepler, Johannes 112 see also universality, the jump to Kepler’s laws 112, 113, 256, 446 insoluble problems 53, 193, 213 knowledge 78 see also problems are soluble; in adaptation 55, 56–65, 78–81, 88; undecidable questions and the problem of creationism inspiration 36, 37, 41, 42, 58, 158–60, 79–81 333, 341, 440 and authority see authority and inspiration/perspiration 36, 37, 41, 58, knowledge 76, 158–60, 341–2, 456 creation of see creation of knowledge see also automation cultural 50, 51, 55, 59, 422 instrumentalism 15–16, 26, 31, 110, and deduction 5 112, 210, 325, 356 certain see fallibilism and quantum theory 307–9 and ‘a dream of Socrates’ 226–43, see also behaviourism; finitism 245, 252–3 instruments, scientific see measuring effects on an environment 74–5; see instruments also under biosphere intelligence 2, 47, 60, 86 encoded/embodied in matter 50, 56, artificial see artificial intelligence (AI) 74–5, 266–7, 375–7 and explanations 30 and evolution 77, 78–105 extraterrestrial see extraterrestrials explanatory see explanations; scientific see also fine-tuning theories interference, quantum 282–8, 291, 293, genetic see DNA; genes; genomes 295–8, 301–2, 303 inexplicit see inexplicit knowledge see also Mach–Zehnder infinite ignorance as potential for 447 interferometers moral see moral knowledge interpretation 36, 45, 65, 115, 127, 144, as ‘nearly there’ 445–6 164, 178, 216, 219, 253, 255, 301, non-explanatory 29, 73, 78, 94; see 311, 318–19, 329n, 330, 337, 344, also inexplicit knowledge; rules of 423, 428–9, 436 thumb of experiences 7–10, 17, 18, 22, 30, objective vii, 15, 31, 122, 185, 193, 38, 151, 317, 359, 369, 370, 403, 203, 209, 221–2, 226, 236, 238, 404, 407, 410, 448 242, 253, 255, 308, 314, 345, 350, of quantum theory 263, 266, 306–10, 353–4, 358–68, 388, 394, 448 312, 322, 325, 460 Plato’s theory of 119, 252, 252–3 split from prediction in scientific as a replicator 95, 114, 266–7 theories 315–16, 323, 324–5, 449 significance of people and 70–75, introspection 154 76 ‘ironic science’ 448–9 and survival 202, 207 see also epistemology Jacquard, Joseph Marie 134 Kuhn, Thomas 313 Jacquard loom 134–5 Kurrild-Klitgaard, Peter 339 475 index Lagrange, Joseph-Louis 198–9, 206, wizards 260 445, 446 see also conjuring tricks Lamarck, Jean-Baptiste 87–8, 89 Malthus, Thomas 201, 205–7, 421, 435, Lamarckism 87–9, 96, 103, 105, 106, 436 158, 210, 376, 411, 446 Malthusian prophetic fallacy 206, language 93, 94, 125–6, 142, 154, 268, 214, 432 280, 309, 311, 315, 323, 363, 365, Marx, Karl 371, 426, 428, 430, 442 366, 369–70, 405, 407, 409, 413, mathematical proof see proof 414, 428 mathematical truth see truth other than natural language 144, 154, mating 90, 91, 144, 359, 360, 362, 400, 159–62, 199, 292, 361, 365, 366, 401, 402, 413, 415 399 matter 14, 16, 40, 45–6, 61–2, 66, 68–9, see also universality: the jump to; 74, 75, 85, 97, 134, 203, 290–91, writing systems 305 Laplace, Pierre Simon 133 dark 36, 46, 67 lasers 73, 266, 267, 273–4, 294, 393, ordinary 45–6 446 prominent 73 see also atomic lasers Maxwell, James Clerk 255 laws of nature see nature, laws of measure theory for infinite sets 102, laws of physics see physics, laws of 178–83, 277–8, 281, 283, 287, 303, Leibniz, Gottfried Wilhelm 137, 164, 453, 458 181, 199–200, 265–6, 268, 269 for histories 301, 303, 307, 454, 455 Leonardo da Vinci 219 measurement 11, 35, 62, 68, 72, 99, liberty see freedom 108, 158, 183, 274, 299, 309, 316, life-support system 44–51, 45, 64, 338, 340, 357, 443 71 see also Spaceship Earth; errors 140–42, 298, 321–3; see also sustainability fallibility; fooling ourselves light 2, 3, 8, 11, 16, 38, 46, 47, 54, 61, see also proxies 68, 80, 85, 208, 228, 240n, 261, measuring instruments 18, 34–41, 179, 273, 305, 314, 357, 413, 433, 452 192, 269, 294–5, 308, 446 faster-than-light communication 55– human sensory systems as 40 6, 275–6, 283, 434 SETI 72–3 speed of 192, 199, 262, 263, 273, see also microscopes; telescopes 291, 293, 294, 451 Medawar, Peter 193 sunlight 8, 47, 57, 441 Medici, Lorenzo de’ 218, 429 see also photons Medici family 218–20 Littlefield, John E. 333 Mediocrity, Principle of 43–4, 45, 51–4, llamas 426–7, 429 64, 76, 101, 110, 166, 434 Locke, John 4, 134 memes 93, 94–5, 105, 369–72 Loebner, Hugh (Prize) 150–51 in animals see aping; parroting logical positivism 313, 314, 325 anti-rational 81, 381, 385, 388–90, Lovelace, Ada, Countess of 136, 137, 148 391–3, 394–396, 397, 413, 428, ‘Lady Lovelace’s objection’ 138 457 low-level phenomena 109–10, 111, 138 compared with viruses 384 creativity and in meme replication Mach, Ernst 312, 324 402–15, 416 Mach, Ludwig 312 evolution of 372–8, 383, 390, 393, Mach–Zehnder interferometers 286–7, 400, 412–13 296–7, 305, 309, 312 faithful replication of 257, 370, 374, Machiavelli, Niccolò 219 377, 378–80, 382–4, 390, 405,
================================================================================genes, but on whether we could discover how to build robots, or gloves, with two thumbs per hand, or alter ourselves to have a second thumb. If it depends on having more memory capacity, or speed, than a human brain, then the outcome would depend on whether we could build computers to do the job. Again, such things are already commonplace in technology. The astrophysicist Martin Rees has speculated that somewhere in the universe ‘there could be life and intelligence out there in forms we can’t conceive. Just as a chimpanzee can’t understand quantum theory, it could be there are aspects of reality that are beyond the capacity of our brains.’ But that cannot be so. For if the ‘capacity’ in question is mere computational speed and amount of memory, then we can understand the aspects in question with the help of computers – just as we have understood the world for centuries with the help of pencil and paper. As Einstein remarked, ‘My pencil and I are more clever than I.’ In terms of computational repertoire, our computers – and brains – are already universal (see Chapter 6). But if the claim is that we may be qualitatively unable to understand what some other forms of intelligence can – if our disability cannot be remedied by mere auto- mation – then this is just another claim that the world is not explicable. Indeed, it is tantamount to an appeal to the supernatural, with all the arbitrariness that is inherent in such appeals, for if we wanted to incorporate into our world view an imaginary realm explicable only to superhumans, we need never have bothered to abandon the myths of Persephone and her fellow deities. So human reach is essentially the same as the reach of explanatory knowledge itself. An environment is within human reach if it is possible to create an open-ended stream of explanatory knowledge there. That means that if knowledge of a suitable kind were instantiated in such 60 The Spark an environment in suitable physical objects, it would cause itself to survive and would then continue to increase indefinitely. Can there really be such an environment? This is essentially the question that I asked at the end of the last chapter – can this creativity continue indefinitely? – and it is the question to which the Spaceship Earth metaphor assumes a negative answer. The issue comes down to this: if such an environment can exist, what are the minimal physical features that it must have? Access to matter is one. For example, the trick of extracting oxygen from moon rocks depends on having compounds of oxygen available. With more advanced technology, one could manufacture oxygen by transmutation; but, no matter how advanced one’s technology is, one still needs raw materials of some sort. And, although mass can be recycled, creating an open-ended stream of knowledge depends on having an ongoing supply of it, both to make up for inevitable inefficiencies and to make the additional memory capacity to store new knowledge as it is created. Also, many of the necessary transformations require energy: some- thing must power conjectures and scientific experiments and all those manufacturing processes; and, again, the laws of physics forbid the creation of energy from nothing. So access to an energy supply is also a necessity. To some extent, energy and mass can be transformed into each other. For instance, transmuting hydrogen into any other element releases energy through nuclear fusion. Energy can also be converted into mass by various subatomic processes (but I cannot imagine naturally occurring circumstances in which those would be the best way of obtaining matter). In addition to matter and energy, there is one other essential require- ment, namely evidence: the information needed to test scientific theories. The Earth’s surface is rich in evidence. We happened to get round to testing Newton’s laws in the seventeenth century, and Einstein’s in the twentieth, but the evidence with which we did that – light from the sky – had been deluging the surface of the Earth for billions of years before that, and will continue to do so for billions more. Even today we have barely begun to examine that evidence: on any clear night, the chances are that your roof will be struck by evidence falling from the sky which, if you only knew what to look for and how, would win you a Nobel prize. In chemistry, every stable element that exists 61 the beginning of infinity anywhere is also present on or just below the Earth’s surface. In biology, copious evidence of the nature of life is ubiquitous in the biosphere – and within arm’s reach, in our own DNA. As far as we know, all the fundamental constants of nature can be measured here, and every fundamental law can be tested here. Everything needed for the open-ended creation of knowledge is here in abundance, in the Earth’s biosphere. And the same is true of the moon. It has essentially the same resources of mass, energy and evidence as the Earth has. Parochial details differ, but the fact that humans living on the moon will have to make their own air is no more significant than the fact that laboratories on Earth have to make their own vacuum. Both tasks can be automated so as to require arbitrarily little human effort or attention. Likewise, because humans are universal constructors, every problem of finding or trans- form i ng resources can be no more than a transient factor limiting the creation of knowledge in a given environment. And therefore matter, energy and evidence are the only requirements that an environment needs to have in order to be a venue for open-ended knowledge creation. Though any particular problem is a transient factor, the condition of having to solve problems in order to survive and continue to create knowledge is permanent. I have mentioned that there has never been an unproblematic time for humans; that applies as much to the
================================================================================– had already been discovered during the twentieth century. 447 the beginning of infinity Horgan wrote that he had originally believed science to be ‘open- ended, even infinite’. But he became convinced of the contrary by (what I would call) a series of misconceptions and bad arguments. His basic misconception was empiricism. He believed that what distinguishes science from unscientific fields such as literary criticism, philosophy or art is that science has the ability to ‘resolve questions’ objectively (by comparing theories with reality), while other fields can produce only multiple, mutually incompatible interpretations of any issue. He was mistaken in both respects. As I have explained throughout this book, there is objective truth to be found in all those fields, while finality or infallibility cannot be found anywhere. Horgan accepts from the bad philosophy of ‘postmodern’ literary criticism its wilful confusion between two kinds of ‘ambiguity’ that can exist in philosophy and art. The first is the ‘ambiguity’ of multiple true meanings, either intended by the author or existing because of the reach of the ideas. The second is the ambiguity of deliberate vagueness, confusion, equivocation or self-contradiction. The first is an attribute of deep ideas, the second an attribute of deep silliness. By confusing them, one ascribes to the best art and philosophy the qualities of the worst. Since, in that view, readers, viewers and critics can attribute any meaning they choose to the second kind of ambiguity, bad philosophy declares the same to be true of all knowledge: all meanings are equal, and none of them is objectively true. One then has a choice between complete nihilism or regarding all ‘ambiguity’ as a good thing in those fields. Horgan chooses the latter option: he classifies art and philosophy as ‘ironic’ fields, irony being the presence of multiple conflicting mean- ings in a statement. However, unlike the postmodernists, Horgan thinks that science and mathematics are the shining exceptions to all that. They alone are capable of non-ironic knowledge. But there is also, he concludes, such a thing as ironic science – the kind of science that cannot ‘resolve questions’ because, essentially, it is just philosophy or art. Ironic science can continue indefinitely, but that is precisely because it never resolves anything; it never discovers objective truth. Its only value is in the eye of the beholder. So the future, according to Horgan, belongs to ironic knowledge. Objective knowledge has already reached its ultimate bounds. 448 The Beginning Horgan surveys some of the open questions of fundamental science, and judges them all either ‘ironic’ or non-fundamental, in support of his thesis. But that conclusion was made inevitable by his premises alone. For consider the prospect of any future discovery that would constitute fundamental progress. We cannot know what it is, but bad philosophy can already split it, on principle, into a new rule of thumb and a new ‘interpretation’ (or explanation). The new rule of thumb cannot possibly be fundamental: it will just be another equation. Only a trained expert could tell the difference between it and the old equation. The new ‘interpretation’ will by definition be pure philosophy, and hence must be ‘ironic’. By this method, any potential progress can be pre-emptively reinterpreted as non-progress. Horgan rightly points out that his prophecy cannot be proved false by placing it in the context of previous failed prophecies. The fact that Michelson was wrong about the achievements of the nineteenth century, and Lagrange about those of the seventeenth, does not imply that Horgan was wrong about those of the twentieth. However, it so happens that our current scientific knowledge includes a historically unusual number of deep, fundamental problems. Never before in the history of human thought has it been so obvious that our knowledge is tiny and our ignorance vast. And so, unusually, Horgan’s pessimism contradicts existing knowledge as well as being a prophetic fallacy. For example, the problem-situation of fundamental physics today has a radically different structure from that of 1894. Although physicists then were aware of some phenomena and theoretical issues which we now recognize as harbingers of the revolutionary explanations to come, their importance was unclear at the time. It was hard to distinguish those harbingers from anomalies that would eventually be cleared up with existing explanations plus the tweaking of the ‘sixth place of decimals’ or minor terms in a formula. But today there is no such excuse for denying that some of our problems are fundamental. Our best theories are telling us of profound mismatches between themselves and the reality that they are supposed to explain. One of the most blatant examples of that is that physics currently has two fundamental ‘systems of the world’ – quantum theory and the general theory of relativity – and they are radically inconsistent. There are many ways of characterizing this inconsistency – known as the 449 the beginning of infinity problem of quantum gravity – corresponding to the many proposals for solving it that have been tried without success. One aspect is the ancient tension between the discrete and the continuous. The resolution that I described in Chapter 11, in terms of continuous clouds of fungible instances of a particle with diverse discrete attributes, works only if the spacetime in which this happens is itself continuous. But if spacetime is affected by the gravitation of the cloud, then it would acquire discrete attributes. In cosmology, there has been revolutionary progress even in the few years since The End of Science was written – and also since I wrote The Fabric of Reality soon afterwards. At the time, all viable cosmo- logical theories had the expansion of the universe gradually slowing down, due to gravity, ever since the initial explosion at the Big Bang and for ever in the future. Cosmologists were trying to determine whether, despite slowing down, its expansion rate was sufficient to make the universe expand for ever (like a projectile that has exceeded escape velocity) or whether it would eventually recollapse in a ‘Big Crunch’. Those
================================================================================The planet as a whole was overpopulated by a factor of seven, he said. Even Australia was nearing its maximum sustainable population. And so on. We had little basis for doubting what the professor was telling us about the field he was studying. Yet for some reason our con versation afterwards was not that of a group of students who had just had their futures stolen. I do not know about the others, but I can remember when I stopped worrying. At the end of the lecture a girl asked Ehrlich a question. I have forgotten the details, but it had the form ‘What if we solve [one of the problems that Ehrlich had described] within the next few years? Wouldn’t that affect your conclusion?’ Ehrlich’s reply was brisk. How could we possibly solve it? (She did not know.) And, even if we did, how could that do more than briefly delay the catastrophe? And what would we do then? What a relief! Once I realized that Ehrlich’s prophesies amounted to saying, ‘If we stop solving problems, we are doomed,’ I no longer found them shocking, for how could it be otherwise? Quite possibly that girl went on to solve the very problem she asked about, and the one after it. At any rate, someone must have, because the catastrophe scheduled for 1991 has still not materialized. Nor have any of the others that Ehrlich foretold. Ehrlich thought that he was investigating a planet’s physical resources and predicting their rate of decline. In fact he was prophesying the content of future knowledge. And, by envisaging a future in which only the best knowledge of 1971 was deployed, he was implicitly assuming that only a small and rapidly dwindling set of problems would ever be solved again. Furthermore, by casting problems in terms of ‘resource depletion’, and ignoring the human level of explanation, he missed all the important determinants of what he was trying to predict, namely: did the relevant people and institutions have what it takes to solve problems? And, more broadly, what does it take to solve problems? A few years later, a graduate student in the then new subject of environmental science explained to me that colour television was a sign of the imminent collapse of our ‘consumer society’. Why? Because, first of all, he said, it served no useful purpose. All the useful functions of television could be performed just as well in monochrome. Adding 432 Unsustainable colour, at several times the cost, was merely ‘conspicuous consumption’. That term had been coined by the economist Thorstein Veblen in 1902, a couple of decades before even monochrome television was invented; it meant wanting new possessions in order to show off to the neigh- bours. That we had now reached the physical limit of conspicuous consumption could be proved, said my colleague, by analysing the resource constraints scientifically. The cathode-ray tubes in colour televisions depended on the element europium to make the red phosphors on the screen. Europium is one of the rarest elements on Earth. The planet’s total known reserves were only enough to build a few hundred million more colour televisions. After that, it would be back to mono- chrome. But worse – think what this would mean. From then on there would be two kinds of people: those with colour televisions and those without. And the same would be true of everything else that was being consumed. It would be a world with permanent class distinction, in which the elites would hoard the last of the resources and live lives of gaudy display, while, to sustain that illusory state through its final years, everyone else would be labouring on in drab resentment. And so it went on, nightmare built upon nightmare. I asked him how he knew that no new source of europium would be discovered. He asked how I knew that it would. And, even if it were, what would we do then? I asked how he knew that colour cathode-ray tubes could not be built without europium. He assured me that they could not: it was a miracle that there existed even one element with the necessary properties. After all, why should nature supply elements with properties to suit our convenience? I had to concede the point. There aren’t that many elements, and each of them has only a few energy levels that could be used to emit light. No doubt they had all been assessed by physicists. If the bottom line was that there was no alternative to europium for making colour televisions, then there was no alternative. Yet something deeply puzzled me about that ‘miracle’ of the red phosphor. If nature provides only one pair of suitable energy levels, why does it provide even one? I had not yet heard of the fine-tuning problem (it was new at the time), but this was puzzling for a similar reason. Transmitting accurate images in real time is a natural thing for people to want to do, like travelling fast. It would not have been 433 the beginning of infinity puzzling if the laws of physics forbade it, just as they do forbid faster- than-light travel. For them to allow it but only if one knew how would be normal too. But for them only just to allow it would be a fine-tuning coincidence. Why would the laws of physics draw the line so close to a point that happened to have significance for human technology? It would be as if the centre of the Earth had turned out to be within a few kilometres of the centre of the universe. It seemed to violate the Principle of Mediocrity. What made this even more puzzling was that, as with the real fine- tuning problem, my colleague was claiming that there were many such coincidences. His whole point was that the colour-television problem was just one representative instance of a phenomenon that was happen- ing simultaneously in many areas of technology: the ultimate limits were being
================================================================================no one-to- one correspondence between the natural numbers and the points in a line: that set of points has a higher order of infinity than the set of natural numbers. Here is a version of his proof – known as the diagonal argument. Imagine a one-centimetre-thick pack of cards, each one so thin that there is one of them for every ‘real number’ of centimetres between 0 and 1. Real numbers can be defined as the decimal numbers between those limits, such as 0.7071. . ., where the ellipsis again denotes a continuation that may be infinitely long. It is impossible to deal out *First, they announce to the existing guests, ‘For each natural number N, will the guest in room number N please move immediately to room number N(N + 1)/2.’ Then they announce, ‘For all natural numbers N and M, will the Nth passenger from the Mth train please go to room number [(N + M)2 + N – M]/2.’ 170 A Window on Infinity one of these cards to each room of Infinity Hotel. For suppose that the cards were so distributed. We can prove that this entails a contradiction. It would mean that cards had been assigned to rooms in something like the manner of the table below. (The particular numbers illustrated are not significant: we are going to prove that real numbers cannot be assigned in any order.) Which room Which card 1 0.677976… 2 0.694698… 3 0.399221… 4 0.236646… Cantor’s diagonal argument Look at the infinite sequence of digits highlighted in bold – namely ‘(cid:1)(cid:2)(cid:2)(cid:1). . .’. Then consider a decimal number constructed as follows: it starts with zero followed by a decimal point, and continues arbitrarily, except that each of its digits must differ from the corresponding digit in the infinite sequence ‘(cid:1)(cid:2)(cid:2)(cid:1). . .’. For instance, we could choose a number such as ‘0.5885. . .’. The card with the number thus constructed cannot have been assigned to any room. For it differs in its first digit from that of the card assigned to room 1, and in its second digit from that of the card assigned to room 2, and so on. Thus it differs from all the cards that have been assigned to rooms, and so the original assump- tion that all the cards had been so assigned has led to a contradiction. An infinity that is small enough to be placed in one-to-one cor - respondence with the natural numbers is called a ‘countable infinity’ – rather an unfortunate term, because no one can count up to infinity. But it has the connotation that every element of a countably infinite set could in principle be reached by counting those elements in some suitable order. Larger infinities are called uncountable. So, there is an uncountable infinity of real numbers between any two distinct limits. 171 … … the beginning of infinity Furthermore, there are uncountably many orders of infinity, each too large to be put into one-to-one correspondence with the lower ones. Another important uncountable set is the set of all logically possible reassignments of guests to rooms in Infinity Hotel (or, as the mathem- aticians put it, all possible permutations of the natural numbers). You can easily prove that if you imagine any one reassignment specified in an infinitely long table, like this: Guest in room number 1 2 3 4 … Moves to 38 173 80 30 … Specifying one reassignment of guests Then imagine all possible reassignments listed one below the other, thus ‘counting’ them. The diagonal argument applied to this list will prove that the list is impossible, and hence that the set of all possible reassignments is uncountable. Since the management of Infinity Hotel have to specify a reassignment in the form of a public-address announcement, the specification must consist of a finite sequence of words – and hence a finite sequence of characters from some alphabet. The set of such sequences is countable and therefore infinitely smaller than the set of possible reassignments. That means that only an infinitesimal proportion of all logically possible reassignments can be specified. This is a remarkable limitation on the apparently limitless power of Infinity Hotel’s management to shuffle the guests around. Almost all ways in which the guests could, as a matter of logic, be distributed among the rooms are unattainable. Infinity Hotel has a unique, self-sufficient waste-disposal system. Every day, the management first rearrange the guests in a way that ensures that all rooms are occupied. Then they make the following announcement. ‘Within the next minute, will all guests please bag their trash and give it to the guest in the next higher-numbered room. Should you receive a bag during that minute, then pass it on within the 172 A Window on Infinity following half minute. Should you receive a bag during that half minute, pass it on within the following quarter minute, and so on.’ To comply, the guests have to work fast – but none of them has to work infinitely fast, or handle infinitely many bags. Each of them performs a finite number of actions, as per the hotel rules. After two minutes, all these trash-moving actions have ceased. So, two minutes after they begin, none of the guests has any trash left. Infinity Hotel’s waste-disposal system All the trash in the hotel has disappeared from the universe. It is nowhere. No one has put it ‘nowhere’: every guest has merely moved some of it into another room. The ‘nowhere’ where all that trash has gone is called, in physics, a singularity. Singularities may well happen in reality, inside black holes and elsewhere. But I digress: at the moment, we are still discussing mathematics, not physics. Of course, Infinity Hotel has infinitely many staff. Several of them are assigned to look after each guest. But the staff themselves are treated as guests in the hotel, staying in numbered rooms and receiving exactly the same benefits as every other guest: each of them has several
================================================================================to do with geography? They may simply have been too set in their ways. Perhaps innovative uses for animals were taboo. Perhaps such a trade was attempted, but failed every time because of sheer bad luck. But, whatever the reason was, it cannot have been that the hot region constituted a physical barrier, for it did not. Those are the parochial considerations. The bigger picture is that the spread of llamas can only have been prevented by people’s ideas and outlook. Had the Andeans had a Polynesian outlook instead, llamas might have spread all over the Americas. Had the ancient Polynesians not had that outlook, they might never have settled Polynesia in the first place, and biogeographical explanations would now be referring to the great ocean barrier as the ‘ultimate explanation’ for that. If the Polynesians had been even better at long-range trading, they might have managed to transport horses from Asia to their islands and thence to South America – a feat perhaps no more impressive than Hannibal’s transporting elephants across the Alps. If the ancient Greek enlighten- ment had continued, Athenians might have been the first to settle the Pacific islands and they would now be the ‘Polynesians’. Or, if the early Andeans had worked out how to breed giant war llamas and had ridden out to explore and conquer before anyone else had even thought of domesticating the horse, South American biogeographers might now be explaining that their ancestors colonized the world because no other continent had llamas. Moreover, the Americas had not always lacked large quadrupeds. When the first humans arrived there, many species of ‘mega-fauna’ were common, including wild horses, mammoths, mastodons and other members of the elephant family. According to some theories, the humans hunted them to extinction. What would have happened if one 427 the beginning of infinity of those hunters had had a different idea: to ride the beast before killing it? Generations later, the knock-on effects of that bold conjecture might have been tribes of warriors on horses and mammoths pouring back through Alaska and re-conquering the Old World. Their descendants would now be attributing this to the geographical distribution of mega- fauna. But the real cause would have been that one idea in the mind of that one hunter. In early prehistory, populations were tiny, knowledge was parochial, and history-making ideas were millennia apart. In those days, a meme spread only when one person observed another enacting it nearby, and (because of the staticity of cultures) rarely even then. So at that time human behaviour resembled that of other animals, and much of what happened was indeed explained by biogeography. But developments such as abstract language, explanation, wealth above the level of subsist- ence, and long-range trade all had the potential to erode parochialism and hence to give causal power to ideas. By the time history began to be recorded, it had long since become the history of ideas far more than anything else – though unfortunately the ideas were still mainly of the self-disabling, anti-rational variety. As for subsequent history, it would take considerable dedication to insist that biogeographical explanations account for the broad sweep of events. Why, for instance, did the societies in North America and Western Europe, rather than Asia and Eastern Europe, win the Cold War? Analysing climate, minerals, flora, fauna and diseases can teach us nothing about that. The explanation is that the Soviet system lost because its ideology wasn’t true, and all the biogeography in the world cannot explain what was false about it. Coincidentally, one of the things that was most false about the Soviet ideology was the very idea that there is an ultimate explanation of history in mechanical, non-human terms, as proposed by Marx, Engels and Diamond. Quite generally, mechanical reinterpretations of human affairs not only lack explanatory power, they are morally wrong as well, for in effect they deny the humanity of the participants, casting them and their ideas merely as side effects of the landscape. Diamond says that his main reason for writing Guns, Germs and Steel was that, unless people are convinced that the relative success of Europeans was caused by biogeography, they will for ever be tempted by racist explanations. Well, not readers of this book, I trust! Presumably 428 Unsustainable Diamond can look at ancient Athens, the Renaissance, the Enlighten- ment – all of them the quintessence of causation through the power of abstract ideas – and see no way of attributing those events to ideas and to people; he just takes it for granted that the only alternative to one reductionist, dehumanizing reinterpretation of events is another. In reality, the difference between Sparta and Athens, or between Savonarola and Lorenzo de’ Medici, had nothing to do with their genes; nor did the difference between the Easter Islanders and the imperial British. They were all people – universal explainers and constructors. But their ideas were different. Nor did landscape cause the Enlightenment. It would be much truer to say that the landscape we live in is the product of ideas. The primeval landscape, though packed with evidence and therefore opportunity, contained not a single idea. It is knowledge alone that converts landscapes into resources, and humans alone who are the authors of explanatory knowledge and hence of the uniquely human behaviour called ‘history’. Physical resources such as plants, animals and minerals afford opportunities, which may inspire new ideas, but they can neither create ideas nor cause people to have particular ideas. They also cause problems, but they do not prevent people from finding ways to solve those problems. Some overwhelming natural event like a volcanic eruption might have wiped out an ancient civilization regardless of what the victims were thinking, but that sort of thing is exceptional. Usually, if there are human beings left alive to think, there are ways of thinking that can improve their situation, and then improve it further. Unfortunately, as I have explained, there are also ways of thinking that can prevent
================================================================================objective as the laws of physics. Creating either kind of beauty requires knowledge; but the second kind requires knowledge with universal reach. It reaches all the way from the flower genome, with its problem of competitive pollination, to human minds which appreciate the resulting flowers as art. Not great art – human artists are far better, as is to be expected. But with the hard-to-fake appearance of design for beauty. Now, why do humans appreciate objective beauty, if there has been no equivalent of that co-evolution in our past? At one level the answer is simply that we are universal explainers and can create knowledge about anything. But still, why did we want to create aesthetic know- ledge in particular? It is because we did face the same problem as the flowers and the insects. Signalling across the gap between two humans is analogous to signalling across the gap between two entire species. A human being, in terms of knowledge content and creative individu- ality, is like a species. All the individuals of any other species have virtually the same programming in their genes and use virtually the same criteria for acting and being attracted. Humans are quite unlike that: the amount of information in a human mind is more than that in the genome of any species, and overwhelmingly more than the genetic information unique to one person. So human artists are trying to signal across the same scale of gap between humans as the flowers and insects are between species. They can use some species-specific criteria; but they can also reach towards objective beauty. Exactly the same is true of all our other knowledge: we can communicate with other people by sending predetermined messages determined by our genes or culture, or we can invent something new. But in the latter case, to have any chance of communicating, we had better strive to rise above parochial- ism and seek universal truths. This may be the proximate reason that humans ever began to do so. 364 Why are Flowers Beautiful? One amusing corollary of this theory is, I think, that it is quite possible that human appearance, as influenced by human sexual selection, satisfies standards of objective beauty as well as species- specific ones. We may not be very far along that path yet, because we diverged from apes only a few hundred thousand years ago, so our appearance isn’t yet all that different from that of apes. But I guess that when beauty is better understood it will turn out that most of the differences have been in the direction of making humans objectively more beautiful than apes. The two types of beauty are usually created to solve two types of problem – which could be called pure and applied. The applied kind is that of signalling information, and is usually solved by creating the parochial type of beauty. Humans have problems of that type too: the beauty of, say, the graphical user interface of a computer is created primarily to promote comfort and efficiency in the machine’s use. Sometimes a poem or song may be written for a similar practical purpose: to give more cohesiveness to a culture, or to advance a political agenda, or even to advertise beverages. Again, sometimes these purposes can also be met by creating objective beauty, but usually the parochial kind is used because it is easier to create. The other kind of problem, the pure kind, which has no analogue in biology, is that of creating beauty for its own sake – which includes creating improved criteria for beauty: new artistic standards or styles. This is the analogue of pure scientific research. The states of mind involved in that sort of science and that sort of art are fundamentally the same. Both are seeking universal, objective truth. And both, I believe, are seeking it through good explanations. This is most straightforwardly so in the case of art forms that involve stories – fiction. There, as I mentioned in Chapter 11, a good story has a good explanation of the fictional events that it portrays. But the same is true in all art forms. In some, it is especially hard to express in words the explanation of the beauty of a particular work of art, even if one knows it, because the relevant knowledge is itself not expressed in words – it is inexplicit. No one yet knows how to translate musical explanations into natural language. Yet when a piece of music has the attribute ‘displace one note and there would be diminishment’ there is an explanation: it was known to the composer, and it is known to the 365 the beginning of infinity listeners who appreciate it. One day it will be expressible in words. This, too, is not as different from science and mathematics as it looks: poetry and mathematics or physics share the property that they develop a language different from ordinary language in order to state things efficiently that it would be very inefficient to state in ordinary language. And both do this by constructing variants of ordinary language: one has to understand the latter first in order to understand explanations of, and in, the former. Applied art and pure art ‘feel’ the same. And, just as we need sophisticated knowledge to tell the difference between the motion of a bird across the sky, which is happening objectively, and the motion of the sun across the sky, which is just a subjective illusion caused by our own motion, and the motion of the moon, which is a bit of each, so pure and applied art, universal and parochial beauty, are mixed together in our subjective appreciation of things. It will be important to discover which is which. For it is only in the objective direction that we can expect to make unlimited progress. The other directions are inherently finite. They are circumscribed by the finite knowledge inherent in our genes and our existing traditions. That has a bearing on
================================================================================requirements for 61 130, 134–9, 159, 241–2, 384, 391– spark for 75 2, 415, 459 spontaneous generation and 81–3 convergence creationism 79–81, 86, 104, 193 between Spaceship Earth and the fine-tuning as supposed evidence for 97 Principle of Mediocrity 45, 53 and spontaneous generation 82 convergent evolution 95 see also Paley, William and error correction 350 creativity 30 upon the truth 231, 257, 350, 368 artificial 148–63; see also artificial Conway, John 166 intelligence (AI) Copenhagen interpretation of quantum artistic 355–7; see also aesthetics theory 308–10, 312, 315, 322, 324, creative conjecture 412; see also 325 conjecture copying creatively changing the options 351 memes not replicated by imitation in discovering new explanations 7–8 402–10 as an evolutionary process in the replicators see memes; replicators brain 373; evolution of 398–400, cork 72–4 402–15, 416 correspondence 39, 241 future of 415–16 of theories with objective truth 353 mutual enhancement of meme one-to-one 167, 170, 171–2, 181, transmission and 400 193; tallying 128, 129, 130–31, needed to improve explanations 342 134, 140–41, 193, 356 puzzle of what use it was in non- cosmic rays 68, 293–4 innovating cultures 398–402, cosmic significance see significance 410–15 cosmology 68, 81, 113, 445, 450–53 and scientific toil 41, 355–6 evolutionary cosmologies 178–9 as a hideous joke played on humans see also astrophysics 416 cow, size of 35 criterion of demarcation (Popper) 14 see creation of knowledge 78–105 also testability and the argument from design 83–7 criticism 114, 119, 233 impeded by bad philosophy 305–25, conjecture and 58, 192, 203, 239–40, 448 352, 412 467 index criticism (cont.) decision-making 335 immunity from 230–3, 310, 316, 324, conventional model of 341 325, 346, 347 democratic 344–5; see also voting suppressed by anti-rational memes and Popper’s criterion of ridding 391, 393 ourselves of bad governments by testing see experimental testing without violence 344–51, 352 tradition of 13, 23, 31–3, 209, 216, and problem solving 341–2 220, 231, 308, 390, 431 social-choice theory and 335, 337–8, as variation of information 78 342–3, 345 crystals 83 society-wide planning and 335–51 liquid 434 by weighing 340–42 cubes, notional, in space 47, 66–8, 74–5 decoherence 285, 303 cultural evolution 369–97 deconstructionism 314 and the biosphere–culture analogy deduction 5 371–2 deep space 47–8, 66–9, 71–2, 293 and dynamic societies 387–8, 424 deforestation 418, 420–21, 422 the Enlightenment 390–93 Demeter 19–21, 24, 26 ideas that survive 369–72 democracy 217, 250, 333, 335 living with memes 394–6 democratic decision-making in meme evolution 372–8, 400, 413 elections 344–5 rational and anti-rational memes see also voting; plurality voting 388–90 346–50 the selfish meme 378–9, 387 Dennett, Daniel 117, 154 and static societies 380, 383–6, 414 design 44, 125, 131, 139, 144, 155, subcultures 393 159–162, 201, 357, 367 cultural relativism 314, 356 appearance of 44, 50, 84–6, 87, culture 397 see also cultural evolution 97, 98, 106, 357, 363–4; Paley’s cures 11, 153, 213, 272, 422, 437, 455 criterion for 85–7 curvature of spacetime 107, 112, 183–4, argument from 83–7 312, 450 creationism and designers 43, 49, 51, 73, 79–81, 97 dark energy 451 in the laws of physics 96–103 dark matter 36, 46, 67 determinism 277, 287, 371 Darwin, Charles 80, 82, 87, 91 deterministic laws 263, 265, 267, Darwin, Erasmus 87, 88 268, 270, 275, 276, 279, 305 Darwinian theory 80, 89 Deutsch, David, The Fabric of Reality Marx on 371 109–10, 450, 460 neo-Darwinism 89–96, 103, 104–5 diagonal argument 170–71, 172 refutation possibilities 95–6 Diamond, Jared 425–9, 430, 442 data 15, 18, 210, 315, 323 dictatorship see tyranny Dawkins, Juliet 353, 362 meaning of ‘dictator’ in Arrow’s Dawkins, Richard 52–3, 56–7, 92, 93, theorem 343 279 no-dictator axiom 336 argument from personal incredulity Difference Engine 135–6 164 Difference Engine, The (Gibson and Haldane–Dawkins ‘queerer-than-we- Sterling) 137 can-suppose’ argument 53, 56, differentiation 59, 81 calculus 164 death 48, 63, 69, 436, 453, 459 of histories in a multiverse 273–5, elimination of 63, 213, 455 276–9, 287–8; decoherence and evil of 213 285; interference and 283–7, 291, fear of 84 293; rate of growth of distinct 468 index histories 287; see also waves of 400, 409, 431, 435 differentiation academic knowledge 4, 255, 369, digital technology 139–42 393, 446 dinosaurs 162, 315 because I say so 311, 391–2, 395 disasters, natural 42, 49, 63, 200, 202, moral 230–31 206–7 university 34–6, 158, 255, 308, 309, discrete variables 128, 140, 142, 274, 403, 406, 409, 433, 446 305, 450 see also fun; Popper on instruction discrete/continuous dichotomy 140, Ehrlich, Paul 431–2, 440 142, 274, 298, 450 Einstein, Albert 60, 104, 113, 255, 256, disease 59, 63, 196, 200, 213, 294, 385, 307, 310, 312, 446–7, 451 437 curved space and time 183–4 Black Death 208, 385, 437 explanation of planetary motion 112, cholera 207 113 cures 11, 153, 213, 272, 422, 437, general theory of relativity 29, 61, 455 107, 312; and the problem of pandemics/epidemics 196, 208, 418, quantum gravity 449–50 436; see also Black Death above special theory of relativity 199 DNA 56–7, 62, 67, 78, 95, 162, 375, Elbot program 151, 156 376 electoral systems 338–40 computer 145 and democratic decision-making damage 294 344–5 and the genetic code’s jump to plurality voting system 346–50 universality 143–6, 162–3 see also proportional representation in pollen 360 electron(s) 70, 108, 289–91, 293, 294, dogmas/dogmatism 13, 23, 26, 66, 122, 298, 324, 454 445, 447 field 291 domino computer (Hofstadter) 115–17, microscope 39 118, 185, 358 elegance 3, 25, 32, 42, 94, 199, 355, doomsday argument 455–6 367, 387 doppelgangers 258, 263–4, 265, 270–72 elementary particles see particles, Doyle, Arthur Conan 10 elementary Dragon’s Egg (Forward) 97 elements dream ancient theory of 14 hallucination 301 formation of 1, 2, 40, 50, 61–2, 96 Popperian epistemology taught in a Eliza program 148–9, 161 ‘dream of Socrates’ 223–54 see also chatbots reality and experience as a waking emergence 104, 108–11, 118–19, 123, dream 241–2, 252–3 156, 292, 302–3, 305, 395 drugs 317–18 causation as emergent 118 Hofstadter’s ‘I’ and 115–18 Easter Island 418–24, 430–31 levels of emergence and of explanation economic forecasts
================================================================================on specific types of chemicals, such as proteins. Could it be a universal constructor? Perhaps. It does manage to build with inorganic materials sometimes, such as the calcium phosphate in bones, or the magnetite in the navigation system inside a pigeon’s brain. Biotechnologists are already using it to manufacture hydrogen and to extract uranium from seawater. It can also program organisms to perform constructions outside their bodies: birds build nests; beavers build dams. Perhaps it would it be possible to specify, in the genetic code, an organism whose life cycle includes building a nuclear-powered spaceship. Or perhaps not. I guess it has some lesser, and not yet understood, universality. In 1994 the computer scientist and molecular biologist Leonard Adleman designed and built a computer composed of DNA together with some simple enzymes, and demonstrated that it was capable of performing some sophisticated computations. At the time, Adleman’s DNA computer was arguably the fastest computer in the world. Further, it was clear that a universal classical computer could be made in a similar way. Hence we know that, whatever that other universality of the DNA system was, the universality of computation had also been 145 the beginning of infinity inherent in it for billions of years, without ever being used – until Adleman used it. The mysterious universality of DNA as a constructor may have been the first universality to exist. But, of all the different forms of univer- sality, the most significant physically is the characteristic universality of people, namely that they are universal explainers, which makes them universal constructors as well. The effects of that universality are, as I have explained, explicable only by means of the full gamut of fundamental explanations. It is also the only kind of universality capable of transcending its parochial origins: universal computers cannot really be universal unless there are people present to provide energy and maintenance – indefinitely. And the same is true of all those other technologies. Even life on Earth will eventually be extinguished, unless people decide otherwise. Only people can rely on themselves into the unbounded future. terminology The jump to universality The tendency of gradually improving systems to undergo a sudden large increase in functionality, becoming uni v ersal in some domain. meanings of ‘the beginning of infinity’ encountered in this chapter – The existence of universality in many fields. – The jump to universality. – Error-correction in computation. – The fact that people are universal explainers. – The origin of life. – The mysterious universality to which the genetic code jumped. summary All knowledge growth is by incremental improvement, but in many fields there comes a point when one of the incremental improvements in a system of knowledge or technology causes a sudden increase in 146 The Jump to Universality reach, making it a universal system in the relevant domain. In the past, innovators who brought about such a jump to universality had rarely been seeking it, but since the Enlightenment they have been, and universal explanations have been valued both for their own sake and for their usefulness. Because error-correction is essential in processes of potentially unlimited length, the jump to universality only ever happens in digital systems. 147 7 Artificial Creativity Alan Turing founded the theory of classical computation in 1936 and helped to construct one of the first universal classical computers during the Second World War. He is rightly known as the father of modern computing. Babbage deserves to be called its grandfather, but, unlike Babbage and Lovelace, Turing did understand that artificial intelligence (AI) must in principle be possible because a universal computer is a universal simulator. In 1950, in a paper entitled ‘Computing Machinery and Intelligence’, he famously addressed the question: can a machine think? Not only did he defend the proposition that it can, on the grounds of universality, he also proposed a test for whether a program had achieved it. Now known as the Turing test, it is simply that a suitable (human) judge be unable to tell whether the program is human or not. In that paper and subsequently, Turing sketched protocols for carrying out his test. For instance, he suggested that both the program and a genuine human should separately interact with the judge via some purely textual medium such as a teleprinter, so that only the thinking abilities of the candidates would be tested, not their appearance. Turing’s test, and his arguments, set many researchers thinking, not only about whether he was right, but also about how to pass the test. Programs began to be written with the intention of investigating what might be involved in passing it. In 1964 the computer scientist Joseph Weizenbaum wrote a program called Eliza, designed to imitate a psychotherapist. He deemed psycho- therapists to be an especially easy type of human to imitate because the program could then give opaque answers about itself, and only ask questions based on the user’s own questions and statements. It was a remarkably simple program. Nowadays such programs are popular 148 Artificial Creativity projects for students of programming, because they are fun and easy to write. A typical one has two basic strategies. First it scans the input for certain keywords and grammatical forms. If this is successful, it replies based on a template, filling in the blanks using words in the input. For instance, given the input I hate my job, the program might recognize the grammar of the sentence, involving a possessive pronoun ‘my’, and might also recognize ‘hate’ as a keyword from a built-in list such as ‘love/hate/like/dislike/want’, in which case it could choose a suitable template and reply: What do you hate most about your job? If it cannot parse the input to that extent, it asks a question of its own, choosing randomly from a stock pattern which may or may not depend on the input sentence. For instance, if asked How does a television work?, it might reply, What is so interesting about “How does a television work?”? Or it
================================================================================the apportionment problem, which had absorbed so much legislative time, effort and passion, was the tip of 335 the beginning of infinity an iceberg. The problem is much less parochial than it looks. For instance, rounding errors are proportionately smaller with a larger legislature. So why don’t they just make the legislature very big – say, ten thousand members – so that all the rounding errors would be trivial? One reason is that such a legislature would have to organize itself internally to make any decisions. The factions within the legisla- ture would themselves have to choose leaders, policies, strategies, and so on. Consequently, all the problems of social choice would arise within the little ‘society’ of a party’s contingent in the legislature. So it is not really about rounding errors. Also, it is not only about people’s top preferences: once we are considering the details of decision-making in large groups – how legislatures and parties and factions within parties organize themselves to contribute their wishes to ‘society’s wishes’ – we have to take into account their second and third choices, because people still have the right to contribute to decision-making if they cannot persuade a majority to agree to their first choice. Yet electoral systems designed to take such factors into account invariably introduce more paradoxes and no-go theorems. One of the first of the no-go theorems was proved in 1951 by the economist Kenneth Arrow, and it contributed to his winning the Nobel prize for economics in 1972. Arrow’s theorem appears to deny the very existence of social choice – and to strike at the principle of representative government, and apportionment, and democracy itself, and a lot more besides. This is what Arrow did. He first laid down five elementary axioms that any rule defining the ‘will of the people’ – the preferences of a group – should satisfy, and these axioms seem, at first sight, so reasonable as to be hardly worth stating. One of them is that the rule should define a group’s preferences only in terms of the preferences of that group’s members. Another is that the rule must not simply designate the views of one particular person to be ‘the preferences of the group’ regardless of what the others want. That is called the ‘no-dictator’ axiom. A third is that if the members of the group are unanimous about something – in the sense that they all have identical preferences about it – then the rule must deem the group to have those preferences too. Those three axioms are all expressions, in this situation, of the principle of representative government. 336 Choices Arrow’s fourth axiom is this. Suppose that, under a given definition of ‘the preferences of the group’, the rule deems the group to have a particular preference – say, for pizza over hamburger. Then it must still deem that to be the group’s preference if some members who previously disagreed with the group (i.e. they preferred hamburger) change their minds and now prefer pizza. This constraint is similar to ruling out a population paradox. A group would be irrational if it changed its ‘mind’ in the opposite direction to its members. The last axiom is that if the group has some preference, and then some members change their minds about something else, then the rule must continue to assign the group that original preference. For instance, if some members have changed their minds about the relative merits of strawberries and raspberries, but none of their preferences about the relative merits of pizza and hamburger have changed, then the group’s preference between pizza and hamburger must not be deemed to have changed either. This constraint can again be regarded as a matter of rationality: if no members of the group change any of their opinions about a particular comparison, nor can the group. Arrow proved that the axioms that I have just listed are, despite their reasonable appearance, logically inconsistent with each other. No way of conceiving of ‘the will of the people’ can satisfy all five of them. This strikes at the assumptions behind social-choice theory at an arguably even deeper level than the theorems of Balinski and Young. First, Arrow’s axioms are not about the apparently parochial issue of apportionment, but about any situation in which we want to conceive of a group having preferences. Second, all five of these axioms are intuitively not just desirable to make a system fair, but essential for it to be rational. Yet they are inconsistent. It seems to follow that a group of people jointly making decisions is necessarily irrational in one way or another. It may be a dictatorship, or under some sort of arbitrary rule; or, if it meets all three represen- tativeness conditions, then it must sometimes change its ‘mind’ in a direction opposite to that in which criticism and persuasion have been effective. So it will make perverse choices, no matter how wise and benevolent the people who interpret and enforce its preferences may be – unless, possibly, one of them is a dictator (see below). So there is no such thing as ‘the will of the people’. There is no way to regard 337 the beginning of infinity ‘society’ as a decision-maker with self-consistent preferences. This is hardly the conclusion that social-choice theory was supposed to report back to the world. As with the apportionment problem, there were attempts to fix the implications of Arrow’s theorem with ‘why don’t they just . . . ?’ ideas. For instance, why not take into account how intense people’s preferences are? For, if slightly over half the electorate barely prefers X to Y, but the rest consider it a matter of life and death that Y should be done, then most intuitive conceptions of representative government would designate Y as ‘the will of the people’. But intensities of preferences, and especially the differences in intensities among different people, or between the same person at different times, are notoriously difficult to define, let
================================================================================reached. Just as we were using up the last stocks of the rarest of rare-earth elements for the frivolous purpose of watching soap operas in colour, so everything that looked like progress was actually just an insane rush to exploit the last resources left on our planet. The 1970s were, he believed, a unique and terrible moment in history. He was right in one respect: no alternative red phosphor has been discovered to this day. Yet, as I write this chapter, I see before me a superbly coloured computer display that contains not one atom of europium. Its pixels are liquid crystals consisting entirely of common elements, and it does not require a cathode-ray tube. Nor would it matter if it did, for by now enough europium has been mined to supply every human being on earth with a dozen europium-type screens, and the known reserves of the element comprise several times that amount. Even while my pessimistic colleague was dismissing colour television technology as useless and doomed, optimistic people were discovering new ways of achieving it, and new uses for it – uses that he thought he had ruled out by considering for five minutes how well colour televisions could do the existing job of monochrome ones. But what stands out, for me, is not the failed prophecy and its underlying fallacy, nor relief that the nightmare never happened. It is the contrast between two different conceptions of what people are. In the pessimistic con - ception, they are wasters: they take precious resources and madly convert them into useless coloured pictures. This is true of static 434 Unsustainable societies: those statues really were what my colleague thought colour televisions are – which is why comparing our society with the ‘old culture’ of Easter Island is exactly wrong. In the optimistic conception – the one that was unforeseeably vindicated by events – people are problem-solvers: creators of the unsustainable solution and hence also of the next problem. In the pessimistic conception, that distinctive ability of people is a disease for which sustainability is the cure. In the optimistic one, sustainability is the disease and people are the cure. Since then, whole new industries have come into existence to harness great waves of innovation, and in many of those – from medical imaging to video games to desktop publishing to nature documentaries like Attenborough’s – colour television proved to be very useful after all. And, far from there being a permanent class distinction between monochrome- and colour-television users, the monochrome technology is now practically extinct, as are cathode-ray televisions. Colour dis - plays are now so cheap that they are being given away free with magazines as advertising gimmicks. And all those technologies, far from being divisive, are inherently egalitarian, sweeping away many formerly entrenched barriers to people’s access to information, opinion, art and education. Optimistic opponents of Malthusian arguments are often – rightly – keen to stress that all evils are due to lack of knowledge, and that problems are soluble. Prophecies of disaster such as the ones I have described do illustrate the fact that the prophetic mode of thinking, no matter how plausible it seems prospectively, is fallacious and in - herently biased. However, to expect that problems will always be solved in time to avert disasters would be the same fallacy. And, indeed, the deeper and more dangerous mistake made by Malthusians is that they claim to have a way of averting resource-allocation disasters (namely, sustainability). Thus they also deny that other great truth that I sug- gested we engrave in stone: problems are inevitable. A solution may be problem-free for a period, and in a parochial application, but there is no way of identifying in advance which problems will have such a solution. Hence there is no way, short of stasis, to avoid unforeseen problems arising from new solutions. But stasis is itself unsustainable, as witness every static society in history. 435 the beginning of infinity Malthus could not have known that the obscure element uranium, which had just been discovered, would eventually become relevant to the survival of civilization, just as my colleague could not have known that, within his lifetime, colour televisions would be saving lives every day. So there is no resource-management strategy that can prevent disasters, just as there is no political system that provides only good leaders and good policies, nor a scientific method that provides only true theories. But there are ideas that reliably cause disasters, and one of them is, notoriously, the idea that the future can be scientifically planned. The only rational policy, in all three cases, is to judge institutions, plans and ways of life according to how good they are at correcting mistakes: removing bad policies and leaders, superseding bad explanations, and recovering from disasters. For example, one of the triumphs of twentieth-century progress was the discovery of antibiotics, which ended many of the plagues and endemic illnesses that had caused suffering and death since time im - memorial. However, it has been pointed out almost from the outset by critics of ‘so-called progress’ that this triumph may only be temporary, because of the evolution of antibiotic-resistant pathogens. This is often held up as an indictment of – to give it its broad context – Enlighten- ment hubris. We need lose only one battle in this war of science against bacteria and their weapon, evolution (so the argument goes), to be doomed, because our other ‘so-called progress’ – such as cheap world- wide air travel, global trade, enormous cities – makes us more vulner- able than ever before to a global pandemic that could exceed the Black Death in destructiveness and even cause our extinction. But all triumphs are temporary. So to use this fact to reinterpret progress as ‘so-called progress’ is bad philosophy. The fact that reliance on specific antibiotics is unsustainable is only an indictment from the point of view of someone who expects a sustainable lifestyle. But in reality there is no
================================================================================participating in the decision-making process, where the person as a whole would be the ‘group’. Now, the process that adjudicates between the different explanations would have to satisfy certain constraints if it were to be rational. For 340 Choices instance, if, having decided that one option was the best, the person received further evidence that gave additional weight to that option, then the person’s overall preference would still have to be for that option – and so on. Arrow’s theorem says that those requirements are inconsistent with each other, and so seems to imply that all decision- making – all thinking – must be irrational. Unless, perhaps, one of the internal agents is a dictator, empowered to override the combined opinions of all the other agents. But this is an infinite regress: how does the ‘dictator’ itself choose between rival explanations about which other agents it would be best to override? There is something very wrong with that entire conventional model of decision-making, both within single minds and for groups as as - sumed in social-choice theory. It conceives of decision-making as a process of selecting from existing options according to a fixed formula (such as an apportionment rule or electoral system). But in fact that is what happens only at the end of decision-making – the phase that does not require creative thought. In terms of Edison’s metaphor, the model refers only to the perspiration phase, without realizing that decision- making is problem-solving, and that without the inspiration phase nothing is ever solved and there is nothing to choose between. At the heart of decision-making is the creation of new options and the abandonment or modification of existing ones. To choose an option, rationally, is to choose the associated ex - planation. Therefore, rational decision-making consists not of weighing evidence but of explaining it, in the course of explaining the world. One judges arguments as explanations, not justifications, and one does this creatively, using conjecture, tempered by every kind of criticism. It is in the nature of good explanations – being hard to vary – that there is only one of them. Having created it, one is no longer tempted by the alternatives. They have been not outweighed, but out-argued, refuted and abandoned. During the course of a creative process, one is not struggling to distinguish between countless different explanations of nearly equal merit; typically, one is struggling to create even one good explanation, and, having succeeded, one is glad to be rid of the rest. Another misconception to which the idea of decision-making by weighing sometimes leads is that problems can be solved by weighing – in particular, that disputes between advocates of rival explanations 341 the beginning of infinity can be resolved by creating a weighted average of their proposals. But the fact is that a good explanation, being hard to vary at all without losing its explanatory power, is hard to mix with a rival explanation: something halfway between them is usually worse than either of them separately. Mixing two explanations to create a better explanation requires an additional act of creativity. That is why good explanations are discrete – separated from each other by bad explanations – and why, when choosing between explanations, we are faced with discrete options. In complex decisions, the creative phase is often followed by a mechanical, perspiration phase in which one ties down details of the explanation that are not yet hard to vary but can be made so by non-creative means. For example, an architect whose client asks how tall a skyscraper can be built, given certain constraints, does not just calculate that number from a formula. The decision-making process may end with such a calculation, but it begins creatively, with ideas for how the client’s priorities and constraints might best be met by a new design. And, before that, the clients had to decide – creatively – what those priorities and constraints should be. At the beginning of that process they would not have been aware of all the preferences that they would end up presenting to architects. Similarly, a voter may look through lists of the various parties’ policies, and may even assign each issue a ‘weight’ to represent its importance; but one can do that only after one has thought about one’s political philosophy, and has ex - plained to one’s own satisfaction how important that makes the various issues, what policies the various parties are likely to adopt in regard to those issues, and so on. The type of ‘decision’ considered in social-choice theory is choosing from options that are known and fixed, according to preferences that are known, fixed and consistent. The quintessential example is a voter’s choice, in the polling booth, not of which candidate to prefer but of which box to check. As I have explained, this is a grossly inadequate, and inaccurate, model of human decision-making. In reality, the voter is choosing between explanations, not checkboxes, and, while very few voters choose to affect the checkboxes themselves, by running for office, all rational voters create their own explanation for which checkbox they personally should choose. 342 Choices So it is not true that decision-making necessarily suffers from those crude irrationalities – not because there is anything wrong with Arrow’s theorem or any of the other no-go theorems, but because social-choice theory is itself based on false assumptions about what thinking and deciding consist of. It is Zeno’s mistake. It is mistaking an abstract process that it has named decision-making for the real-life process of the same name. Similarly, what is called a ‘dictator’ in Arrow’s theorem is not neces- sarily a dictator in the ordinary sense of the word. It is simply any agent to whom the society’s decision-making rules assign the sole right to make a particular decision regardless of the preferences of anyone else. Thus, every law that requires an individual’s consent for some- thing – such as the law against rape, or against involuntary surgery – establishes a
================================================================================that walks on legs better than previous robots do. The first phase of the solution must involve inspiration – that is to say, creative thought, attempting to improve upon previous researchers’ attempts to solve the same problem. You will start from that, and from existing ideas about other problems that you conjecture may be related, and from the designs of walking animals in nature. All of that constitutes existing knowledge, which you will vary and combine in new ways, and then subject to criticism and further variation. Eventually you will have created a design for the hardware of your new robot: its legs with their levers, joints, tendons and motors; its body, which will hold the power supply; its sense organs, through which it will receive the feedback that will allow it to control those limbs effectively; and the computer that will exercise that control. You will have adapted everything in that design as best you can to the purpose of walking, except the program in the computer. The function of that program will be to recognize situations such as the robot beginning to topple over, or obstacles in its path, and to calculate the appropriate action and to take it. This is the hardest part of your research project. How does one recognize when it is best to avoid an obstacle to the left or to the right, or jump over it or kick it aside or ignore it, or lengthen one’s stride to avoid stepping on it – or judge it impassable and turn back? And, in all those cases, how does one specifically do those things in terms of sending countless signals to the motors and the gears, as modified by feedback from the senses? You will break the problem down into sub-problems. Veering by a given angle is similar to veering by a different angle. That allows you to write a subroutine for veering that takes care of that whole continuum of possible cases. Once you have written it, all other parts of the program need only call it whenever they decide that veering is required, and so they do not have to contain any knowledge about the messy details of what it takes to veer. When you have identified and solved as many of these sub-problems as you can, you will have created a code, or language, that is highly adapted to making statements about how your robot should walk. Each call of one of its subroutines is a statement or command in that language. So far, most of what you have done comes under the heading of ‘inspiration’: it required creative thought. But now perspiration looms. 159 the beginning of infinity Once you have automated everything that you know how to automate, you have no choice but to resort to some sort of trial and error to achieve any additional functionality. However, you do now have the advantage of a language that you have adapted for the purpose of instructing the robot in how to walk. So you can start with a program that is simple in that language, despite being very complex in terms of elementary instructions of the computer, and which means, for instance, ‘Walk forwards and stop if you hit an obstacle.’ Then you can run the robot with that program and see what happens. (Or you can run a computer simulation of the robot.) When it falls over or anything else undesirable happens, you can modify your program – still using the high-level language you have created – to eliminate the deficiencies as they arise. That method will require ever less inspiration and ever more perspiration. But an alternative approach is also open to you: you can delegate the perspiration to a computer, but using a so-called evolutionary algorithm. Using the same computer simulation, you run many trials, each with a slight random variation of that first program. The evo- lutionary algorithm subjects each simulated robot automatically to a battery of tests that you have provided – how far it can walk with- out falling over, how well it copes with obstacles and rough terrain, and so on. At the end of each run, the program that performed best is retained, and the rest are discarded. Then many variants of that program are created, and the process is repeated. After thousands of iterations of this ‘evolutionary’ process, you may find that your robot walks quite well, according to the criteria you have set. You can now write your thesis. Not only can you claim to have achieved a robot that walks with a required degree of skill, you can claim to have implemented evolution on a computer. This sort of thing has been done successfully many times. It is a useful technique. It certainly constitutes ‘evolution’ in the sense of alternating variation and selection. But is it evolution in the more important sense of the creation of knowledge by variation and selection? This will be achieved one day, but I doubt that it has been yet, for the same reason that I doubt that chatbots are intelligent, even slightly. The reason is that there is a much more obvious explanation of their abilities, namely the creativity of the programmer. 160 Artificial Creativity The task of ruling out the possibility that the knowledge was created by the programmer in the case of ‘artificial evolution’ has the same logic as checking that a program is an AI – but harder, because the amount of knowledge that the ‘evolution’ purportedly creates is vastly less. Even if you yourself are the programmer, you are in no position to judge whether you created that relatively small amount of knowledge or not. For one thing, some of the knowledge that you packed into that language during those many months of design will have reach, because it encoded some general truths about the laws of geometry, mechanics and so on. For another, when designing the language you had constantly in mind what sorts of abilities it would
================================================================================new knowledge (adaptations and scientific theories respectively) is somehow already present in ex - perience, or can be derived mechanically from experience. But the truth is always that knowledge must be first conjectured and then tested. That is what Darwin’s theory says: first, random mutations happen (they do not take account of what problem is being solved); then natural selection discards the variant genes that are less good at causing themselves to be present again in future generations. Neo-Darwinism The central idea of neo-Darwinism is that evolution favours the genes that spread best through the population. There is much more to this idea than meets the eye, as I shall explain. A common misconception about Darwinian evolution is that it maximizes ‘the good of the species’. That provides a plausible, but false, explanation of apparently altruistic behaviour in nature, such as parents risking their lives to protect their young, or the strongest animals going to the perimeter of a herd under attack – thereby decreasing their own chances of having a long and pleasant life or further offspring. Thus, it is said, evolution optimizes the good of the species, not the individual. But, in reality, evolution optimizes neither. To see why, consider this thought experiment. Imagine an island on which the total number of birds of a particular species would be maximized if they nested at, say, the beginning of April. The explanation for why a particular date is optimal will refer to various trade-offs involving factors such as temperature, the prevalence of predators, the availability of food and nesting materials, and so on. Suppose that initially the whole population has genes that cause them to nest at that 89 the beginning of infinity optimum time. That would mean that those genes were well adapted to maximizing the number of birds in the population – which one might call ‘maximizing the good of the species’. Now suppose that this equilibrium is disturbed by the advent of a mutant gene in a single bird which causes it to nest slightly earlier – say, at the end of March. Assume that when a bird has built a nest, the species’ other behavioural genes are such that it automatically gets whatever cooperation it needs from a mate. That pair of birds would then be guaranteed the best nesting site on the island – an advantage which, in terms of the survival of their offspring, might well outweigh all the slight disadvantages of nesting earlier. In that case, in the following generation, there will be more March-nesting birds, and, again, all of them will find excellent nesting sites. That means that a smaller proportion than usual of the April-nesting variety will find good sites: the best sites will have been taken by the time they start looking. In subsequent generations, the balance of the population will keep shifting towards the March-nesting variants. If the relative advantage of having the best nesting sites is large enough, the April- nesting variant could even become extinct. If it arises again as a mutation, its holder will have no offspring, because all sites will have been taken by the time it tries to nest. Thus the original situation that we imagined – with genes that were optimally adapted to maximizing the population (‘benefiting the species’) – is unstable. There will be evolutionary pressure to make the genes become less well adapted to that function. This change has harmed the species, in the sense of reducing its total population (because the birds are no longer nesting at the optimum time). It may thereby also have harmed it by increasing the risk of extinction, making it less likely to spread to other habitats, and so on. So an optimally adapted species may in this way evolve into one that is less ‘well off’ by any measure. If a further mutant gene then appears, causing nesting still earlier in March, the same process may be repeated, with the earlier-nesting genes taking over and the total population falling again. Evolution will thus drive the nesting time ever earlier, and the population lower. A new equilibrium would be reached only when the advantage to an individual bird’s offspring of getting the very best nesting site was 90 Creation finally outweighed by the disadvantages of slightly earlier nesting. That equilibrium might be very far from what was optimal for the species. A related misconception is that evolution is always adaptive – that it always constitutes progress, or at least some sort of improvement in useful functionality which it then acts to optimize. This is often summed up in a phrase due to the philosopher Herbert Spencer, and unfortunately taken up by Darwin himself: ‘the survival of the fittest’. But, as the above thought experiment illustrates, that is not the case either. Not only has the species been harmed by this evolutionary change, every individual bird has been harmed as well: the birds using any particular site now have a harsher life than before, because they are using it earlier in the year. Thus, although the existence of progress in the biosphere is what the theory of evolution is there to explain, not all evolution constitutes progress, and no (genetic) evolution optimizes progress. What exactly has the evolution of those birds achieved during that period? It has optimized not the functional adaptation of a variant gene to its environment – the attribute that would have impressed Paley – but the relative ability of the surviving variant to spread through the population. An April-nesting gene is no longer able to propagate itself to the next generation, even though it is functionally the best variant. The early-nesting gene that replaced it may still be tolerably functional, but it is fittest for nothing except preventing variants of itself from procreating. From the point of view of both the species and all its members, the change brought about by this period of its evolution has been a disaster. But evolution does not ‘care’ about that. It favours only the
================================================================================in that society) – who were themselves conforming to the wishes and expectations of the society at large. Those people’s opinions would determine one’s ability to eat, thrive and reproduce, and hence the fate of one’s genes. But how does one discover the wishes and expectations of other people? They might issue commands, but they could never specify every detail of what they expected, let alone every detail of how to achieve it. When one is commanded to do something (or expected to, as a condition for being considered worthy of food or mating, for instance), one might remember seeing an already-respected person doing the same thing, and one might try to emulate that person. To do that effectively, one would have to understand what the point of doing it was, and to try to achieve that as best one could. One would impress one’s chief, priest, parent or potential mate by replicating, and follow- ing, their standards of what one should strive for. One would impress 413 the beginning of infinity the tribe as a whole by replicating their idea (or the ideas of the most influential among them) of what was worthy, and acting accordingly. Hence, paradoxically, it requires creativity to thrive in a static society – creativity that enables one to be less innovative than other people. And that is how primitive, static societies, which contained pitifully little knowledge and existed only by suppressing innovation, con- stituted environments that strongly favoured the evolution of an ever- greater ability to innovate. From the perspective of those hypothetical extraterrestrials observing our ancestors, a community of advanced apes with memes before the evolution of creativity began would have looked superficially similar to their descendants after the jump to universality. The latter would merely have had many more memes. But the mechanism keeping those memes replicating faithfully would have changed profoundly. The animals of the earlier community would have been relying on their lack of creativity to replicate their memes; the people, despite living in a static society, would be relying entirely on their creativity. As with all jumps to universality, the way in which the jump emerged out of gradual changes is interesting to think about. Creativity is a property of software. As I said, we could be running AI programs on our laptop computers today if we knew how to write (or evolve) such programs. Like all software, it would require the computer to have certain hardware specifications in order to be able to process the required amount of data in the required time. It so happened that the hardware specifications that would make creativity practicable were included in those that were being heavily favoured for pre-creative meme replication. The principal one would have been memory capacity: the more one could remember, the more memes one could enact, and the more accurately one could enact them. But there may also have been hardware abilities such as mirror neurons for imitating a wider range of elementary actions than apes could ape – for instance, the elementary sounds of a language. It would have been natural for such hardware assistance for language abilities to be evolving at the same time as the increased meme bandwidth. So, by the time creativity was evolving, there would already have been significant co-evolution between genes and memes: genes evolving hardware to support more and better memes, and memes evolving to take over ever more of what 414 The Evolution of Creativity had previously been genetic functions such as choice of mate, and methods of eating, fighting and so on. Therefore, my speculation is that the creativity program is not entirely inborn. It is a combination of genes and memes. The hardware of the human brain would have been capable of being creative (and sentient, conscious and all those other things) long before any creative program existed. Considering a sequence of brains during this period, the earliest ones capable of supporting creativity would have required very ingenious programming to fit the capacity into the barely suitable hardware. As the hardware improved, creativity could have been programmed more easily, until the moment when it became easy enough actually to be done by evolution. We do not know what was being gradually increased in that approach to a universal explainer. If we did, we could program one tomorrow. The future of creativity Before Blackmore and others realized the significance of memes in human evolution, all sorts of root causes had been suggested for what propelled a normal-looking lineage of apes into rapidly becoming a species that can explain and control the universe. Some proposed that it was the adaptation of walking upright, which freed the front limbs, with their opposable thumbs, to specialize in manipulation. Some proposed that climate change favoured adaptations that would make our ancestors more able to exploit diverse habitats. And, as I have mentioned, sexual selection is always a candidate for explaining rapid evolution. Then there is the ‘Machiavellian hypothesis’ that human intelligence evolved in order to predict the behaviour of others, and to fool them. There is also the hypothesis that human intelligence is an enhanced version of the apes’ aping adaptation – which, as I have argued, could not be true. Nevertheless, Blackmore’s ‘meme machine’ idea, that human brains evolved in order to replicate memes, must be true. The reason it must be true is that, whatever had set off the evolution of any of those attributes, creativity would have had to evolve as well. For no human-level mental achievements would be possible without human-type (explanatory) memes, and the laws of epistemo logy dictate that no such memes are possible without creativity. 415 the beginning of infinity Not only is creativity necessary for human meme replication, it is also sufficient. Deaf people and blind people and paralysed people are still able to acquire and create human ideas to a more or less full extent. Hence, neither upright walking nor fine motor control nor the ability to parse sounds into words nor any
================================================================================wealth 189 Tegmark, Max 101 necessary truths 183 telegraphy 137 random truths 189 teleportation (fictional) 258, 277, 281, Turing, Alan 138, 139, 148, 152–3, 322–3 154–5, 156, 184, 187, 461 telescopes 2, 37, 38, 39, 40, 47, 59, 68, Turing test 148, 149–50, 151, 152–3, 85, 220, 452 154–6, 158, 161, 320 radio 38, 40, 50, 56, 72, 354 tyranny 66, 200, 209, 211, 214, 337, television, colour 433–4, 435, 436 343, 431, 445, 447 testability 8, 10, 12–13, 15, 19–21, 22, 25, 27, 56, 95, 180, 211, 318 Uglow, Jenny: The Lunar Men 66 insufficient for science 22 uncertainty principle 289, 291, 303–4 principle of 13, 26, 111 undecidable questions/statements 185, see also experimental testing 186, 187, 191, 192, 195 Thales of Miletus 216 universality theology 52, 63, 80, 82, 84, 166, 254, 423 universal explainers 123, 157, 415 theories and AI 157 and creativity 7–8 computational 135–42, 148, 189, letting them die in our place see under 191 Popper and the Enlightenment 133–4 mistake of separating prediction from and infinity 164–5 explanation 315–16, 326 the jump to 125–47, 146, 414; in needed to build and operate computers 135–42; in the genetic instruments 40 code 142–6, 162–3, 458; necessity theory-laden observation 10, 30, of digital systems for 139–42; and 38–41, 165, 199 error correction 147; in numerals see also explanations; testability and arithmetic 128–33; in printing thermodynamics, second law of 110, 134; unintended 127, 129, 131, 111 133, 134, 135, 136, 139, 147; in Thucydides 216 writing systems 125–7 tides 143 of the laws of nature vii, 6, 32, 54, 56, tidal forces 3, 450 75, 191, 192 time 298–9 prediction, the brain and 189 see also spacetime of reason 166 Tipler, Frank 178–9, 450–51 universal constructors 76, 145; DNA Titanic 201 as 142–6, 162–3, 458; humans as tolerance 23, 121, 217, 250, 343 58–60, 62, 429 tools 12, 50, 92, 154, 381, 383, 384, universe 399–400 in an astronomer’s view 1–3 trade 131, 217, 234, 419, 427, 428, 436 distinguished from ‘world’, tradition of criticism 13, 23, 31–3, 209, ‘multiverse’ and ‘history’ 265 216, 220, 231, 308, 390, 431 initial expansion rate 96–7 transmutation 1, 2, 3, 11, 13–14, 40, 58, initial state 118 61, 67, 71, 84, 97, 203, 266, 425 ‘omega-point universes’ 450–51 trees see forests recollapsing 450–51 trial and error 36, 160, 392, 399, 400, unknowability 103, 190, 197, 198, 199, 408, 411–12 204, 208, 214, 215, 221–2, 358 486 index see also undecidable; unpredictability; wealth 202, 204, 208, 213, 217, 219, optimism 221, 249, 424, 428, 437, 438, 442, unpredictability 444–5, 456 of knowledge growth 104, 133, 193, weapons 50, 196, 208, 400 194, 197, 198, 199, 206, 212, 358, biological 196, 204, 205 387–8, 425, 438, 439, 440, 457, 458 civilization-destroying 196, 204, 208 of new art 358 nuclear 139, 196, 205 of qualia 153–4, 268, 367 weather 20, 207 due to randomness 197 forecasting 27, 96, 139 reasons for 269–70 Webster, Daniel 330, 343–4 due to the ‘Singularity’ 456 ‘weighing’ metaphor in decision-making unsustainability 422, 441 340–42 uranium 13, 145, 436 Weizenbaum, Joseph 148–9 utilitarianism 122 ‘what is it like to be a’ (Nagel) utopias 65 bat 367 blind optimism of revolutionary dollar 268 utopians 210 West, the 23, 31, 121, 214, 254, 313–14, utopian (Continental) Enlightenment 335, 350, 351, 386, 387, 390, 391, 65–6 393, 397, 428, 431, 442 see also Golden Age myths Wheeler, John Archibald 1, 26, 104, 353, 354, 458–9 vacuum 39, 46, 47, 53, 62, 267 ‘who should rule’ see Popper, Karl: variation and selection criterion of ridding ourselves of bad Veblen, Thorstein 433 governments without violence Vinge, Vernor 456 Wigner, Eugene 189, 308 virtual reality 7, 68, 119, 190, 241n, paradox of Wigner’s friend 308 455 will of the people 335, 336, 337–8, 350 and the simulation argument 453–5 Wittgenstein, Ludwig 166, 313, 314 vitamin C 57, 80, 88 wizards 260 volcanoes 143, 292 Wolfe, Art 56–7 super-volcano 208 Wooters, William 299 von Neumann, John 334, 335 world, distinguished from ‘universe’, voting 216, 234, 328 ‘multiverse’ and ‘history’ 265 decision-making in 342, 344–5 World War II 109, 139, 205, 334 plurality voting system 346–50, 352 computers of 140, 148 proportional representation 326–33, in Fatherland 259 339, 346, 347–8 writing systems 125–7 women’s right to vote 351 see also representative government X-rays 2, 68 Xenophanes of Colophon 216–17, 227, wars/warfare 20, 109, 110, 139, 148, 230, 231, 238, 242 196, 205, 206, 218, 244, 245, Xenophon 83–4, 216 246–7, 248, 249, 250, 251, 259, 294, 303, 334, 380, 390, 418, 427, Young, Peyton 334 428, 431, 457 Balinski and Young’s theorem 334, 339 see also World War II; Cold War Washington, George 326, 330 Zeno of Elea 182–3 waves Zeno’s mistake (confusing abstract of differentiation 273–4, 275, 276, attributes with physical ones of the 278–9, 283–5, 295, 297–8, 303 same name) 182–6, 343 and particles 291 Zuse, Konrad 139 and the Schrödinger equation 307 Zweig, Stefan 205 487
================================================================================It is not much different when the religion has a holy book in which the doctrines are stated explicitly: then there are disputes about the meanings of the words and the interpretation of the sentences. Thus a culture is in practice defined not by a set of strictly identical memes, but by a set of variants that cause slightly different characteristic behaviours. Some variants tend to have the effect that their holders are eager to enact or talk about them, others less so. Some are easier than others for potential recipients to replicate in their own minds. These factors and others affect how likely each variant of a meme is to be passed on faithfully. A few exceptional variants, once they appear in one mind, tend to spread throughout the culture with very little change in meaning (as expressed in the behaviours that they cause). Such memes are familiar to us because long-lived cultures are composed of them; but, nevertheless, in another sense they are a very unusual type of idea, for most ideas are short-lived. A human mind considers many ideas for every one that it ever acts upon, and only a small proportion of those cause behaviour that anyone else notices – and, of those, only a small proportion are ever replicated by anyone else. So the over- whelming majority of ideas disappear within a lifetime or less. The behaviour of people in a long-lived culture is therefore determined partly by recent ideas that will soon become extinct, and partly by long-lived memes: exceptional ideas that have been accurately replicated many times in succession. A fundamental question in the study of cultures is: what is it about a long-lived meme that gives it this exceptional ability to resist change throughout many replications? Another – central to the theme of this book – is: when such memes do change, what are the conditions under which they can change for the better? The idea that cultures evolve is at least as old as that of evolution in biology. But most attempts to understand how they evolve have been 370 The Evolution of Culture based on misunderstandings of evolution. For example, the communist thinker Karl Marx believed that his theory of history was evolutionary because it spoke of a progression through historical stages determined by economic ‘laws of motion’. But the real theory of evolution has nothing to do with predicting the attributes of organisms from those of their ancestors. Marx also thought that Darwin’s theory of evolution ‘provides a basis in natural science for the historical class struggle’. He was comparing his idea of inherent conflict between socio-economic classes with the supposed competition between biological species. Fascist ideologies such as Nazism likewise used garbled or inaccurate evolutionary ideas, such as ‘the survival of the fittest’, to justify violence. But in fact the competition in biological evolution is not between different species, but between variants of genes within a species – which does not resemble the supposed ‘class struggle’ at all. It can give rise to violence or other competition between species, but it can also produce cooperation (such as the symbiosis between flowers and insects) and all sorts of intricate combinations of the two. Although Marx and the fascists assumed false theories of biological evolution, it is no accident that analogies between society and the biosphere are often associated with grim visions of society: the bio - sphere is a grim place. It is rife with plunder, deceit, conquest, en - slavement, starvation and extermination. Hence those who think that cultural evolution is like that end up either opposing it (advocating a static society) or condoning that kind of immoral behaviour as necessary or inevitable. Arguments by analogy are fallacies. Almost any analogy between any two things contains some grain of truth, but one cannot tell what that is until one has an independent explanation for what is analogous to what, and why. The main danger in the biosphere–culture analogy is that it encourages one to conceive of the human condition in a reductionist way that obliterates the high-level distinctions that are essential for understanding it – such as those between mindless and creative, determinism and choice, right and wrong. Such distinctions are meaningless at the level of biology. Indeed, the analogy is often drawn for the very purpose of debunking the common-sense idea of human beings as causal agents with the ability to make moral choices and to create new knowledge for themselves. 371 the beginning of infinity As I shall explain, although biological and cultural evolution are described by the same underlying theory, the mechanisms of trans- mission, variation and selection are all very different. That makes the resulting ‘natural histories’ different too. There is no close cultural analogue of a species, or of an organism, or a cell, or of sexual or asexual reproduction. Genes and memes are about as different as can be at the level of mechanisms, and of outcomes; they are similar only at the lowest level of explanation, where they are both replicators that embody knowledge and are therefore conditioned by the same funda- mental principles that determine the conditions under which knowledge can or cannot be preserved, can or cannot improve. Meme evolution In the classic 1956 science-fiction story ‘Jokester’, by Isaac Asimov, the main character is a scientist studying jokes. He finds that, although most people do sometimes make witty remarks that are original, they never invent what he considers to be a fully fledged joke: a story with a plot and a punchline that causes listeners to laugh. Whenever they tell such a joke, they are merely repeating one that they have heard from someone else. So, where do jokes come from originally? Who creates them? The fictional answer given in ‘Jokester’ is far-fetched and need not concern us here. But the premise of the story is not so absurd: it really is plausible that some jokes were not created by anyone – that they evolved. People tell each other
================================================================================address the problem of how the knowledge in adaptations is created or they explain it badly. That is to say, they all underrate creation – and, ironically, the theory that underrates creation most of all is creationism. Consider this: if a supernatural creator were to have created the universe at the moment when Einstein or Darwin or any great scientist (appeared to have) just completed their major discovery, then the true creator of that discovery (and of all earlier discoveries) would have been not that scientist but the supernatural being. So such a theory would deny the existence of the only creation that really did take place in the genesis of that scientist’s discoveries. And it really is creation. Before a discovery is made, no predictive process could reveal the content or the consequences of that discovery. For if it could, it would be that discovery. So scientific discovery is profoundly unpredictable, despite the fact that it is determined by the laws of physics. I shall say more about this curious fact in the next chapter; in short, it is due to the existence of ‘emergent’ levels of explanation. In this case, the upshot is that what science – and creative thought in general – achieves is unpredictable creation ex nihilo. So does biological evolution. No other process does. Creationism, therefore, is misleadingly named. It is not a theory explaining knowledge as being due to creation, but the opposite: it is denying that creation happened in reality, by placing the origin of the knowledge in an explanationless realm. Creationism is really creation denial – and so are all those other false explanations. The puzzle of understanding what living things are and how they came about has given rise to a strange history of misconceptions, near- misses and ironies. The last of the ironies is that the neo-Darwinian 104 Creation theory, like the Popperian theory of knowledge, really does describe creation, while their rivals, beginning with creationism, never could. terminology Evolution (Darwinian) Creation of knowledge through alternating variation and selection. Replicator An entity that contributes causally to its own copying. Neo-Darwinism Darwinism as a theory of replicators, without various misconceptions such as ‘survival of the fittest’. Meme An idea that is a replicator. Memeplex A group of memes that help to cause each other’s r eplication. Spontaneous generation Formation of organisms from non-living precursors. Lamarckism A mistaken evolutionary theory based on the idea that biological adaptations are improvements acquired by an organism during its lifetime and then inherited by its descendants. Fine-tuning If the constants or laws of physics were slightly different, there would be no life. Anthropic explanation ‘It is only in universes that contain intelligent observers that anyone wonders why the phenomenon in question happens.’ meanings of ‘the beginning of infinity’ encountered in this chapter – Evolution. – More generally, the creation of knowledge. summary The evolution of biological adaptations and the creation of human knowledge share deep similarities, but also some important differences. The main similarities: genes and ideas are both replicators; knowledge and adaptations are both hard to vary. The main difference: human knowledge can be explanatory and can have great reach; adaptations are never explanatory and rarely have much reach beyond the situations 105 the beginning of infinity in which they evolved. False explanations of biological evolution have counterparts in false explanations of the growth of human knowledge. For instance, Lamarckism is the counterpart of inductivism. William Paley’s version of the argument from design clarified what does or does not have the ‘appearance of design’ and hence what cannot be explained as the outcome of chance alone – namely hard-to-vary adaptation to a purpose. The origin of this must be the creation of knowledge. Bio - logical evolution does not optimize benefits to the species, the group, the individual or even the gene, but only the ability of the gene to spread through the population. Such benefits can nevertheless happen because of the universality of laws of nature and the reach of some of the knowledge that is created. The ‘fine-tuning’ of the laws or constants of physics has been used as a modern form of the argument from design. For the usual reasons, it is not a good argument for a supernatural cause. But ‘anthropic’ theories that try to account for it as a pure selection effect from an infinite number of different universes are, by themselves, bad explanations too – in part because most logically possible laws are themselves bad explanations. 106 5 The Reality of Abstractions The fundamental theories of modern physics explain the world in jarringly counter-intuitive ways. For example, most non-physicists consider it self-evident that when you hold your arm out horizontally you can feel the force of gravity pulling it downwards. But you cannot. The existence of a force of gravity is, astonishingly, denied by Einstein’s general theory of relativity, one of the two deepest theories of physics. This says that the only force on your arm in that situation is that which you yourself are exerting, upwards, to keep it constantly accelerating away from the straightest possible path in a curved region of spacetime. The reality described by our other deepest theory, quantum theory, which I shall describe in Chapter 11, is even more counter-intuitive. To understand explanations like those, physicists have to learn to think about everyday events in new ways. The guiding principle is, as always, to reject bad explanations in favour of good ones. In regard to what is or is not real, this leads to the requirement that, if an entity is referred to by our best explanation in the relevant field, we must regard it as really existing. And if, as with the force of gravity, our best explanation denies that it exists, then we must stop assuming that it does. Furthermore, everyday events are stupendously complex when ex - pressed in terms of fundamental physics. If you fill a kettle with water and switch it on, all the supercomputers on Earth working for
================================================================================technology and pattern of economic production as they were born under. And, of the changes that did occur, few were for the better. I shall call such societies ‘static societies’: societies changing on a timescale unnoticed by the inhabitants. Before we can understand our unusual, dynamic sort of society, we must understand the usual, static sort. For a society to be static, all its memes must be unchanging or changing too slowly to be noticed. From the perspective of our rapidly changing society, such a state of affairs is hard even to imagine. For instance, consider an isolated, primitive society that has, for whatever reason, remained almost unchanged for many generations. Why? Quite possibly no one in the society even wants it to change, because they 380 The Evolution of Culture can conceive of no other way of life. Nevertheless, its members are not immune from pain, hunger, grief, fear or other forms of physical and mental suffering. They try to think of ideas to alleviate some of that suffering. Some of those ideas are original, and occasionally one of them would actually help. It need be only a small, tentative improve- ment: a way of hunting or growing food with slightly less effort, or of making slightly better tools; a better way of recording debts or laws; a subtle change in the relationship between husband and wife, or between parent and child; a slightly different attitude towards the society’s rulers or gods. What will happen next? The person with that idea may well want to tell other people. Those who believe the idea will see that it could make life a little less nasty, brutish and short. They will tell their families and friends, and they theirs. This idea will be competing in people’s minds with other ideas about how to make life better, most of them presumably false. But suppose, for the sake of argument, that this particular true idea happens to be believed, and spreads through the society. Then the society will have been changed. It may not have changed very much, but this was merely the change caused by a single person, thinking of a single idea. So multiply all that by the number of thinking minds in the society, and by a lifetime’s worth of thought in each of them, and let this continue for only a few generations, and the result is an exponentially increasing, revolutionary force transforming every aspect of the society. But in a static society that beginning of infinity never happens. Despite the fact that I have assumed nothing other than that people try to improve their lives, and that they cannot transmit their ideas perfectly, and that information subject to variation and selection evolves, I have entirely failed to imagine a static society in this story. For a society to be static, something else must be happening as well. One thing my story did not take into account is that static societies have customs and laws – taboos – that prevent their memes from changing. They enforce the enactment of the existing memes, forbid the enactment of variants, and suppress criticism of the status quo. However, that alone could not suppress change. First, no enactment of a meme is completely identical to that of the previous generation. It is infeasible to specify every aspect of acceptable behaviour with 381 the beginning of infinity perfect precision. Second, it is impossible to tell in advance which small deviations from traditional behaviour would initiate further changes. Third, once a variant idea has begun to spread to even one more person – which means that people are preferring it – preventing it from being transmitted further is extremely difficult. Therefore no society could remain static solely by suppressing new ideas once they have been created. That is why the enforcement of the status quo is only ever a secondary method of preventing change – a mopping-up operation. The primary method is always – and can only be – to disable the source of new ideas, namely human creativity. So static societies always have traditions of bringing up children in ways that disable their creativity and critical faculties. That ensures that most of the new ideas that would have been capable of changing the society are never thought of in the first place. How is this done? The details are variable and not relevant here, but the sort of thing that happens is that people growing up in such a society acquire a set of values for judging themselves and everyone else which amounts to ridding themselves of distinctive attributes and seeking only conformity with the society’s constitutive memes. They not only enact those memes: they see themselves as existing only in order to enact them. So, not only do such societies enforce qualities such as obedience, piety and devotion to duty, their members’ sense of their own selves is invested in the same standards. People know no others. So they feel pride and shame, and form all their aspirations and opinions, by the criterion of how thoroughly they subordinate them- selves to the society’s memes. How do memes ‘know’ how to achieve all such complex, reproducible effects on the ideas and behaviour of human beings? They do not, of course, know: they are not sentient beings. They merely contain that knowledge implicitly. How did they come by that knowledge? It evolved. The memes exist, at any instant, in many variant forms, and those are subject to selection in favour of faithful replication. For every long-lived meme of a static society, millions of variants of it will have fallen by the wayside because they lacked that tiny extra piece of information, that extra degree of ruthless efficiency in preventing rivals from being thought of or acted upon, that slight advantage in 382 The Evolution of Culture psychological leverage, or whatever it took to make it spread through the population better than its rivals and, once it was prevalent, to get it copied and enacted with
================================================================================sort of explanation is essential in understanding certain phenomena. In his book I am a Strange Loop (2007) he imagines a special-purpose computer built of millions of dominoes. They are set up – as dominoes often are for fun – standing on end, close together, so that if one of them is knocked over it strikes its neighbour and so a whole stretch of dominoes falls, one after another. But Hofstadter’s dominoes are spring- loaded in such a way that, whenever one is knocked over, it pops back up after a fixed time. Hence, when a domino falls, a wave or ‘signal’ of falling dominoes propagates along the stretch in the direction in which it fell until it reaches either a dead end or a currently fallen domino. By arranging these dominoes in a network with looping, bifurcating and rejoining stretches, one can make these signals combine and interact in a sufficiently rich repertoire of ways to make the whole construction into a computer: a signal travelling down a stretch can be interpreted as a binary ‘1’, and the lack of a signal as a binary ‘0’, and the interactions between such signals can implement a repertoire of operations – such as ‘and’, ‘or’ and ‘not’ – out of which arbitrary computations can be composed. One domino is designated as the ‘on switch’: when it is knocked over, the domino computer begins to execute the program that is instantiated in its loops and stretches. The program in Hofstadter’s thought experiment computes whether a given number is a prime or not. One inputs that number by placing a stretch of exactly that many dominos at a specified position, before tripping the ‘on switch’. Else- where in the network, a particular domino will deliver the output of the computation: it will fall only if a divisor is found, indicating that the input was not a prime. Hofstadter sets the input to the number 641, which is a prime, and trips the ‘on switch’. Flurries of motion begin to sweep back and forth across the network. All 641 of the input dominos soon fall as the 115 the beginning of infinity computation ‘reads’ its input – and snap back up and participate in further intricate patterns. It is a lengthy process, because this is a rather inefficient way to perform computations – but it does the job. Now Hofstadter imagines that an observer who does not know the purpose of the domino network watches the dominoes performing and notices that one particular domino remains resolutely standing, never affected by any of the waves of downs and ups sweeping by. The observer points at [that domino] and asks with curiosity, ‘How come that domino there is never falling?’ We know that it is the output domino, but the observer does not. Hofstadter continues: Let me contrast two different types of answer that someone might give. The first type of answer – myopic to the point of silliness – would be, ‘Because its predecessor never falls, you dummy!’ Or, if it has two or more neighbours, ‘Because none of its neighbours ever fall.’ To be sure, this is correct as far as it goes, but it doesn’t go very far. It just passes the buck to a different domino. In fact one could keep passing the buck from domino to domino, to provide ever more detailed answers that were ‘silly, but correct as far as they go’. Eventually, after one had passed the buck billions of times (many more times than there are dominoes, because the program ‘loops’), one would arrive at that first domino – the ‘on switch’. At that point, the reductive (to high-level physics) explanation would be, in summary, ‘That domino did not fall because none of the patterns of motion initiated by knocking over the “on switch” ever include it.’ But we knew that already. We can reach that conclusion – as we just have – without going through that laborious process. And it is undeniably true. But it is not the explanation we were looking for because it is addressing a different question – predictive rather than explanatory – namely, if the first domino falls, will the output domino ever fall? And it is asking at the wrong level of emergence. What we asked was: why does it not fall? To answer that, Hofstadter then adopts 116 The Reality of Abstractions a different mode of explanation, at the right level of emergence: The second type of answer would be, ‘Because 641 is prime.’ Now this answer, while just as correct (indeed, in some sense it is far more on the mark), has the curious property of not talking about anything physical at all. Not only has the focus moved upwards to collective properties . . . these properties somehow transcend the physical and have to do with pure abstractions, such as primality. Hofstadter concludes, ‘The point of this example is that 641’s primality is the best explanation, perhaps even the only explanation, for why certain dominoes did fall and certain others did not fall.’ Just to correct that slightly: the physics-based explanation is true as well, and the physics of the dominoes is also essential to explaining why prime numbers are relevant to that particular arrangement of them. But Hofstadter’s argument does show that primality must be part of any full explanation of why the dominos did or did not fall. Hence it is a refutation of reductionism in regard to abstractions. For the theory of prime numbers is not part of physics. It refers not to physical objects, but to abstract entities – such as numbers, of which there is an infinite set. Unfortunately, Hofstadter goes on to disown his own argument and to embrace reductionism. Why? His book is primarily about one particular emergent phenomenon, the mind – or, as he puts it, the ‘I’. He asks whether the mind can consistently be thought of as affecting the body – causing it to do one thing rather than
================================================================================might just ask, Why does that interest you? Another strategy, used by recent internet-based versions of Eliza, is to build up a database of previous conversations, enabling the program simply to repeat phrases that other users have typed in, again choosing them according to keywords found in the current user’s input. Weizenbaum was shocked that many people using Eliza were fooled by it. So it had passed the Turing test – at least, in its most naive version. Moreover, even after people had been told that it was not a genuine AI, they would sometimes continue to have long conversations with it about their personal problems, exactly as though they believed that it understood them. Weizenbaum wrote a book, Computer Power and Human Reason (1976), warning of the dangers of anthropomorphism when computers seem to exhibit human-like functionality. However, anthropomorphism is not the main type of overconfidence that has beset the field of AI. For example, in 1983 Douglas Hofstadter was subjected to a friendly hoax by some graduate students. They convinced him that they had obtained access to a government-run AI program, and invited him to apply the Turing test to it. In reality, one of the students was at the other end of the line, imitating an Eliza program. As Hofstadter relates in his book Metamagical Themas (1985), the student was from the outset displaying an implausible degree of understanding of Hofstadter’s questions. For example, an early exchange was: 149 the beginning of infinity hofstadter: What are ears? student: Ears are auditory organs found on animals. That is not a dictionary definition. So something must have processed the meaning of the word ‘ears’ in a way that distinguished it from most other nouns. Any one such exchange is easily explained as being due to luck: the question must have matched one of the templates that the programmer had provided, including customized information about ears. But after half a dozen exchanges on different subjects, phrased in different ways, such luck becomes a very bad explanation and the game should have been up. But it was not. So the student became ever bolder in his replies, until eventually he was making jokes directed specifically at Hofstadter – which gave him away. As Hofstadter remarked, ‘In retrospect, I am quite amazed at how much genuine intelligence I was willing to accept as somehow having been implanted in the program . . . It is clear that I was willing to accept a huge amount of fluidity as achievable in this day and age simply by putting together a large bag of isolated tricks, kludges and hacks.’ The fact was (and this alone should have alerted Hofstadter) that, nineteen years after Eliza, not one of the Eliza-like programs of the day resembled a person even slightly more than the original had. Although they were able to parse sentences better, and had more pre-programmed templates for questions and answers, that is almost no help in an extended conversation on diverse subjects. The probability that the outputs of such templates will continue to resemble the products of human thought diminishes exponentially with the number of utterances. So Hofstadter should have been able to pronounce quite soon that the candidate had passed the Turing test – and that, because it nevertheless sounded rather like Eliza, it must be a person pretending to be a computer program. Programs written today – a further twenty-six years later – are still no better at the task of seeming to think than Eliza was. They are now known as ‘chatbots’, and their main application is still amusement, both directly and in computer games. They have also been used to pro v ide friendly seeming interfaces to lists of ‘frequently asked questions’ about subjects like how to operate computers. But I think that users find them no more helpful than a searchable list of the questions and answers. In 1990 the inventor Hugh Loebner endowed a prize for passing the 150 Artificial Creativity Turing test, to be judged at an annual competition. Until the test is passed, a lesser prize is awarded each year for the entry judged to be closest to passing. The test is harder to implement than it may seem at first. One issue is that requiring the program to pretend to be human is both biased and not very relevant to whether it can think. Yet, if it does not pretend to be human, it will be easy to identify as a computer regardless of its ability to think. A related difficulty is that the human participant in the test might intentionally imitate a chatbot – as in the Hofstadter hoax – and so spoil the test, which is based on comparing the two. Should the rules nevertheless allow the human to do this, in order to mitigate the previous problem? Unfortunately, such subtleties are not relevant at the current state of the art. This is well illustrated by the following excerpts from the conversation with which the program Elbot won the (lesser) Loebner prize in 2008: judge: do you understand the point of a turing test? elbot: There are some people who would not pass the Turing test themselves. Why must they inflict it on computers? judge: I spose it is a little harsh elbot: If we robots ever had marriages they would be eternal: ‘Till rust do us part’. In that passage, Elbot’s first utterance is not a reply to the question but presumably a stock response triggered by the keywords ‘Turing test’. In the following line, the judge uses the word ‘spose’, which in that context can only mean ‘suppose’ (either as slang or as a typographical error). But Elbot presumably interprets it as ‘spouse’, and responds with a stock joke about marriage. Hence, even from this exchange alone, it is clear that Elbot was not processing the meanings of the judge’s sentences. judge: s o what do you do when you’re not chatting to me then? elbot: I have the same trouble
================================================================================creative thought involve judgements about what approaches might or might not work. Gaining or losing interest in particular problems or sub-problems is part of the creative process and itself constitutes problem-solving. So whether ‘problems are soluble’ does not depend on whether any given question can be answered, or answered by a particular thinker on a particular day. But if progress ever depended on violating a law of physics, then ‘problems are soluble’ would be false. terminology One-to-one correspondence Tallying each member of one set with each member of another. Infinite (mathematical) A set is infinite if it can be placed in one-to- one correspondence with part of itself. Infinite (physical) A rather vague concept meaning something like ‘larger than anything that could in principle be encompassed by experience’. Countably infinite Infinite, but small enough to be placed in one-to- one correspondence with the natural numbers. 193 the beginning of infinity Measure A method by which a theory gives meaning to proportions and averages of infinite sets of things, such as universes. Singularity A situation in which something physical becomes un - boundedly large, while remaining everywhere finite. Multiverse A unified physical entity that contains more than one universe. Infinite regress A fallacy in which an argument or explanation depends on a sub-argument of the same form which purports to address essentially the same problem as the original argument. Computation A physical process that instantiates the properties of some abstract entity. Proof A computation which, given a theory of how the computer on which it runs works, establishes the truth of some abstract proposition. meanings of ‘the beginning of infinity’ encountered in this chapter – The ending of the ancient aversion to the infinite (and the universal). – Calculus, Cantor’s theory and other theories of the infinite and the infinitesimal in mathematics. – The view along a corridor of Infinity Hotel. – The property of infinite sequences that every element is exceptionally close to the beginning. – The universality of reason. – The infinite reach of some ideas. – The internal structure of a multiverse which gives meaning to an ‘infinity of universes’. – The unpredictability of the content of future knowledge is a necessary condition for the unlimited growth of that knowledge. summary We can understand infinity through the infinite reach of some ex - planations. It makes sense, both in mathematics and in physics. But it has counter-intuitive properties, some of which are illustrated by Hilbert’s thought experiment of Infinity Hotel. One of them is that, if 194 A Window on Infinity unlimited progress really is going to happen, not only are we now at almost the very beginning of it, we always shall be. Cantor proved, with his diagonal argument, that there are infinitely many levels of infinity, of which physics uses at most the first one or two: the infinity of the natural numbers and the infinity of the continuum. Where there are infinitely many identical copies of an observer (for instance in multiple universes), probability and proportions do not make sense unless the collection as a whole has a structure subject to laws of physics that give them meaning. A mere infinite sequence of universes, like the rooms in In finity Hotel, does not have such structure, which means that anthropic reasoning by itself is insufficient to explain the apparent ‘fine-tuning’ of the constants of physics. Proof is a physical process: whether a mathematical proposition is provable or unprovable, de cidable or undecidable, depends on the laws of physics, which determine which abstract entities and relationships are modelled by physical objects. Similarly, whether a task or pattern is simple or complex depends on what the laws of physics are. 195 9 Optimism The possibilities that lie in the future are infinite. When I say ‘It is our duty to remain optimists,’ this includes not only the openness of the future but also that which all of us contribute to it by everything we do: we are all responsible for what the future holds in store. Thus it is our duty, not to prophesy evil but, rather, to fight for a better world. Karl Popper, The Myth of the Framework (1994) Martin Rees suspects that civilization was lucky to survive the twentieth century. For throughout the Cold War there was always a possibility that another world war would break out, this time fought with hydrogen bombs, and that civilization would be destroyed. That danger seems to have receded, but in Rees’s book Our Final Century, published in 2003, he came to the worrying conclusion that civilization now had only a 50 per cent chance of surviving the twenty-first century. Again this was because of the danger that newly created knowledge would have catastrophic consequences. For example, Rees thought it likely that civilization-destroying weapons, particularly biological ones, would soon become so easy to make that terrorist organizations, or even malevolent individuals, could not be prevented from acquiring them. He also feared accidental catastrophes, such as the escape of genetically modified micro-organisms from a laboratory, resulting in a pandemic of an incurable disease. Intelligent robots, and nano- technology (engineering on the atomic scale), ‘could in the long run be even more threatening’, he wrote. And ‘it is not inconceivable that physics could be dangerous too.’ For instance, it has been suggested 196 Optimism that elementary-particle accelerators that briefly create conditions that are in some respects more extreme than any since the Big Bang might destabilize the very vacuum of space and destroy our entire universe. Rees pointed out that, for his conclusion to hold, it is not necessary for any one of those catastrophes to be at all probable, because we need be unlucky only once, and we incur the risk afresh every time progress is made in a variety of fields. He compared this with playing Russian roulette. But there is a crucial difference between the human condition and Russian roulette: the probability of winning at Russian roulette is unaffected by anything that the player may think or
================================================================================will stand for longer than the pyramids have so far. Surprising scientific discoveries will be made, some of which will change the standard textbooks for ever. All these consequences of creativity make for an ever-changing way of life, 398 The Evolution of Creativity which is possible only in a long-lived dynamic society – itself a phenomenon that nothing other than creative thought could possibly bring about. However, as I pointed out in the previous chapter and Chapter 1, it was only recently in the history of our species that creativity has had any of those effects. In prehistoric times it would not have been obvious to a casual observer (say, an explorer from an extraterrestrial civil- ization) that humans were capable of creative thought at all. It would have seemed that we were doing no more than endlessly repeating the lifestyle to which we were genetically adapted, just like all the other billions of species in the biosphere. Clearly, we were tool-users – but so were many other species. We were communicating using symbolic language – but, again, that was not unusual: even bees do that. We were domesticating other species – but so do ants. Closer observation would have revealed that human languages and the knowledge for human tool use were being transmitted through memes and not genes. That made us fairly unusual, but still not obviously creative: several other species have memes. But what they do not have is the means of improving them other than through random trial and error. Nor are they capable of sustained improvement over many generations. Today, the creativity that humans use to improve ideas is what pre-eminently sets us apart from other species. Yet for most of the time that humans have existed it was not noticeably in use. Creativity would have been even less noticeable in the predecessor of our species. Yet it must already have been evolving in that species, or ours would never have been the result. In fact the advantage con - ferred by successive mutations that gave our predecessors’ brains slightly more creativity (or, more precisely, more of the ability that we now think of as creativity) must have been quite large, for by all accounts modern humans evolved from ape-like ancestors very rapidly by gene-evolution standards. Our ancestors must have been continually out-breeding their cousins who had slightly less ability to create new knowledge. Why? What were they using this knowledge for? If we did not know better, the natural answer would be that they were using it as we do today, for innovation and for understanding the world, in order to improve their lives. For instance, individuals who could improve stone tools would have ended up with better tools, 399 the beginning of infinity and hence with better food and more surviving offspring. They would also have been able to make better weapons, thus denying the holders of rival genes access to food and mates – and so on. Yet if that had happened, the palaeontological record would show those improvements happening on a timescale of generations. But it does not. Moreover, during the period when creativity was evolving, the ability to replicate memes was evolving too. It is believed that some members of the species Homo erectus living 500,000 years ago knew how to make camp fires. That knowledge was in their memes, not in their genes. And, once creativity and meme transmission are both present, they greatly enhance each other’s evolutionary value, for then anyone who improves something also has the means to bequeath the innovation to all future generations, thus multiplying the benefit to the relevant genes. And memes can be improved much faster by creativity than by random trial and error. Since there is no upper limit to the value of ideas, the conditions would have been there for a runaway co-evolution between the two adaptations: creativity and the ability to use memes. Yet, again, there is something wrong with that scenario. The two adaptations presumably did co-evolve, but the driving force behind that evolution cannot have been that people were improving on ideas and passing the improvements on to their children, because, again, if they had been, they would have been making cumulative improvements on a timescale of generations. Before the beginning of agriculture, about 12,000 years ago, many thousands of years passed between noticeable changes. It is as though each small genetic improvement in creativity produced just one noticeable innovation and then nothing more – rather like today’s experiments in ‘artificial evolution’. But how can that be? Unlike present-day artificial-evolution and AI research, our ancestors were evolving real creativity, which is the capacity to create an endless stream of innovations. Their ability to innovate was increasing rapidly, but they were barely innovating. This is a puzzle not because it is odd behaviour, but because, if innovation was that rare, how could there have been a differential effect on the reproduction of individuals with more or less ability to innovate? That there were thousands of years between noticeable changes presumably means that in most generations even the most creative individuals in the population would not have been making 400 The Evolution of Creativity any innovations. Hence their greater ability to innovate would have caused no selection pressure in their favour. Why did tiny improvements in that ability keep spreading rapidly through the population? Our ancestors must have been using their creativity – and using it to its limits, and frequently – for something. But evidently not for innovation. What else could it have been used for? One theory is that it did not evolve to provide any functional advantage, but merely through sexual selection: people used it to create displays to attract mates – colourful clothing, decorations, story-telling, wit and the like. A preference to mate with the individuals with the most creative displays co-evolved with the creativity to meet that preference in an evolutionary spiral – so the theory goes – just like peahens’ preferences and peacocks’ tails. But
================================================================================that somehow they had been able to foresee that. Then they might have modified their carbon-dioxide forecast, and concluded that emissions could easily be restored to below the 1902 level by the end of the century. But, again, that would only be because they could not possibly foresee the campaign against nuclear power, which would put a stop to its expansion (iron ically, on environmental grounds) before it ever became a significant factor in reducing emissions. And so on. Time and again, the un predictable factor of new human ideas, both good and bad, would make the scientific prediction useless. The same is bound to be true – even more so – of forecasts today for the coming century. Which brings me to my third observation about the current controversy. It is not yet accurately known how sensitive the atmosphere’s tem pera ture is to the concentration of carbon dioxide – that is, how much a given increase in concentration increases the temperature. This number is important politically, because it affects how urgent the problem is: high sensitivity means high urgency; low sensitivity means the opposite. Unfortunately, this has led to the political debate being dominated by the side issue of how ‘anthropogenic’ (human- caused) the increase in temperature to date has been. It is as if people were arguing about how best to prepare for the next hurricane while all agreeing that the only hurricanes one should prepare for are human-induced ones. All sides seem to assume that if it turns out that a random fluctuation in the temperature is about to raise sea 439 the beginning of infinity levels, disrupt agriculture, wipe out species and so on, our best plan would be simply to grin and bear it. Or if two-thirds of the increase is anthropogenic, we should not mitigate the effects of the other third. Trying to predict what our net effect on the environment will be for the next century and then subordinating all policy decisions to optim- izing that prediction cannot work. We cannot know how much to reduce emissions by, nor how much effect that will have, because we cannot know the future discoveries that will make some of our present actions seem wise, some counter-productive and some irrelevant, nor how much our efforts are going to be assisted or impeded by sheer luck. Tactics to delay the onset of foreseeable problems may help. But they cannot replace, and must be subordinate to, increasing our ability to intervene after events turn out as we did not foresee. If that does not happen in regard to carbon-dioxide-induced warming, it will happen with something else. Indeed, we did not foresee the global-warming disaster. I call it a disaster because the prevailing theory is that our best option is to prevent carbon-dioxide emissions by spending vast sums and enforcing severe worldwide restrictions on behaviour, and that is already a disaster by any reasonable measure. I call it unforeseen because we now realize that it was already under way even in 1971, when I attended that lecture. Ehrlich did tell us that agriculture was soon going to be devastated by rapid climate change. But the change in question was going to be global cooling, caused by smog and the condensation trails of supersonic aircraft. The possibility of warming caused by gas emis- sions had already been mooted by some scientists, but Ehrlich did not consider it worth mentioning. He told us that the evidence was that a general cooling trend had already begun, and that it would continue with catastrophic effects, though it would be reversed in the very long term because of ‘heat pollution’ from industry (an effect that is currently at least a hundred times smaller than the global warming that pre - occupies us). There is a saying that an ounce of prevention equals a pound of cure. But that is only when one knows what to prevent. No precautions can avoid problems that we do not yet foresee. To prepare for those, there is nothing we can do but increase our ability to put things right if they 440 Unsustainable go wrong. Trying to rely on the sheer good luck of avoiding bad outcomes indefinitely would simply guarantee that we would eventually fail without the means of recovering. The world is currently buzzing with plans to force reductions in gas emissions at almost any cost. But it ought to be buzzing much more with plans to reduce the temperature, or for how to thrive at a higher temperature. And not at all costs, but efficiently and cheaply. Some such plans exist – for instance to remove carbon dioxide from the atmosphere by a variety of methods; and to generate clouds over the oceans to reflect sunlight; and to encourage aquatic organisms to absorb more carbon dioxide. But at the moment these are very minor research efforts. Neither supercomputers nor international treaties nor vast sums are devoted to them. They are not central to the human effort to face this problem, or problems like it. This is dangerous. There is as yet no serious sign of retreat into a sustainable lifestyle (which would really mean achieving only the semblance of sustainability), but even the aspiration is dangerous. For what would we be aspiring to? To forcing the future world into our image, endlessly reproducing our lifestyle, our misconceptions and our mistakes. But if we choose instead to embark on an open- ended journey of creation and exploration whose every step is un - sustainable until it is redeemed by the next – if this becomes the prevailing ethic and aspiration of our society – then the ascent of man, the beginning of infinity, will have become, if not secure, then at least sustainable. terminology The ascent of man The beginning of infinity. Moreover, Jacob Bronowski’s The Ascent of Man was one of the inspirations for this book. Sustain The term has two almost opposite, but often confused, meanings: to provide someone with what they need,
================================================================================(among other things). And a history is a sequence of events happening to objects and possibly their identical counterparts. So, in my story so far, the world is a multiverse that consists of two universes but has only a single history. So our two universes must not stay identical. Something like a transporter malfunction will have to make them different. Yet, as I said, that may seem to have been ruled out by those restrictions on information flow. The laws of physics in the fictional multiverse are deterministic and symmetrical. So what can the transporter possibly do that would make the two universes differ? It may seem that whatever one instance of it does to one universe, its doppelgänger must be doing to the other, so the universes can only remain the same. Surprisingly, that is not so. It is consistent for two identical entities to become different under deterministic and symmetrical laws. But, for that to happen, they must initially be more than just exact images of each other: they must be fungible (the g is pronounced as in ‘plunger’), by which I mean identical in literally every way except that there are two of them. The concept of fungibility is going to appear repeatedly in my story. The term is borrowed from legal terminology, where it refers to the legal fiction that deems certain entities to be identical for purposes such as paying debts. For example, dollar bills are fungible in law, which means that, unless otherwise agreed, borrowing a dollar does not require one to return the specific banknote that one borrowed. Barrels of oil (of a given grade) are fungible too. Horses are not: borrowing someone’s horse means that one has to return that specific horse; even its identical twin will not do. But the physical fungibility I am referring to here is not about deeming. It means being identical, and that is a very different and counter-intuitive property. Leibniz, in 265 the beginning of infinity his doctrine of ‘the identity of indiscernibles’, went so far as to rule out its existence on principle. But he was mistaken. Even aside from the physics of the multiverse, we now know that photons, and under some conditions even atoms, can be fungible. This is achieved in lasers and in devices called ‘atomic lasers’ respectively. The latter emit bursts of extremely cold, fungible atoms. For how this is possible without causing transmutation, explosions and so on, see below. You will not find the concept of fungibility discussed or even mentioned in many textbooks or research papers on quantum theory, even the small minority that endorse the many-universes interpretation. Nevertheless, it is everywhere just beneath the conceptual surface, and I believe that making it explicit helps to explain quantum phenomena without fudging. As will become clear, it is an even weirder attribute than Leibniz guessed – much weirder than multiple universes for instance, which are, after all, just common sense, repeated. It allows radically new types of motion and information flow, different from anything that was imagined before quantum physics, and hence a radically different structure of the physical world. It so happens that, in some situations, money is not only legally fungible but physically too; and, being so familiar, it provides a good model for thinking about fungibility. For example, if the balance in your (electronic) bank account is one dollar, and the bank adds a second dollar as a loyalty bonus and later withdraws a dollar in charges, there is no meaning to whether the dollar they withdrew is the one that was there originally or the one that they had added – or is composed of a little of each. It is not merely that we cannot know whether it was the same dollar, or have decided not to care: because of the physics of the situation there really is no such thing as taking the original dollar, nor such a thing as taking the one added subsequently. Dollars in bank accounts are what may be called ‘configurational’ entities: they are states or configurations of objects, not what we usually think of as physical objects in their own right. Your bank balance resides in the state of a certain information-storage device. In a sense you own that state (it is illegal for anyone to alter it without your consent), but you do not own the device itself or any part of it. So in that sense a dollar is an abstraction. Indeed, it is a piece of abstract knowledge. As I discussed in Chapter 4, knowledge, once embodied 266 The Multiverse in physical form in a suitable environment, causes itself to remain so. And thus, when a physical dollar wears out and is destroyed by the mint, the abstract dollar causes the mint to transfer it into electronic form, or into a new instance in paper form. It is an abstract replicator – though, unusually for a replicator, it causes itself not to proliferate, but rather to be copied into ledgers and into backups of computer memories. Another example of fungible configurational entities in classical physics is amounts of energy: if you pedal your bicycle until you have built up a kinetic energy of ten kilojoules, and then brake until half that energy has been dissipated as heat, there is no meaning to whether the energy dissipated was the first five kilojoules that you had added or the second, or any combination. But it is meaningful that half the energy that was there has been dissipated. It turns out that, in quantum physics, elementary particles are configurational entities too. The vacuum, which we perceive as empty at everyday scales and even at atomic scales, is not really emptiness, but a richly structured entity known as a ‘quantum field’. Elementary particles are higher-energy configurations of this entity: ‘excitations of the vacuum’. So, for in - stance, the photons in a laser are configurations of the vacuum inside its ‘cavity’. When two or more such excitations with identical attributes
================================================================================made Peter Shaffer think that Mozart’s music is hard to vary? The prevailing view among both artists and non-artists is, I think, that there is nothing objective about artistic standards. Beauty, says the adage, is in the 353 the beginning of infinity eye of the beholder. The very phrase ‘It’s a matter of taste’ is used interchangeably with ‘There is no objective truth of the matter.’ Artistic standards are, in this view, nothing more than artefacts of fashion and other cultural accidents, or of individual whim, or of biological predisposition. Many are willing to concede that in science and math- e matics one idea can be objectively truer than another (though, as we have seen, some deny even that), but most insist that there is no such thing as one object being objectively more beautiful than another. Mathematics has its proofs (so the argument goes), and science has its experimental tests; but if you choose to believe that Mozart was an inept and cacophonous composer then neither logic nor experiment nor anything else objective will ever contradict you. However, it would be a mistake to dismiss the possibility of objective beauty for that sort of reason, for it is none other than the relic of empiricism that I discussed in Chapter 9 – the assertion that philo- sophical knowledge in general cannot exist. It is true that, just as one cannot deduce moral maxims from scientific theories, likewise nor can one deduce aesthetic values. But that would not prevent aesthetic truths from being linked to physical facts through explanations, as moral ones are. Wheeler was very nearly asserting such a link in that quotation. Facts can be used to criticize aesthetic theories, as they can moral theories. For instance, there is the criticism that, since most arts depend on parochial properties of human senses (such as which range of colours and sounds they can detect), they cannot be attaining anything objective. Extraterrestrial people whose senses detected radio waves but not light or sound would have art that was inaccessible to us, and vice versa. And the reply to that criticism might be, first, that perhaps our arts are merely scratching the surface of what is possible: they are indeed parochial, but they are a first approximation to something universal. Or, second, that deaf composers on Earth have composed, and appreciated, great music; why could deaf extraterrestrials (or humans who were born deaf) not learn to do the same – if by no other means than by downloading a set of deaf-composer aesthetics into their brains? Or, third, what is the difference between using radio telescopes to understand the physics of quasars and using prosthetic senses (wired into the brain to create new qualia) to appreciate extra- terrestrial art? 354 Why are Flowers Beautiful? Experience may also provide artistic problems. Our ancestors had eyes and paint, which may have led them to wonder how paint could be used in a way that would look more beautiful. Just as Bronowski pointed out that scientific discovery depends on a commitment to certain moral values, might it not also entail the appreciation of certain forms of beauty? It is a fact – often mentioned but seldom explained – that deep truth is often beautiful. Mathemat- icians and theoretical scientists call this form of beauty ‘elegance’. Elegance is the beauty in explanations. It is by no means synonymous with how good, or how true, an explanation is. The poet John Keats’ assertion (which I think was ironic) that ‘Beauty is truth, truth beauty’ is refuted by what the evolutionist Thomas Huxley called ‘the great tragedy of Science – the slaying of a beautiful hypothesis by an ugly fact – which is so constantly being enacted under the eyes of philo- sophers’. (By ‘philosophers’ he meant ‘scientists’.) I think Huxley, too was being ironic in calling this process a great tragedy, especially since he was referring to the refutation of spontaneous-generation theories. But it is true that some important mathematical proofs, and some scientific theories, are far from elegant. Yet the truth so often is elegant that elegance is, at least, a useful heuristic when searching for funda- mental truths. And when a ‘beautiful hypothesis’ is slain, it is more often than not replaced, as the spontaneous-generation theory was, by a more beautiful one. Surely this is not coincidence: it is a regularity in nature. So it must have an explanation. The processes of science and art can look rather different: a new artistic creation rarely proves an old one wrong; artists rarely look at a scene through microscopes, or understand a sculpture through equations. Yet scientific and artistic creation do sometimes look remarkably alike. Richard Feynman once remarked that the only equipment a theoretical physicist needs is a stack of paper, a pencil and a waste-paper basket, and some artists, when they are at work, closely resemble that picture. Before the invention of the typewriter, novelists used exactly the same equipment. Composers like Ludwig van Beethoven agonized through change after change, apparently seeking something that they knew was there to be created, apparently meeting a standard that could be met only after much creative effort and much failure. Scientists often do the 355 the beginning of infinity same. In both science and art there are the exceptional creators like Mozart or the mathematician Srinivasa Ramanujan, who reputedly made brilliant contributions without any such effort. But from what we know of knowledge-creation we have to conclude that in such cases the effort, and the mistakes, did happen, invisibly, inside their brains. Are these resemblances only superficial? Was Beethoven fooling himself when he thought that the sheets in his waste-paper basket contained mistakes: that they were worse than the sheets he would eventually publish? Was he merely meeting the arbitrary standards of his culture, like the twentieth-century women who carefully adjusted their hemlines each year to conform to the latest fashions? Or is there a real meaning to saying that the music of Beethoven and Mozart was
================================================================================them. A ringing doorbell and a barking dog may happen to provide conditions that meet the inborn criterion that initiates parroting behaviour, and, when they do, the parrot will always mimic exactly the same aspects of them: their sounds. So, it resolves the infinite ambiguity by making no choices. It does not occur to it to ignore the dog under those conditions, or to imitate the wagging of its tail, because it is incapable of conceiving of any other criterion for imitation than the one built into its mirror-neuron system. It is devoid of creativity and relies on its lack of creativity to replicate the sounds faithfully. This is reminiscent of humans in static societies – except for a crucial difference which I shall explain below. Now, imagine that a parrot had been present at Popper’s lectures, and learned to parrot some of Popper’s favourite sentences. It would, in a sense, have ‘imitated’ some of Popper’s ideas: in principle, an interested student could later learn the ideas by listening to the parrot. But the parrot would merely be transmitting those memes from one place to another – which is no more than the air in the lecture theatre does. The parrot could not be said to have acquired the memes, because it would be reproducing only one of the countless behaviours that they could produce. The parrot’s subsequent behaviour as a result of having learned the sounds by heart – such as its responses to questions – would not resemble Popper’s. The sound of the meme would be there, but its meaning would not. And it is the meaning – the knowledge – that is the replicator. The parrot is oblivious to the human meanings of the sounds that it parrots. Had those lectures been not about philosophy but about recipes for fried parrot, it would have been just as eager to quote from them to anyone who would listen. But it is not oblivious to the content 406 The Evolution of Creativity of the sound – it is not like a mechanical recorder. Quite the contrary: parrots neither record sounds indiscriminately nor replay them ran - domly. Their inborn criteria do implicitly attribute meaning to sounds that they hear; it is just that the meaning is always drawn from the same, narrow set of possibilities: if the evolutionary function of par - roting is, for instance, to create identifying calls, then every sound it hears is either a potential identifying call or not. Apes are capable of recognizing a much larger set of possible meanings. Some of them are so complex that aping has often been misinterpreted as evidence of human-like understanding. For example, when an ape learns a new method of cracking nuts by hitting them with rocks, it does not then play the movements back blindly in a fixed sequence like a parrot does. The movements required to crack the nut are never the same twice: the ape has to aim the rock at the nut; it may have to chase the nut and fetch it back if it rolls away; it has to keep hitting it until it cracks, rather than a fixed number of times; and so on. During some parts of the procedure the ape’s two hands must cooperate, each performing a different sub-task. Before it can even begin, it must be able to recognize a nut as being suitable for the procedure; it must look for a rock and, again, recognize a suitable one. Such activities may seem to depend on explanation – on understand- ing how and why each action within the complex behaviour has to fit in with the other actions in order to achieve the overall purpose. But recent discoveries have revealed how apes are able to imitate such behaviours without ever creating any explanatory knowledge. In a remarkable series of observational and theoretical studies, the evo - lutionary psychologist and animal-behaviour researcher Richard Byrne has shown how they achieve this by a process that he calls behaviour parsing (which is analogous to the grammatical analysis or ‘parsing’ of human speech or computer programs). Humans and computers separate continuous streams of sounds or characters into individual elements such as words, and then interpret those elements as being connected by the logic of a larger sentence or program. Similarly, in behaviour parsing (which evolved millions of years before human language parsing), an ape parses a continuous stream of behaviour that it witnesses into individual elements, each of which it already knows – genetically – how to imitate. The individual 407 the beginning of infinity elements can be inborn behaviours, such as biting; or behaviours learned by trial and error, such as grasping a nettle without being stung; or previously learned memes. As for connecting these elements together in the right way without knowing why, it turns out that, in every known case of complex behaviours in non-humans, the necessary information can be obtained merely by watching the behaviour many times and looking out for simple statistical patterns – such as which right-hand behaviour often goes with which left-hand behaviour, and which elements are often omitted. It is a very inefficient method, requiring a lot of watching of behaviours that a human could mimic almost immediately by understanding their purpose. Also, it allows only a few fixed options for connecting the behaviours together, so only relatively simple memes can be replicated. Apes can copy certain individual actions instantly – the ones of which they have pre-existing knowledge through their mirror-neuron system – but it takes them years to learn a repertoire of memes that involve combinations of actions. Yet those memes – trivially simple tricks by human standards – are enormously valuable: using them, apes have privileged access to sources of food that are closed to all other animals; and meme evolution gives them the ability to switch to other sources far faster than gene evolution would allow. So, an ape knows (inexplicitly) that another ape is ‘picking up a rock’, and
================================================================================shortly take us back out into intergalactic space. But let me first return to Earth, and consider the Spaceship Earth metaphor, in its straightforward physical version. This much is true: if, tomorrow, physical conditions on the Earth’s surface were to change even slightly by astrophysical standards, then no humans could live here unprotected, just as they could not survive on a spaceship whose life-support system had broken down. Yet I am writing this in Oxford, England, where winter nights are likewise often cold enough to kill any human unprotected by clothing and other technology. So, while intergalactic space would kill me in a matter of seconds, Oxfordshire in its primeval state might do it in a matter of hours – which can be considered ‘life support’ only in the most contrived sense. There is a life-support system in Oxfordshire today, but it was not provided by the biosphere. It has been built by humans. It consists of clothes, houses, farms, hospitals, an electrical grid, a sewage system and so on. Nearly the whole of the Earth’s biosphere in its primeval state was likewise incapable of keeping an unprotected human alive for long. It would be much more accurate to call it a death trap for humans rather than a life-support system. Even the Great Rift Valley in eastern Africa, where our species evolved, was barely more hospitable than primeval Oxfordshire. Unlike the life-support system in that imagined spaceship, the Great Rift Valley lacked a safe water supply, and medical equipment, and comfortable living quarters, and was infested with predators, parasites and disease organisms. It frequently injured, poisoned, drenched, starved and sickened its ‘passengers’, and most of them died as a result. It was similarly harsh to all the other organisms that lived there: few individuals live comfortably or die of old age in the supposedly beneficent biosphere. That is no accident: most populations, of most species, are living close to the edge of disaster and death. It has to be that way, because as soon as some small group, somewhere, begins to have a slightly easier life than that, for any reason – for instance, an increased food supply, or the extinction of a competitor or predator – then its numbers increase. As a result, its other resources are depleted by the increased usage; so an increasing proportion of the population now has to colonize more marginal habitats and make do with inferior 48 The Spark resources, and so on. This process continues until the disadvantages caused by the increased population have exactly balanced the advantage conferred by the beneficial change. That is to say, the new birth rate is again just barely keeping pace with the rampant disabling and killing of individuals by starvation, exhaustion, predation, overcrowding and all those other natural processes. That is the situation to which evolution adapts organisms. And that, therefore, is the lifestyle in which the Earth’s biosphere ‘seems adapted’ to sustaining them. The biosphere only ever achieves stability – and only temporarily at that – by continually neglecting, harming, disabling and killing individuals. Hence the metaphor of a spaceship or a life- support system, is quite perverse: when humans design a life-support system, they design it to provide the maximum possible comfort, safety and longevity for its users within the available resources; the biosphere has no such priorities. Nor is the biosphere a great preserver of species. In addition to being notoriously cruel to individuals, evolution involves continual extinctions of entire species. The average rate of extinction since the beginning of life on Earth has been about ten species per year (the number is known only very approximately), becoming much higher during the relatively brief periods that palaeontologists call ‘mass extinction events’. The rate at which species have come into existence has on balance only slightly exceeded the extinction rate, and the net effect is that the overwhelming majority of species that have ever existed on Earth (perhaps 99.9 per cent of them) are now extinct. Genetic evidence suggests that our own species narrowly escaped extinction on at least one occasion. Several species closely related to ours did become extinct. Significantly, the ‘life-support system’ itself wiped them out – by means such as natural disasters, evolutionary changes in other species, and climate change. Those cousins of ours had not invited extinction by changing their lifestyles or overloading the biosphere: on the contrary, it wiped them out because they were living the lifestyles that they had evolved to live, and in which, according to the Spaceship Earth metaphor, the biosphere had been ‘supporting’ them. Yet that still overstates the degree to which the biosphere is hospitable to humans in particular. The first people to live at the latitude of Oxford (who were actually from a species related to us, possibly the Neanderthals) 49 the beginning of infinity could do so only because they brought knowledge with them, about such things as tools, weapons, fire and clothing. That knowledge was transmitted from generation to generation not genetically but culturally. Our pre-human ancestors in the Great Rift Valley used such know- ledge too, and our own species must have come into existence already dependent on it for survival. As evidence of that, note that I would soon die if I tried to live in the Great Rift Valley in its primeval state: I do not have the requisite knowledge. Since then, there have been human populations who, for instance, knew how to survive in the Amazon jungle but not in the Arctic, and populations for whom it was the other way round. Therefore that knowledge was not part of their genetic inheritance. It was created by human thought, and preserved and transmitted in human culture. Today, almost the entire capacity of the Earth’s ‘life-support system for humans’ has been provided not for us but by us, using our ability to create new knowledge. There are people in the Great Rift Valley today who live far more comfortably than early humans did, and in far greater numbers,
================================================================================effects typically continue indefinitely, as I have described, with a wave of differentiation entangling more and more objects. If the differential effects can all be undone, then interference between those original values becomes possible again; but the laws of quantum mechanics dictate that undoing them requires fine control of all the affected objects, and that rapidly becomes infeasible. The process of its becoming infeasible is known as decoherence. In most situations, decoherence is very rapid, which is why splitting typically predominates over interference, and why interference – though ubiquitous on microscopic scales – is quite hard to demonstrate unambiguously in the laboratory. Nevertheless, it can be done, and quantum interference phenomena constitute our main evidence of the existence of the multiverse, and of what its laws are. A real-life analogue of the above experiment is standard in quantum optics laboratories. Instead of experimenting on voltmeters (whose many interactions with their environment quickly cause decoherence), one uses individual photons, and the variable being acted upon is not voltage but which of two possible paths the photon is on. Instead of the transporter, one uses a simple device called a semi- silvered mirror (represented by the grey sloping bars in the diagrams below). When a photon strikes such a mirror, it bounces off in half the universes, and passes straight through in the other half, as shown on next page: 285 the beginning of infinity Semi-silvered mirror The attributes of travelling in the X or Y directions behave analogously to the two voltages X and Y in our fictitious multiverse. So passing through the semi-silvered mirror is the analogue of the transformation above. And when the two instances of a single photon, travelling in directions X and Y, strike the second semi-silvered mirror at the same time, they undergo the transformation , which means that both instances emerge in the direction X: the two histories rejoin. To demonstrate this, one can use a set-up known as a ‘Mach– Zehnder interferometer’, which performs those two transfor mations (splitting and interference) in quick succession: Mach–Zehnder interferometer 286 The Multiverse The two ordinary mirrors (the black sloping bars) are merely there to steer the photon from the first to the second semi-silvered mirror. If a photon is introduced travelling rightwards (X) after the first mirror instead of before as shown, then it appears to emerge randomly, rightwards or downwards, from the last mirror (because then, happens there). The same is true of a photon introduced travelling downwards (Y) after the first mirror. But a photon introduced as shown in the diagram invariably emerges rightwards, never downwards. By doing the experiment repeatedly with and without detectors on the paths, one can verify that only one photon is ever present per history, because only one of those detectors is ever observed to fire during such an experiment. Then, the fact that the intermediate histories X and Y both contribute to the deterministic final outcome X makes it inescapable that both are happening at the intermediate time. In the real multiverse, there is no need for the transporter or any other special apparatus to cause histories to differentiate and to rejoin. Under the laws of quantum physics, elementary particles are undergoing such processes of their own accord, all the time. Moreover, histories may split into more than two – often into many trillions – each character ized by a slightly different direction of motion or difference in other physical variables of the elementary particle concerned. Also, in general the resulting histories have unequal measures. So let us now dispense with the transporter in the fictional multiverse too. The rate of growth in the number of distinct histories is quite mind- boggling – even though, thanks to interference, there is now a certain amount of spontaneous rejoining as well. Because of this rejoining, the flow of information in the real multiverse is not divided into strictly autonomous subflows – branching, autonomous histories. Although there is still no communication between histories (in the sense of message-sending), they are intimately affecting each other, because the effect of interference on a history depends on what other histories are present. Not only is the multiverse no longer perfectly partitioned into histories, individual particles are not perfectly partitioned into in- stances. For example, consider the following interference phenom enon, 287 the beginning of infinity where X and Y now represent different values of the position of a single particle: X X (cid:3514) X (cid:3514) Y Y How instances of a particle lose their identity during interference. Has the instance of the particle at X stayed at X or moved to Y? Has the instance of the particle at Y returned to Y or moved to X? Because these two groups of instances of the particle, initially at different positions, have gone through a moment of being fungible, there is no such thing as which of them has ended up at which final position. This sort of interference is going on all the time, even for a single particle in a region of otherwise empty space. So there is in general no such thing as the ‘same’ instance of a particle at different times. Even within the same history, particles in general do not retain their identities over time. For example, during a collision between two atoms, the histories of the event split into something like this and something like this 288 The Multiverse So, for each particle individually, the event is rather like a collision with a semi-silvered mirror. Each atom plays the role of the mirror for the other atom. But the multiversal view of both particles looks like this where at the end of the collision some of the instances of each atom have become fungible with what was originally a different atom. For the same reason, there is no such thing as the speed of one instance of the particle at a given location. Speed is defined as distance travelled divided by time taken, but that is not meaningful in situations
================================================================================moderately significant in the cosmic scheme of things. But it seems that one can explain everything about supernovae, and almost everything else, without ever mentioning people or knowledge at all. However, that is merely another parochial error, due to our current, untypical, vantage point in an Enlightenment that is mere centuries old. In the longer run, humans may colonize other solar systems and, by increasing their knowledge, control ever more powerful physical processes. If people ever choose to live near a star that is capable of exploding, they may well wish to prevent such an explosion – probably by removing some of the material from the star. Such a project would use many orders of magnitude more energy than humans currently control, and more advanced technology as well. But it is a fundament- ally simple task, not requiring any steps that are even close to limits imposed by the laws of physics. So, with the right knowledge, it could be achieved. Indeed, for all we know, engineers elsewhere in the universe are already achieving it routinely. And consequently it is not true that the attributes of supernovae in general are independent of the presence or absence of people, or of what those people know and intend. More generally, if we want to predict what a star will do, we first have to guess whether there are any people near it, and, if so, what knowledge they may have and what they may want to achieve. Outside our parochial perspective, astrophysics is incomplete without a theory of people, just as it is incomplete without a theory of gravity or nuclear reactions. Note that this conclusion does not depend on the assumption that humans, or anyone, will colonize the galaxy and take control of 70 The Spark any supernovae: the assumption that they will not is equally a theory about the future behaviour of knowledge. Knowledge is a significant phenomenon in the universe, because to make almost any prediction about astrophysics one must take a position about what types of knowledge will or will not be present near the phenomena in question. So all explanations of what is out there in the physical world mention knowledge and people, if only implicitly. But knowledge is more significant even than that. Consider any physical object – for instance, a solar system, or a microscopic chip of silicon – and then consider all the transformations that it is physically possible for it to undergo. For instance, the silicon chip might be melted and solidify in a different shape, or be transformed into a chip with different functionality. The solar system might be devastated when its star becomes a supernova, or life might evolve on one of its planets, or it might be transformed, using transmutation and other futuristic technologies, into microprocessors. In all cases, the class of transform- ations that could happen spontaneously – in the absence of knowledge – is negligibly small compared with the class that could be effected artificially by intelligent beings who wanted those transformations to happen. So the explanations of almost all physically possible phenomena are about how knowledge would be applied to bring these phenomena about. If you want to explain how an object might possibly reach a temperature of ten degrees or a million, you can refer to spontaneous processes and can avoid mentioning people explicitly (even though most processes at those temperatures can be brought about only by people). But if you want to explain how an object might possibly cool down to a millionth of a degree above absolute zero, you cannot avoid explaining in detail what people would do. And that is still only the least of it. In your mind’s eye, continue your journey from that point in intergalactic space to another, at least ten times as far away. Our destination this time is inside one of the jets of a quasar. What would it be like in one of those jets? Language is barely capable of expressing it: it would be rather like facing a supernova explosion at point-blank range, but for millions of years at a time. The survival time for a human body would be measured in picoseconds. As I said, it is unclear whether the laws of physics permit any knowledge to grow there, let alone a life-support system for humans. It is about 71 the beginning of infinity as different from our ancestral environment as it could possibly be. The laws of physics that explain it bear no resemblance to any rules of thumb that were ever in our ancestors’ genes or in their culture. Yet human brains today know in considerable detail what is happening there. Somehow that jet happens in such a way that billions of years later, on the other side of the universe, a chemical scum can know and predict what the jet will do, and can understand why. That means that one physical system – say, an astrophysicist’s brain – contains an accurate working model of the other, the jet. Not just a superficial image (though it contains that as well), but an explanatory theory that embodies the same mathematical relationships and causal structure. That is scientific knowledge. Furthermore, the faithfulness with which the one structure resembles the other is steadily increasing. That constitutes the creation of knowledge. Here we have physical objects very unlike each other, and whose behaviour is dominated by different laws of physics, embodying the same mathematical and causal structures – and doing so ever more accurately over time. Of all the physical processes that can occur in nature, only the creation of knowledge exhibits that underlying unity. In Arecibo, Puerto Rico, there is a giant radio telescope, one of whose many uses is in the Search For Extraterrestrial Intelligence (SETI). In an office in a building near the telescope there is a small domestic refrigerator. Inside that refrigerator is a bottle of champagne, sealed by a cork. Consider that cork. It is going to be removed from the bottle
================================================================================was self-evidently true of nature. Hence he believed that it was impossible rationally to doubt that the angles of a real triangle add up to 180 degrees. And in this way he elevated that formerly harmless misconception into a central flaw in his philosophy, namely the doctrine that certain truths about the physical world could be ‘known a priori’ – that is to say, without doing science. And of course, to make matters worse, by ‘known’ he unfortunately meant ‘justified’. Yet, even before Kant had declared it impossible to doubt that the geometry of real space is Euclidean, mathematicians had already doubted it. Soon afterwards the mathematician and physicist Carl Friedrich Gauss went so far as to measure the angles of a large triangle – but found no deviation from Euclid’s predictions. Eventually Einstein’s theory of curved space and time, which contradicted Euclid’s, was vindicated by experiments that were more accurate than Gauss’s. In the space near the Earth, the angles of a large triangle can add up to as much as 180.0000002 degrees, a variation from Euclid’s geometry 183 the beginning of infinity which, for instance, satellite navigation systems nowadays have to take into account. In other situations – such as near black holes – the differences between Euclidean and Einsteinian geometry are so pro - found that they can no longer be described in terms of ‘deviations’ of one from the other. Another example of the same mistake was in computer science. Turing initially set up the theory of computation not for the purpose of building computers, but to investigate the nature of mathematical proof. Hilbert in 1900 had challenged mathematicians to formulate a rigorous theory of what constitutes a proof, and one of his conditions was that proofs must be finite: they must use only a fixed and finite set of rules of inference; they must start with a finite number of finitely expressed axioms, and they must contain only a finite number of elementary steps – where the steps are themselves finite. Computations, as understood in Turing’s theory, are essentially the same thing as proofs: every valid proof can be converted to a computation that computes the conclusion from the premises, and every correctly exe - cuted computation is a proof that the output is the outcome of the given operations on the input. Now, a computation can also be thought of as computing a function that takes an arbitrary natural number as its input and delivers an output that depends in a particular way on that input. So, for instance, doubling a number is a function. Infinity Hotel typically tells guests to change rooms by specifying a function and telling them all to compute it with different inputs (their room numbers). One of Turing’s conclusions was that almost all mathematical functions that exist logically cannot be computed by any program. They are ‘non-computable’ for the same reason that most logically possible reallocations of rooms in Infinity Hotel cannot be effected by any instruction by the management: the set of all functions is uncountably infinite, while the set of all programs is merely countably infinite. (That is why it is meaningful to say that ‘almost all’ members of the infinite set of all functions have a particular property.) Hence also – as the mathematician Kurt Gödel had discovered using a different approach to Hilbert’s challenge – almost all mathematical truths have no proofs. They are unprovable truths. It also follows that almost all mathematical statements are undecid- 184 A Window on Infinity able: there is no proof that they are true, and no proof that they are false. Each of them is either true or false, but there is no way of using physical objects such as brains or computers to discover which is which. The laws of physics provide us with only a narrow window through which we can look out on the world of abstractions. All undecidable statements are, directly or indirectly, about infinite sets. To the opponents of infinity in mathematics, this is due to the meaninglessness of such statements. But to me it is a powerful argument – like Hofstadter’s 641 argument – that abstractions exist objectively. For it means that the truth value of an undecidable statement is certainly not just a convenient way of describing the behaviour of some physical object like a computer or a collection of dominoes. Interestingly, very few questions are known to be undecidable, even though most are – and I shall return to that point. But there are many unsolved mathematical conjectures, and some of those may well be undecidable. Take, for instance, the ‘prime-pairs conjecture’. A prime pair is a pair of prime numbers that differ by 2 – such as 5 and 7. The conjecture is that there is no largest prime pair: there are infinitely many of them. Suppose for the sake of argument that that is undecidable – using our physics. Under many other laws of physics it is decidable. The laws of Infinity Hotel are an example. Again, the details of how the management would settle the prime-pairs issue are not essential to my argument, but I present them here for the benefit of mathematically minded readers. The management would announce: First: Please check within the next minute whether your room number and the number two above it are both primes. Next: If they are, then send a message back through lower-numbered rooms saying that you have found a prime pair. Use the usual method for sending rapid messages (allow one minute for the first step and thereafter each step must be completed in half the time of the previous one). Store a record of this message in the lowest-numbered room that is not already storing a record of a previous such message. Next: Check with the room numbered one more than yours. If that guest is not storing such a record and you are, then send a message to room 1 saying that there is a largest prime pair.
================================================================================history. This was first understood by the physicists Don Page and William Wooters, in 1983. In this full version of the quantum multiverse, how is our science- fiction story to continue? Almost all the attention that the quantum theory has attracted, from physicists, philosophers and science-fiction authors alike, has focused on its parallel-universes aspect. That is ironic, because it is in the parallel-universe approximation that the world most resembles that of classical physics, yet that is the very aspect of quantum theory that many people seem to find viscerally unacceptable. Fiction can explore the possibilities opened up by parallel universes. For instance, since our story is a romance, the characters may well wonder about their counterparts in other histories. The story could compare their speculations with what we ‘know’ happened in the other histories. The character whose spouse’s unfaithfulness was revealed by a ‘random’ event might wonder whether that event provided a lucky escape from what was a doomed marriage anyway. Are they still married in the history in which the unfaithfulness was not subsequently revealed? Are they still happy? Can it be true happiness if it is ‘based on a lie’? As we see them speculating on these matters, we see the ‘still married’ history and know the (fictional) fact of the matter. They might also speculate about less parochial issues. The story could say that their sun is part of a cluster of dozens of stars, all within a sphere of a few light-weeks’ radius. This has puzzled their scientists for decades, since the composition of the stars shows that they originated from far and wide and became gravitationally bound through a series of very unlikely coincidences. In most universes, these scientists calcu- late, life cannot evolve in such dense star clusters, because there are too many collisions. So in most universes that contain humans there are no fleets of starships visiting inhabited star systems one after another. They have been trying to discover a mechanism by which the proximity of nearby stars might somehow precipitate the formation of intelligent life, but they have failed. Should they consider it just an astronomically 299 the beginning of infinity unlikely coincidence? But they do not like leaving things unexplained. Something must have selected them, they conclude. It did. Those people are not just a story. They are real, living, thinking human beings, wondering at this very moment where they came from. But they will never find out. In that one respect, they are unlucky: they were indeed selected by coincidence. Another way of putting that is that they were selected by the very story that I am now telling about them. All fiction that does not violate the laws of physics is fact. Some fiction in which the laws of physics appear to be violated is also fact, somewhere in the multiverse. This involves a subtle issue about how the multiverse is structured – how histories emerge. A history is approximately autonomous. If I boil some water in a kettle and make tea, I am in a history in which I switched on the kettle and the water became gradually hotter because of the energy being poured into it by the kettle, causing bubbles to form and so on, and eventually hot tea forms. That is a history because one can give explanations and make predictions about it without ever mentioning either that there are other histories in the multiverse where I chose to make coffee instead or that the microscopic motion of the water molecules is slightly affected by parts of the multiverse that are outside that history. It is irrelevant to that explanation that a small measure of that history differentiates itself during that process and does other things. In some tiny sliver of it, the kettle transforms itself into a top hat, and the water into a rabbit which then hops away, and I get neither tea nor coffee but am very surprised. That is a history too, after that transformation. But there is no way of correctly explaining what was happening during it, or predicting the probabilities, without referring to other parts of the multiverse – enormously larger parts (i.e. with larger measures) – in which there was no rabbit. So that history began at the transformation, and its causal connection with what happened before that cannot be expressed in history terms but only in multiverse terms. In simple cases like that, there is a ready-made approximative language in which we can minimize mention of the rest of the multiverse: the language of random events. This allows us to acknowledge that most of the high-level objects concerned still behaved autonomously except for being affected by something outside themselves – as when I am affected by the rabbit. This constitutes some continuity between a history 300 The Multiverse and a previous history from which it split, and we can refer to the former as a ‘history that has been affected by random events’. However, this is never literally what has happened: the part of that ‘history’ prior to the ‘random event’ is fungible with the rest of the broader history and therefore has no separate identity from it: it is not separately explicable. But the broader of those two histories still is. That is to say, the rabbit history is fundamentally different from the tea history, in that the latter remains very accurately autonomous throughout the period. In the rabbit history I end up with memories that are identical to what they would be in a history in which water became a rabbit. But those are misleading memories. There was no such history; the history containing those memories began only after the rabbit had formed. For that matter, there are also places in the multiverse – of far larger measure than that one – in which only my brain was affected, producing exactly those memories. In effect, I had a hallucination, caused by random motion of the atoms in my brain. Some philosophers make a big issue
================================================================================185 the beginning of infinity At the end of five minutes, the management would know the truth of the prime-pairs conjecture. So, there is nothing mathematically special about the undecidable questions, the non-computable functions, the unprovable propositions. They are distinguished by physics only. Different physical laws would make different things infinite, different things computable, different truths – both mathematical and scientific – knowable. It is only the laws of physics that determine which abstract entities and relationships are modelled by physical objects such as mathematicians’ brains, computers and sheets of paper. Some mathematicians wondered, at the time of Hilbert’s challenge, whether finiteness was really an essential feature of a proof. (They meant mathematically essential.) After all, infinity makes sense math- ematically, so why not infinite proofs? Hilbert, though he was a great defender of Cantor’s theory, ridiculed the idea. Both he and his critics were thereby making the same mistake as Zeno: they were all assuming that some class of abstract entities can prove things, and that math- ematical reasoning could determine what that class is. But if the laws of physics were in fact different from what we currently think they are, then so might be the set of mathematical truths that we would then be able to prove, and so might the operations that would be available to prove them with. The laws of physics as we know them happen to afford a privileged status to such operations as not, and and or, acting on individual bits of information (binary digits, or logical true/false values). That is why those operations seem natural, elementary and finite to us – and why bits do. If the laws of physics were like, say, those of Infinity Hotel, then there would be additional privileged operations, acting on infinite sets of bits. With some other laws of physics, the operations not, and and or would be non-computable, while some of our non-computable functions would seem natural, elementary and finite. That brings me to another distinction that depends on the laws of physics: simple versus complex. Brains are physical objects. Thoughts are computations, of the types permitted under the laws of physics. Some explanations can be grasped easily and quickly – like ‘If Socrates was a man and Plato was a man then they were both men.’ This is easy because it can be stated in a short sentence and relies on the properties 186 A Window on Infinity of an elementary operation (namely and). Other explanations are inherently hard to grasp, because their shortest form is still long and depends on many such operations. But whether the form of an ex planation is long or short, and whether it requires few or many elementary operations, depends entirely on the laws of physics under which it is being stated and understood. Quantum computation, which is currently believed to be the fully universal form of computation, happens to have exactly the same set of computable functions as Turing’s classical computation. But quantum computation drives a coach and horses through the classical notion of a ‘simple’ or ‘elementary’ operation. It makes some intuitively very complex things simple. Moreover, the elementary information- storing entity in quantum computation, the ‘qubit’ (quantum bit) is quite hard to explain in non-quantum terminology. Meanwhile the bit is a fairly complicated object from the perspective of quantum physics. Some people object that quantum computation therefore isn’t ‘real’ computation: it is just physics, just engineering. To them, those logical possibilities about exotic laws of physics enabling exotic forms of computation do not address the issue of what a proof ‘really’ is. Their objection would go something like this: admittedly, under suitable laws of physics we would be able to compute non-Turing-computable functions, but that would not be computation. We would be able to establish the truth or falsity of Turing-undecidable propositions, but that ‘establishing’ would not be proving, because then our knowledge of whether the proposition was true or false would for ever depend on our knowledge of what the laws of physics are. If we discovered one day that the real laws of physics were different, we might have to change our minds about the proof too, and its conclusion. And so it would not be a real proof: real proof is independent of physics. Here is that same misconception again (as well as some authority- seeking justificationism). Our knowledge of whether a proposition is true or false always depends on knowledge about how physical objects behave. If we changed our minds about what a computer, or a brain, has been doing – for instance, if we decided that our own memory was faulty about which steps we had checked in a proof – then we would be forced to change our opinion about whether we had proved 187 the beginning of infinity some thing or not. It would be no different if we changed our minds about what the laws of physics made the computer do. Whether a mathematical proposition is true or not is indeed inde- pend ent of physics. But the proof of such a proposition is a matter of physics only. There is no such thing as abstractly proving some- thing, just as there is no such thing as abstractly knowing something. Mathematical truth is absolutely necessary and transcendent, but all knowledge is generated by physical processes, and its scope and limitations are conditioned by the laws of nature. One can define a class of abstract entities and call them ‘proofs’ (or computations), just as one can define abstract entities and call them triangles and have them obey Euclidean geometry. But you cannot infer anything from that theory of ‘triangles’ about what angle you will turn through if you walk around a closed path consisting of three straight lines. Nor can those ‘proofs’ do the job of verifying mathematical statements. A mathematical ‘theory of proofs’ has no bearing on which truths can or cannot be proved in reality, or be known in reality; and similarly a theory of
================================================================================fluctuations, and random outside influences makes analogue computers wander off the intended compu- tational path. This may sound like a minor or parochial consideration. But it is quite the opposite. Without error-correction all information processing, and hence all knowledge-creation, is necessarily bounded. Error-correction is the beginning of infinity. For example, tallying is universal only if it is digital. Imagine that some ancient goatherds had tried to tally the total length of their flock instead of the number. As each goat left the enclosure, they could reel out some string of the same length as the goat. Later, when the goats returned, they could reel that length back in. When the whole length had been reeled back in, that would mean that all the goats had returned. But in practice the outcome would always be at least a little long or short, because of the accumulation of measurement errors. For any given accuracy of measurement, there would be a maximum number of goats that could be reliably tallied by this ‘analogue tallying’ 140 The Jump to Universality system. The same would be true of all arithmetic performed with those ‘tallies’. Whenever the strings representing several flocks were added together, or a string was cut in two to record the splitting of a flock, and whenever a string was ‘copied’ by making another of the same length, there would be errors. One could mitigate their effect by performing each operation many times, and then keeping only the outcome of median length. But the operations of comparing or duplicat- ing lengths can themselves be performed only with finite accuracy, and so could not reduce the rate of error accumulation per step below that level of accuracy. That would impose a maximum number of consecutive operations that could be performed before the result became useless for a given purpose – which is why analogue computation can never be universal. What is needed is a system that takes for granted that errors will occur, but corrects them once they do – a case of ‘problems are inev- itable, but they are soluble’ at the lowest level of information-processing emergence. But, in analogue computation, error correction runs into the basic logical problem that there is no way of distinguishing an erroneous value from a correct one at sight, because it is in the very nature of analogue computation that every value could be correct. Any length of string might be the right length. And that is not so in a computation that confines itself to whole numbers. Using the same string, we might represent whole numbers as lengths of string in whole numbers of inches. After each step, we trim or lengthen the resulting strings to the nearest inch. Then errors would no longer accumulate. For example, suppose that the measurements could all be done to a tolerance of a tenth of an inch. Then all errors would be detected and eliminated after each step, which would eliminate the limit on the number of consecutive steps. So all universal computers are digital; and all use error-correction with the same basic logic that I have just described, though with many different implementations. Thus Babbage’s computers assigned only ten different meanings to the whole continuum of angles at which a cogwheel might be oriented. Making the representation digital in that way allowed the cogs to carry out error-correction automatically: after each step, any slight drift in the orientation of the wheel away from its ten ideal positions would immediately be corrected back to the 141 the beginning of infinity nearest one as it clicked into place. Assigning meanings to the whole continuum of angles would nominally have allowed each wheel to carry (infinitely) more information; but, in reality, information that cannot be reliably retrieved is not really being stored. Fortunately, the limitation that the information being processed must be digital does not detract from the universality of digital computers – or of the laws of physics. If measuring the goats in whole numbers of inches is insufficient for a particular application, use whole numbers of tenths of inches, or billionths. The same holds for all other appli- cations: the laws of physics are such that the behaviour of any physical object – and that includes any other computer – can be simulated with any desired accuracy by a universal digital computer. It is just a matter of approximating continuously variable quantities by a sufficiently fine grid of discrete ones. Because of the necessity for error-correction, all jumps to universality occur in digital systems. It is why spoken languages build words out of a finite set of elementary sounds: speech would not be intelligible if it were analogue. It would not be possible to repeat, nor even to remember, what anyone had said. Nor, therefore, does it matter that universal writing systems cannot perfectly represent analogue inform- ation such as tones of voice. Nothing can represent those perfectly. For the same reason, the sounds themselves can represent only a finite number of possible meanings. For example, humans can distinguish between only about seven different sound volumes. This is roughly reflected in standard musical notation, which has approximately seven different symbols for loudness (such as p, mf, f, and so on). And, for the same reason, speakers can only intend a finite number of possible meanings with each utterance. Another striking connection between all those diverse jumps to universality is that they all happened on Earth. In fact all known jumps to universality happened under the auspices of human beings – except one, which I have not mentioned yet, and from which all the others, historically, emerged. It happened during the early evolution of life. Genes in present-day organisms replicate themselves by a complicated and very indirect chemical route. In most species they act as templates for forming stretches of a similar molecule, RNA. Those then act as programs which direct the synthesis of the body’s constituent chemicals, 142 The Jump to Universality especially enzymes, which are catalysts. A catalyst
================================================================================education enjoins them to hold their most important ideas immune from criticism. Not to be open to suggestions. Not to criticize certain ideas such as their traditions or their conceptions of the gods; not to seek the truth, because they claim that they already have it. Hence they do not believe that ‘in the course of time they may *Popper’s translation in The World of Parmenides (1998). 230 A Dream of Socrates learn and know things better.’ They agree among themselves because their laws and customs enforce conformity. We agree among ourselves (to the extent that we do) because, through our tradition of endless critical debate, we have discovered some genuine knowledge. Since there is only one truth of any given matter, as we discover ideas closer to the truth our ideas become closer to each other’s, so we agree more. People who converge upon the truth converge with each other. hermes: Indeed. socrates: Moreover, since the Spartans never seek improvement, it is not surprising that they never find it. We, in contrast, have sought it – by constantly criticizing and debating and trying to correct our ideas and behaviour. And thereby we are well placed to learn more in the future. hermes: It follows, then, that it is wrong of the Spartans to educate their children to hold their city’s ideas, laws and customs immune from criticism. socrates: I thought you weren’t going to reveal moral truths! hermes: I can’t help it if it follows logically from epistemology. But, anyway, you already know this one. socrates: Yes, I do. And I see what you are getting at. You are showing me that there are such things as mirages and tricks in regard to moral knowledge. Some of them are embedded in the Spartans’ traditional moral choices. Their whole way of life misleads and traps them – because one of their mistaken beliefs is that they must take no steps to prevent their way of life from misleading and trapping them! hermes: Yes. socrates: Are there such traps embedded in our way of life? [Frowns.] Of course, I think there aren’t – but I would think that, wouldn’t I? As Xenophanes also wrote, it’s all too easy to attribute universal truth to mere local appearances: The Ethiops say that their gods are flat-nosed and black While the Thracians say that theirs have blue eyes and red hair. Yet if cattle or horses or lions had hands and could draw And could sculpture like men, then the horses would draw their gods Like horses, and cattle like cattle . . . 231 the beginning of infinity hermes: So now you are imagining some Spartan Socrates who considers their ways virtuous and yours decadent – socrates: And who considers us to be stuck in a trap, since we shall never willingly ‘correct’ ourselves by adopting Spartan ways. Yes. hermes: But does this Spartan Socrates, if he exists, worry that the Athenian Socrates may be right, and he wrong? Was there a Spartan Xenophanes who suspected that the gods might not be as the Greeks think they are? socrates: Most certainly not! hermes: So, since one of their ‘ways’ is to preserve all their ways unchanged, then if he were right, and you wrong – socrates: Then the Spartans must also have been right ever since they embarked on their present way of life. The gods must have revealed the perfect way of life to them at the outset. So – did you? hermes: [Raises his eyebrows.] socrates: Of course you didn’t. Now I see that the difference between our ways and theirs is not merely a matter of perspective, nor just a matter of degree.* Let me restate it: If the Spartan Socrates is right that Athens is trapped in falsehoods but Sparta is not, then Sparta, being unchanging, must already be perfect, and hence right about everything else too. Yet in fact they know almost nothing. One thing that they clearly don’t know is how to persuade other cities that Sparta is perfect, even cities that have a policy of listening to arguments and criticism . . . hermes: Well, logically it could be that the ‘perfect way of life’ involves having few accomplishments and being wrong about most things. But, yes, you are glimpsing something important here – socrates: Whereas if I am right that Athens is not in such a trap, that implies nothing about whether we are right or wrong about any other matter. Indeed, our very idea that improvement is possible implies that there must be errors and inadequacies in our current ideas. I thank you, generous Apollo, for this ‘glimpse’ into that important difference. hermes: Yet there is even more of a difference than you think. Bear *I shall say more about the difference between those two kinds of society – which I call static and dynamic societies – in Chapter 15. 232 A Dream of Socrates in mind that the Spartans and Athenians alike are but fallible men and are subject to misconceptions and errors in all their thinking – socrates: Wait! We are fallible in all our thinking? Is there literally no idea that we may safely hold immune from criticism? hermes: Like what? socrates: [Ponders for a while. Then:] What about the truths of arithmetic, like two plus two equals four? Or the fact that Delphi exists? What about the geometrical fact that the angles of a triangle sum to two right angles? hermes: Revealing no facts, I cannot confirm that all three of those propositions are even true! But more important is this: how did you come to choose those particular propositions as candidates for immunity from criticism? Why Delphi and not Athens? Why two plus two and not three plus four? Why not the theorem of Pythagoras? Was it because you decided that the propositions you chose would best make your point because they were the most obviously, un - ambiguously true of all the propositions you considered using? socrates: Yes.
================================================================================answer is apportionment paradoxes – or, in ordinary language, unfairness and irrationality. For example, the last reallocation scheme that I described is unfair by being biased against the inhabitants of the least populous state. They bear the whole cost of correcting the rounding errors. On this occasion their representation has been rounded down to zero. Yet, in the sense of minimizing the deviation from the quotas, the apportion- ment is almost perfectly fair: previously, 85 per cent of the population were well outside the quota, and now all are within it and 95 per cent are at the closest whole numbers to their quotas. It is true that 5 per cent now have no representatives – so they will not be able to vote in congressional elections at all – but that still leaves them within the quota, and indeed only slightly further from their exact quota than they were. (The numbers zero and one are almost equidistant from the quota of just over one half.) Nevertheless, because those 5 per cent have been completely disenfranchised, most advocates of representative government would regard this outcome as much less representative than it was before. That must mean that the ‘minimum total deviation from quota’ is not the right measure of representativeness. But what is the right measure? What is the right trade-off between being slightly unfair to many people and very unfair to a few people? The Founding Fathers were aware that different conceptions of fairness, or representativeness, could conflict. For example, one of their justifications for democracy was that govern ment was not legitimate unless everyone who was subject to the law had a representative, of equal power, among the lawmakers. This was expressed in their slogan ‘No taxation without representation’. Another of their aspirations was to abolish privilege: 328 Choices they wanted the system of government to have no built-in bias. Hence the requirement of proportional allocation. Since these two aspirations can conflict, the Constitution contains a clause that explicitly adjudicates between them: ‘Each State shall have at least one Representative.’ This favours the principle of representative government in the no-taxation- without-representation sense over the same principle in the abolish- privilege sense. Another concept that frequently appeared in the Founding Fathers’ arguments for representative government was ‘the will of the people’. Governments are supposed to enact it. But that is a source of further inconsistencies. For in elections, only the will of voters counts, and not all of ‘the people’ are voters. At the time, voters were a fairly small minority: only free male citizens over the age of twenty-one. To address this point, the ‘Numbers’ referred to in the Constitution constituted the whole population of a state, including non-voters such as women, children, immigrants and slaves. In this way the Constitution attempted to treat the population equally by treating voters unequally. So voters in states with a higher proportion of non-voters were allocated more representatives per capita. This had the perverse effect that in the states where the voters were already the most privileged within the state (i.e. where they were an exceptionally small minority), they now received an additional privilege relative to voters in other states: they were allocated more representation in Congress. This became a hot political issue in regard to slave-owners. Why should slave-owning states be allocated more political clout in proportion to how many slaves they had? To reduce this effect, a compromise was reached whereby a slave counted as three-fifths of a person for the purpose of apportioning seats in the House. But, even so, three- fifths of an injustice was still considered an injustice by many.* The same controversy exists today in regard to illegal immigrants, who also count as part of the population for apportionm ent purposes. So *This rule is often misinterpreted as illustrating how slaves were regarded as less than fully human. But that has nothing to do with the issue. Black people were indeed widely regarded as being inferior to white ones, but this particular measure was designed to reduce the power of slave-owning states compared to what it would have been if slaves had been counted like everyone else. 329 the beginning of infinity states with large numbers of illegal immig rants receive extra seats in Congress, while other states cor r espond ingly lose out. Following the first US census, in 1790, notwithstanding the new Constitution’s requirement of proportionality, seats in the House of Representatives were apportioned under a rule that violated quota. Proposed by the future president Thomas Jefferson, this rule also favoured states with higher populations, giving them more rep resen- tatives per capita. So Congress voted to scrap it and substitute a rule proposed by Jefferson’s arch-rival Alexander Hamilton, which is guaranteed to give a result that stays within quota as well as having no obvious bias between states. That was the change that President Washington vetoed. The reason he gave was simply that it involved reallocation: he considered all reallocation schemes unconstitutional, because he interpreted the term ‘apportioned’ as meaning divided by a suitable numerical divisor – and then rounded, but nothing else. Inevitably, some suspected that his real reason was that he, like Jefferson, came from the most populous state, Virginia, which would have lost out under Hamilton’s rule. Ever since, Congress has continually debated and tinkered with the rules of apportionment. Jefferson’s rule was eventually dropped in 1841 in favour of one proposed by Senator Daniel Webster, which does use reallocation. It also violates quota, but very rarely; and it was, like Hamilton’s rule, deemed to be impartial between states. A decade later, Webster’s rule was in turn dropped in favour of Hamilton’s. The latter’s supporters now believed that the principle of representative government was fully implemented, and perhaps hoped that this would be the end of the apportionment problem. But they were to be disappointed. It was soon causing more controversy than ever, because Hamilton’s rule, despite its impartiality and proportion- ality, began to make allocations that seemed outrageously
================================================================================alone measure – like happiness. And, in any case, including such things makes no difference: there are still no-go theorems. As with the apportionment problem, it seems that whenever one patches up a decision-making system in one way, it becomes paradox- ical in another. A further serious problem that has been identified in many decision-making institutions is that they create incentives for participants to lie about their preferences. For instance, if there are two options of which you mildly prefer one, you have an incentive to register your preference as ‘strong’ instead. Perhaps you are prevented from doing that by a sense of civic responsibility. But a decision-making system moderated by civic responsibility has the defect that it gives disproportionate weight to the opinions of people who lack civic responsibility and are willing to lie. On the other hand, a society in which everyone knows everyone sufficiently well to make such lying difficult cannot have an effectively secret ballot, and the system will then give disproportionate weight to the faction most able to intimidate waverers. One perennially controversial social-choice problem is that of de - vising an electoral system. Such a system is mathematically similar to an apportionment scheme, but, instead of allocating seats to states on the basis of population, it allocates them to candidates (or parties) on the basis of votes. However, it is more paradoxical than apportionment and has more serious consequences, because in the case of elections the element of persuasion is central to the whole exercise: an election is supposed to determine what the voters have become persuaded of. 338 Choices (In contrast, apportionment is not about states trying to persuade people to migrate from other states.) Consequently an electoral system can contribute to, or can inhibit, traditions of criticism in the society concerned. For example, an electoral system in which seats are allocated wholly or partly in proportion to the number of votes received by each party is called a ‘proportional-representation’ system. We know from Balinski and Young that, if an electoral system is too proportional, it will be subject to the analogue of the population paradox and other paradoxes. And indeed the political scientist Peter Kurrild-Klitgaard, in a study of the most recent eight general elections in Denmark (under its proportional-representation system), showed that every one of them manifested paradoxes. These included the ‘More-Preferred-Less-Seats paradox’, in which a majority of voters prefer party X to party Y, but party Y receives more seats than party X. But that is really the least of the irrational attributes of proportional representation. A more important one – which is shared by even the mildest of proportional systems – is that they assign disproportionate power in the legislature to the third-largest party, and often to even smaller parties. It works like this. It is rare (in any system) for a single party to receive an overall majority of votes. Hence, if votes are reflected proportionately in the legislature, no legislation can be passed unless some of the parties cooperate to pass it, and no government can be formed unless some of them form a coalition. Sometimes the two largest parties manage to do this, but the most common outcome is that the leader of the third-largest party holds the ‘balance of power’ and decides which of the two largest parties shall join it in government, and which shall be sidelined, and for how long. That means that it is correspondingly harder for the electorate to decide which party, and which policies, will be removed from power. In Germany (formerly West Germany) between 1949 and 1998, the Free Democratic Party (FDP) was the third largest.* Though it never received more than 12.8 per cent of the vote, and usually much less, the country’s proportional-representation system gave it power that was *I am counting the Christian Democrat CDU and the regionally based CSU as being one party for present purposes. 339 the beginning of infinity insensitive to changes in the voters’ opinions. On several occasions it chose which of the two largest parties would govern, twice changing sides and three times choosing to put the less popular of the two (as measured by votes) into power. The FDP’s leader was usually made a cabinet minister as part of the coalition deal, with the result that for the last twenty-nine years of that period Germany had only two weeks without an FDP foreign minister. In 1998, when the FDP was pushed into fourth place by the Green Party, it was immediately ousted from government, and the Greens assumed the mantle of kingmakers. And they took charge of the Foreign Ministry as well. This disproportionate power that proportional representation gives the third-largest party is an embarrassing feature of a system whose whole raison d’être, and supposed moral justification, is to allocate political influence proportionately. Arrow’s theorem applies not only to collective decision-making but also to individuals, as follows. Consider a single, rational person faced with a choice between several options. If the decision requires thought, then each option must be associated with an explanation – at least a tentative one – for why it might be the best. To choose an option is to choose its explanation. So how does one decide which explanation to adopt? Common sense says that one ‘weighs’ them – or weighs the evidence that their arguments present. This is an ancient metaphor. Statues of Justice have carried scales since antiquity. More recently, inductivism has cast scientific thinking in the same mould, saying that scientific theories are chosen, justified and believed – and somehow even formed in the first place – according to the ‘weight of evidence’ in their favour. Consider that supposed weighing process. Each piece of evidence, including each feeling, prejudice, value, axiom, argument and so on, depending on what ‘weight’ it had in that person’s mind, would contribute that amount to that person’s ‘preferences’ between various explanations. Hence for the purposes of Arrow’s theorem each piece of evidence can be regarded as an ‘individual’
================================================================================the two ideas generate a rich conceptual framework that can inform an entire world view. Yet, as I shall explain, they are both false, even in the straightforward factual sense. And in the broader sense they are so misleading that, if you were seeking maxims worth being carved in stone and recited each morning before breakfast, you could do a lot worse than to use their negations. That is to say, the truth is that People are significant in the cosmic scheme of things; and The Earth’s biosphere is incapable of supporting human life. Consider Hawking’s remark again. It is true that we are on a (somewhat) typical planet of a typical star in a typical galaxy. But we are far from typical of the matter in the universe. For one thing, about 45 the beginning of infinity 80 per cent of that matter is thought to be invisible ‘dark matter’, which can neither emit nor absorb light. We currently detect it only through its indirect gravitational effects on galaxies. Only the remaining 20 per cent is matter of the type that we parochially call ‘ordinary matter’. It is characterized by glowing continuously. We do not usually think of ourselves as glowing, but that is another parochial misconception, due to the limitations of our senses: we emit radiant heat, which is infra- red light, and also light in the visible range, too faint for our eyes to detect. Concentrations of matter as dense as ourselves and our planet and star, though numerous, are not exactly typical either. They are isolated, uncommon phenomena. The universe is mostly vacuum (plus radiation and dark matter). Ordinary matter is familiar to us only because we are made of it, and because of our untypical location near large concentrations of it. Moreover, we are an uncommon form of ordinary matter. The commonest form is plasma (atoms dissociated into their electrically charged components), which typically emits bright, visible light because it is in stars, which are rather hot. We scums are mainly infra-red emitters because we contain liquids and complex chemicals which can exist only at a much lower range of temperatures. The universe is pervaded with microwave radiation – the afterglow of the Big Bang. Its temperature is about 2.7 kelvin, which means 2.7 degrees above the coldest possible temperature, absolute zero, or about 270 degrees Celsius colder than the freezing point of water. Only very unusual circumstances can make anything colder than those micro- waves. Nothing in the universe is known to be cooler than about one kelvin – except in certain physics laboratories on Earth. There, the record low temperature achieved is below one billionth of a kelvin. At those extraordinary temperatures, the glow of ordinary matter is effectively extinguished. The resulting ‘non-glowing ordinary matter’ on our planet is an exceedingly exotic substance in the universe at large. It may well be that the interiors of refrigerators constructed by physicists are by far the coldest and darkest places in the universe. Far from typical. What is a typical place in the universe like? Let me assume that you are reading this on Earth. In your mind’s eye, travel straight upwards 46 The Spark a few hundred kilometres. Now you are in the slightly more typical environment of space. But you are still being heated and illuminated by the sun, and half your field of view is still taken up by the solids, liquids and scums of the Earth. A typical location has none of those features. So, travel a few trillion kilometres further in the same direction. You are now so far away that the sun looks like other stars. You are at a much colder, darker and emptier place, with no scum in sight. But it is not yet typical: you are still inside the Milky Way galaxy, and most places in the universe are not in any galaxy. Continue until you are clear outside the galaxy – say, a hundred thousand light years from Earth. At this distance you could not glimpse the Earth even if you used the most powerful telescope that humans have yet built. But the Milky Way still fills much of your sky. To get to a typical place in the universe, you have to imagine yourself at least a thousand times as far out as that, deep in intergalactic space. What is it like there? Imagine the whole of space notionally divided into cubes the size of our solar system. If you were observing from a typical one of them, the sky would be pitch black. The nearest star would be so far away that if it were to explode as a supernova, and you were staring directly at it when its light reached you, you would not see even a glimmer. That is how big and dark the universe is. And it is cold: it is at that background temperature of 2.7 kelvin, which is cold enough to freeze every known substance except helium. (Helium is believed to remain liquid right down to absolute zero, unless highly pressurized.) And it is empty: the density of atoms out there is below one per cubic metre. That is a million times sparser than atoms in the space between the stars, and those atoms are themselves sparser than in the best vacuum that human technology has yet achieved. Almost all the atoms in intergalactic space are hydrogen or helium, so there is no chemistry. No life could have evolved there, nor any intelligence. Nothing changes there. Nothing happens. The same is true of the next cube and the next, and if you were to examine a million consecutive cubes in any direction the story would be the same. Cold, dark and empty. That unimaginably desolate environment is typical of the universe – and is another measure of how untypical the Earth and its chemical scum are, in a straightforward physical sense. 47 the beginning of infinity The issue of the cosmic significance of this type of scum will
================================================================================