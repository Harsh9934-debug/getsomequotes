Reach of Explanations Behind it all is surely an idea so simple, so beautiful, that when we grasp it – in a decade, a century, or a millennium – we will all say to each other, how could it have been otherwise? John Archibald Wheeler, Annals of the New York Academy of Sciences, 480 (1986) To unaided human eyes, the universe beyond our solar system looks like a few thousand glowing dots in the night sky, plus the faint, hazy streaks of the Milky Way. But if you ask an astronomer what is out there in reality, you will be told not about dots or streaks, but about stars: spheres of incandescent gas millions of kilometres in diameter and light years away from us. You will be told that the sun is a typical star, and looks different from the others only because we are much closer to it – though still some 150 million kilometres away. Yet, even at those unimaginable distances, we are confident that we know what makes stars shine: you will be told that they are powered by the nuclear energy released by transmutation – the conversion of one chemical element into another (mainly hydrogen into helium). Some types of transmutation happen spontaneously on Earth, in the decay of radioactive elements. This was first demonstrated in 1901, by the physicists Frederick Soddy and Ernest Rutherford, but the concept of transmutation was ancient. Alchemists had dreamed for centuries of transmuting ‘base metals’, such as iron or lead, into gold. They never came close to understanding what it would take to achieve that, so they never did so. But scientists in the twentieth century did. And so do stars, when they explode as supernovae. Base metals can be 1 the beginning of infinity transmuted into gold by stars, and by intelligent beings who understand the processes that power stars, but by nothing else in the universe. As for the Milky Way, you will be told that, despite its insubstantial appearance, it is the most massive object that we can see with the naked eye: a galaxy that includes stars by the hundreds of billions, bound by their mutual gravitation across tens of thousands of light years. We are seeing it from the inside, because we are part of it. You will be told that, although our night sky appears serene and largely changeless, the universe is seething with violent activity. Even a typical star converts millions of tonnes of mass into energy every second, with each gram releasing as much energy as an atom bomb. You will be told that within the range of our best telescopes, which can see more galaxies than there are stars in our galaxy, there are several supernova explosions per second, each briefly brighter than all the other stars in its galaxy put together. We do not know where life and intelligence exist, if at all, outside our solar system, so we do not know how many of those explosions are horrendous tragedies. But we do know that a supernova devastates all the planets that may be orbiting it, wiping out all life that may exist there – including any intelligent beings, unless they have technology far superior to ours. Its neutrino radiation alone would kill a human at a range of billions of kilometres, even if that entire distance were filled with lead shielding. Yet we owe our existence to supernovae: they are the source, through transmutation, of most of the elements of which our bodies, and our planet, are composed. There are phenomena that outshine supernovae. In March 2008 an X-ray telescope in Earth orbit detected an explosion of a type known as a ‘gamma-ray burst’, 7.5 billion light years away. That is halfway across the known universe. It was probably a single star collapsing to form a black hole – an object whose gravity is so intense that not even light can escape from its interior. The explosion was intrinsically brighter than a million supernovae, and would have been visible with the naked eye from Earth – though only faintly and for only a few seconds, so it is unlikely that anyone here saw it. Supernovae last longer, typically fading on a timescale of months, which allowed astronomers to see a few in our galaxy even before the invention of telescopes. Another class of cosmic monsters, the intensely luminous objects known as quasars, are in a different league. Too distant to be seen with 2 The Reach of Explanations the naked eye, they can outshine a supernova for millions of years at a time. They are powered by massive black holes at the centres of galaxies, into which entire stars are falling – up to several per day for a large quasar – shredded by tidal effects as they spiral in. Intense magnetic fields channel some of the gravitational energy back out in the form of jets of high-energy particles, which illuminate the sur - rounding gas with the power of a trillion suns. Conditions are still more extreme in the black hole’s interior (within the surface of no return known as the ‘event horizon’), where the very fabric of space and time may be being ripped apart. All this is happening in a relentlessly expanding universe that began about fourteen billion years ago with an all-encompassing explosion, the Big Bang, that makes all the other phenomena I have described seem mild and inconsequential by comparison. And that whole universe is just a sliver of an enormously larger entity, the multiverse, which includes vast numbers of such universes. The physical world is not only much bigger and more violent than it once seemed, it is also immensely richer in detail, diversity and incident. Yet it all proceeds according to elegant laws of physics that we understand in some depth. I do not know which is more awesome: the phenomena themselves or the fact that we know so much about them. How do we know? One of the most remarkable things
================================================================================the Earth is not at rest but in complex motion. Although we first noticed a daily rotation by observing stars, it is not a property of the stars at all, but of the Earth, and of the observers who rotate with it. It is a classic example of the deceptiveness of the senses: the Earth looks and feels as though it is at rest beneath our feet, even though it is really rotating. As for the celestial sphere, despite being visible in broad daylight (as the sky), it does not exist at all. The deceptiveness of the senses was always a problem for empiricism – and thereby, it seemed, for science. The empiricists’ best defence was that the senses cannot be deceptive in themselves. What misleads us are only the false interpretations that we place on appearances. That is indeed true – but only because our senses themselves do not say anything. Only our interpretations of them do, and those are very fallible. But the real key to science is that our explanatory theories – which include those interpretations – can be improved, through conjecture, criticism and testing. Empiricism never did achieve its aim of liberating science from authority. It denied the legitimacy of traditional authorities, and that was salutary. But unfortunately it did this by setting up two other false 8 The Reach of Explanations authorities: sensory experience and whatever fictitious process of ‘derivation’, such as induction, one imagines is used to extract theories from experience. The misconception that knowledge needs authority to be genuine or reliable dates back to antiquity, and it still prevails. To this day, most courses in the philosophy of knowledge teach that knowledge is some form of justified, true belief, where ‘justified’ means designated as true (or at least ‘probable’) by reference to some authoritative source or touchstone of knowledge. Thus ‘how do we know . . . ?’ is trans- formed into ‘by what authority do we claim . . . ?’ The latter question is a chimera that may well have wasted more philosophers’ time and effort than any other idea. It converts the quest for truth into a quest for certainty (a feeling) or for endorsement (a social status). This misconception is called justificationism. The opposing position – namely the recognition that there are no authoritative sources of knowledge, nor any reliable means of justifying ideas as being true or probable – is called fallibilism. To believers in the justified-true-belief theory of knowledge, this recognition is the occasion for despair or cynicism, because to them it means that know- ledge is unattainable. But to those of us for whom creating knowledge means understanding better what is really there, and how it really behaves and why, fallibilism is part of the very means by which this is achieved. Fallibilists expect even their best and most fundamental explanations to contain misconceptions in addition to truth, and so they are predisposed to try to change them for the better. In contrast, the logic of justificationism is to seek (and typically, to believe that one has found) ways of securing ideas against change. Moreover, the logic of fallibilism is that one not only seeks to correct the misconceptions of the past, but hopes in the future to find and change mistaken ideas that no one today questions or finds problematic. So it is fallibilism, not mere rejection of authority, that is essential for the initiation of unlimited knowledge growth – the beginning of infinity. The quest for authority led empiricists to downplay and even stig- matize conjecture, the real source of all our theories. For if the senses were the only source of knowledge, then error (or at least avoidable error) could be caused only by adding to, subtracting from or mis - interpreting what that source is saying. Thus empiricists came to believe 9 the beginning of infinity that, in addition to rejecting ancient authority and tradition, scientists should suppress or ignore any new ideas they might have, except those that had been properly ‘derived’ from experience. As Arthur Conan Doyle’s fictional detective Sherlock Holmes put it in the short story ‘A Scandal in Bohemia’, ‘It is a capital mistake to theorize before one has data.’ But that was itself a capital mistake. We never know any data before interpreting it through theories. All observations are, as Popper put it, theory-laden,* and hence fallible, as all our theories are. Consider the nerve signals reaching our brains from our sense organs. Far from providing direct or untainted access to reality, even they themselves are never experienced for what they really are – namely crackles of electrical activity. Nor, for the most part, do we experience them as being where they really are – inside our brains. Instead, we place them in the reality beyond. We do not just see blue: we see a blue sky up there, far away. We do not just feel pain: we experience a headache, or a stomach ache. The brain attaches those interpretations – ‘head’, ‘stomach’ and ‘up there’ – to events that are in fact within the brain itself. Our sense organs themselves, and all the interpretations that we consciously and unconsciously attach to their outputs, are notoriously fallible – as witness the celestial-sphere theory, as well as every optical illusion and conjuring trick. So we perceive nothing as what it really is. It is all theoretical interpretation: conjecture. Conan Doyle came much closer to the truth when, during ‘The Boscombe Valley Mystery’, he had Holmes remark that ‘circumstantial evidence’ (evidence about unwitnessed events) is ‘a very tricky thing . . . It may seem to point very straight to one thing, but if you shift your own point of view a little, you may find it pointing in an equally uncompromising manner to something entirely different . . . There is nothing more deceptive than an obvious fact.’ The same holds for scientific discovery. And that again raises the question: how do we know? If all our theories
================================================================================what is really there in the physical world. The quest for good explanations is, I believe, the basic regulating principle not only of science, but of the Enlightenment generally. It is the feature that distinguishes those approaches to knowledge from all others, and it implies all those other conditions for scientific progress I have discussed: It trivially implies that prediction alone is insufficient. 22 The Reach of Explanations Somewhat less trivially, it leads to the rejection of authority, because if we adopt a theory on authority, that means that we would also have accepted a range of different theories on authority. And hence it also implies the need for a tradition of criticism. It also implies a meth- odological rule – a criterion for reality – namely that we should conclude that a particular thing is real if and only if it figures in our best explanation of something. Although the pioneers of the Enlightenment and of the scientific revolution did not put it this way, seeking good explanations was (and remains) the spirit of the age. This is how they began to think. It is what they began to do, systematically for the first time. It is what made that momentous difference to the rate of progress of all kinds. Long before the Enlightenment, there were individuals who sought good explanations. Indeed, my discussion here suggests that all progress then, as now, was due to such people. But in most ages they lacked contact with a tradition of criticism in which others could carry on their ideas, and so created little that left any trace for us to detect. We do know of sporadic traditions of good-explanation-seeking in narrowly defined fields, such as geometry, and even short-lived traditions of criticism – mini-enlightenments – which were tragically snuffed out, as I shall describe in Chapter 9. But the sea change in the values and patterns of thinking of a whole community of thinkers, which brought about a sustained and accelerating creation of knowledge, happened only once in history, with the Enlightenment and its scientific revolution. An entire political, moral, economic and intellectual culture – roughly what is now called ‘the West’ – grew around the values entailed by the quest for good explanations, such as tolerance of dissent, openness to change, distrust of dogmatism and authority, and the aspiration to progress both by individuals and for the culture as a whole. And the progress made by that multifaceted culture, in turn, promoted those values – though, as I shall explain in Chapter 15, they are nowhere close to being fully implemented. Now consider the true explanation of seasons. It is that the Earth’s axis of rotation is tilted relative to the plane of its orbit around the sun. Hence for half of each year the northern hemisphere is tilted towards the sun while the southern hemisphere is tilted away, and for the other half it is the other way around. Whenever the sun’s rays are 23 the beginning of infinity falling vertically in one hemisphere (thus providing more heat per unit area of the surface) they are falling obliquely in the other (thus providing less). The true explanation of seasons (not to scale!) That is a good explanation – hard to vary, because all its details play a functional role. For instance, we know – and can test independently of our experience of seasons – that surfaces tilted away from radiant heat are heated less than when they are facing it, and that a spinning sphere in space points in a constant direction. And we can explain why, in terms of theories of geometry, heat and mechanics. Also, the same tilt appears in our explanation of where the sun appears relative to the horizon at different times of year. In the Persephone myth, in contrast, the coldness of the world is caused by Demeter’s sadness – but people do not generally cool their surroundings when they are sad, and we have no way of knowing that Demeter is sad, or that she ever cools the world, other than the onset of winter itself. One could not substitute the moon for the sun in the axis-tilt story, because the position of the moon in the sky does not repeat itself once a year, and because the sun’s rays heating the Earth are integral to the explanation. Nor could one easily incorporate any stories about how the sun god feels about all this, because if the true explanation of winter is in the geometry of the Earth–sun motion, then how anyone feels about it is irrelevant, and if there were some flaw in that explanation, then no story about how anyone felt would put it right. The axis-tilt theory also predicts that the seasons will be out of phase in the two hemispheres. So if they had been found to be in phase, the 24 The Reach of Explanations theory would have been refuted, just as, in the event, the Persephone and Freyr myths were refuted by the opposite observation. But the difference is, if the axis-tilt theory had been refuted, its defenders would have had nowhere to go. No easily implemented change could make tilted axes cause the same seasons all over the planet. Fundamentally new ideas would have been needed. That is what makes good ex - planations essential to science: it is only when a theory is a good explanation – hard to vary – that it even matters whether it is testable. Bad explanations are equally useless whether they are testable or not. Most accounts of the differences between myth and science make too much of the issue of testability – as if the ancient Greeks’ great mistake was that they did not send expeditions to the southern hemi- sphere to observe the seasons. But in fact they could never have guessed that such an expedition might provide evidence about seasons unless they had already guessed that seasons would be out of phase in the two hemispheres –
================================================================================and if that guess was hard to vary, which it could have been only if it had been part of a good explanation. If their guess was easy to vary, they might just as well have saved themselves the boat fare, stayed at home, and tested the easily testable theory that winter can be staved off by yodelling. So long as they had no better explanation than the Persephone myth, there should have been no need for testing. Had they been seeking good explanations, they would immediately have tried to improve upon the myth, without testing it. That is what we do today. We do not test every testable theory, but only the few that we find are good explanations. Science would be impossible if it were not for the fact that the over- whelming majority of false theories can be rejected out of hand without any experiment, simply for being bad explanations. Good explanations are often strikingly simple or elegant – as I shall discuss in Chapter 14. Also, a common way in which an explanation can be bad is by containing superfluous features or arbitrariness, and sometimes removing those yields a good explanation. This has given rise to a misconception known as ‘Occam’s razor’ (named after the fourteenth-century philosopher William of Occam, but dating back to antiquity), namely that one should always seek the ‘simplest ex - planation’. One statement of it is ‘Do not multiply assumptions beyond necessity.’ However, there are plenty of very simple explanations that 25 the beginning of infinity are nevertheless easily variable (such as ‘Demeter did it’). And, while assumptions ‘beyond necessity’ make a theory bad by definition, there have been many mistaken ideas of what is ‘necessary’ in a theory. Instrumentalism, for instance, considers explanation itself unnecessary, and so do many other bad philosophies of science, as I shall discuss in Chapter 12. When a formerly good explanation has been falsified by new observations, it is no longer a good explanation, because the problem has expanded to include those observations. Thus the standard scientific methodology of dropping theories when refuted by experi- ment is implied by the requirement for good explanations. The best explanations are the ones that are most constrained by existing know- ledge – including other good explanations as well as other knowledge of the phenomena to be explained. That is why testable explanations that have passed stringent tests become extremely good explanations, which is in turn why the maxim of testability promotes the growth of knowledge in science. Conjectures are the products of creative imagination. But the problem with imagination is that it can create fiction much more easily than truth. As I have suggested, historically, virtually all human attempts to explain experience in terms of a wider reality have indeed been fiction, in the form of myths, dogma and mistaken common sense – and the rule of testability is an insufficient check on such mistakes. But the quest for good explanations does the job: inventing falsehoods is easy, and therefore they are easy to vary once found; discovering good explanations is hard, but the harder they are to find, the harder they are to vary once found. The ideal that explanatory science strives for is nicely described by the quotation from Wheeler with which I began this chapter: ‘Behind it all is surely an idea so simple, so beautiful, that when we grasp it – in a decade, a century, or a millennium – we will all say to each other, how could it have been otherwise? [my italics].’ Now we shall see how this explanation-based conception of science answers the question that I asked above: how do we know so much about unfamiliar aspects of reality? Put yourself in the place of an ancient astronomer thinking about the axis-tilt explanation of seasons. For the sake of simplicity, let us assume that you have also adopted the heliocentric theory. So you 26 The Reach of Explanations might be, say, Aristarchus of Samos, who gave the earliest known arguments for the heliocentric theory in the third century bce. Although you know that the Earth is a sphere, you possess no evidence about any location on Earth south of Ethiopia or north of the Shetland Islands. You do not know that there is an Atlantic or a Pacific ocean; to you, the known world consists of Europe, North Africa and parts of Asia, and the coastal waters nearby. Nevertheless, from the axis-tilt theory of seasons, you can make predictions about the weather in the literally unheard-of places beyond your known world. Some of these predictions are mundane and could be mistaken for induction: you predict that due east or west, however far you travel, you will experience seasons at about the same time of year (though the timings of sunrise and sunset will gradually shift with longitude). But you will also make some counter-intuitive predictions: if you travel only a little further north than the Shetlands, you will reach a frozen region where each day and each night last six months; if you travel further south than Ethiopia, you will first reach a place where there are no seasons, and then, still further south, you will reach a place where there are seasons, but they are perfectly out of phase with those everywhere in your known world. You have never travelled more than a few hundred kilometres from your home island in the Mediterranean. You have never experienced any seasons other than Mediterranean ones. You have never read, nor heard tell, of seasons that were out of phase with the ones you have experienced. But you know about them. What if you’d rather not know? You may not like these predictions. Your friends and colleagues may ridicule them. You may try to modify the explanation so that it will not make them, without spoiling its agreement with observations and with other ideas for which you have no good alternatives. You will fail. That is what a good explanation will do
================================================================================anything so grand (even if only potentially) on behalf of a project that has swept away all the ancient myths that used to assign human beings a special significance in the scheme of things. For if the power of the human faculties of reason and creativity, which have driven the En - lightenment, were indeed unlimited, would humans not have just such a significance? And yet, as I mentioned at the beginning of this chapter, gold can be created only by stars and by intelligent beings. If you find a nugget of gold anywhere in the universe, you can be sure that in its history there was either a supernova or an intelligent being with an explanation. And if you find an explanation anywhere in the universe, you know that there must have been an intelligent being. A supernova alone would not suffice. But – so what? Gold is important to us, but in the cosmic scheme of things it has little significance. Explanations are important to us: we need them to survive. But is there anything significant, in the cosmic scheme of things, about explanation, that apparently puny physical process that happens inside brains? I shall address that question in Chapter 3, after some reflections about appearance and reality. terminology Explanation Statement about what is there, what it does, and how and why. Reach The ability of some explanations to solve problems beyond those that they were created to solve. Creativity The capacity to create new explanations. Empiricism The misconception that we ‘derive’ all our knowledge from sensory experience. Theory-laden There is no such thing as ‘raw’ experience. All our experience of the world comes through layers of conscious and unconscious interpretation. Inductivism The misconception that scientific theories are obtained by generalizing or extrapolating repeated experiences, and that the 30 The Reach of Explanations more often a theory is confirmed by observation the more likely it becomes. Induction The non-existent process of ‘obtaining’ referred to above. Principle of induction The idea that ‘the future will resemble the past’, combined with the misconception that this asserts anything about the future. Realism The idea that the physical world exists in reality, and that knowledge of it can exist too. Relativism The misconception that statements cannot be objectively true or false, but can be judged only relative to some cultural or other arbitrary standard. Instrumentalism The misconception that science cannot describe reality, only predict outcomes of observations. Justificationism The misconception that knowledge can be genuine or reliable only if it is justified by some source or criterion. Fallibilism The recognition that there are no authoritative sources of knowledge, nor any reliable means of justifying knowledge as true or probable. Background knowledge Familiar and currently uncontroversial knowledge. Rule of thumb ‘Purely predictive theory’ (theory whose explanatory content is all background knowledge). Problem A problem exists when a conflict between ideas is ex - perienced. Good/bad explanation An explanation that is hard/easy to vary while still accounting for what it purports to account for. The Enlightenment (The beginning of) a way of pursuing knowledge with a tradition of criticism and seeking good explanations instead of reliance on authority. Mini-enlightenment A short-lived tradition of criticism. Rational Attempting to solve problems by seeking good explanations; actively pursuing error-correction by creating criticisms of both existing ideas and new proposals. The West The political, moral, economic and intellectual culture that has been growing around the Enlightenment values of science, reason and freedom. 31 the beginning of infinity meanings of ‘the beginning of infinity’ encountered in this chapter – The fact that some explanations have reach. – The universal reach of some explanations. – The Enlightenment. – A tradition of criticism. – Conjecture: the origin of all knowledge. – The discovery of how to make progress: science, the scientific revo- lution, seeking good explanations, and the political principles of the West. – Fallibilism. summary Appearances are deceptive. Yet we have a great deal of knowledge about the vast and unfamiliar reality that causes them, and of the elegant, universal laws that govern that reality. This knowledge consists of explanations: assertions about what is out there beyond the appear- ances, and how it behaves. For most of the history of our species, we had almost no success in creating such knowledge. Where does it come from? Empiricism said that we derive it from sensory experience. This is false. The real source of our theories is conjecture, and the real source of our knowledge is conjecture alternating with criticism. We create theories by rearranging, combining, altering and adding to existing ideas with the intention of improving upon them. The role of experiment and observation is to choose between existing theories, not to be the source of new ones. We interpret experiences through explanatory theories, but true explanations are not obvious. Fallibilism entails not looking to authorities but instead acknowledging that we may always be mistaken, and trying to correct errors. We do so by seeking good explanations – explanations that are hard to vary in the sense that changing the details would ruin the explanation. This, not experimental testing, was the decisive factor in the scientific revolution, and also in the unique, rapid, sustained progress in other fields that have partici- pated in the Enlightenment. That was a rebellion against authority which, unlike most such rebellions, tried not to seek authoritative 32 The Reach of Explanations justifications for theories, but instead set up a tradition of criticism. Some of the resulting ideas have enormous reach: they explain more than what they were originally designed to. The reach of an explanation is an intrinsic attribute of it, not an assumption that we make about it as empiricism and inductivism claim. Now I’ll say some more about appearance and reality, explanation and infinity. 33 2 Closer to Reality A galaxy is a mind-bogglingly huge thing. For that matter, a star is a mind-bogglingly huge thing. Our own planet is. A human brain is – in terms of both its internal complexity and the
================================================================================‘dark matter’ (see the next chapter) really exists – and it succeeded. If Edison, or those graduate students, or any scientific researcher engaged upon the ‘perspiration’ 36 Closer to Reality phase of discovery, had really been doing it mindlessly, they would be missing most of the fun – which is also what largely powers that ‘one per cent inspiration’. As I reached one particularly ambiguous image I asked my hosts, ‘Is that a galaxy or a star?’ ‘Neither,’ was the reply. ‘That’s just a defect in the photographic emulsion.’ The drastic mental gear change made me laugh. My grandiose speculations about the deep meaning of what I was seeing had turned out to be, in regard to this particular object, about nothing at all: suddenly there were no astronomers in that image, no rivers or earthquakes. They had disappeared in a puff of imagination. I had overestimated the mass of what I was looking at by some fifty powers of ten. What I had taken to be the largest object I had ever seen, and the most distant in space and time, was in reality just a speck barely visible without a microscope, within arm’s reach. How easily, and how thoroughly, one can be misled. But wait. Was I ever looking at a galaxy? All the other blobs were in fact microscopic smudges of silver too. If I misclassified the cause of one of them, because it looked too like the others, why was that such a big error? Because an error in experimental science is a mistake about the cause of something. Like an accurate observation, it is a matter of theory. Very little in nature is detectable by unaided human senses. Most of what happens is too fast or too slow, too big or too small, or too remote, or hidden behind opaque barriers, or operates on principles too differ- ent from anything that influenced our evolution. But in some cases we can arrange for such phenomena to become perceptible, via scientific instruments. We experience such instruments as bringing us closer to the reality – just as I felt while looking at that galactic cluster. But in purely physical terms they only ever separate us further from it. I could have looked up at the night sky in the direction of that cluster, and there would have been nothing between it and my eye but a few grams of air – but I would have seen nothing at all. I could have interposed a telescope, and then I might have seen it. In the event, I was interposing a telescope, a camera, a photographic development laboratory, another camera (to 37 the beginning of infinity make copies of the plates), a truck to bring the plates to my university, and a microscope. I could see the cluster far better with all that equipment in the way. Astronomers nowadays never look up at the sky (except perhaps in their spare time), and hardly ever look through telescopes. Many telescopes do not even have eyepieces suitable for a human eye. Many do not even detect visible light. Instead, instruments detect invisible signals which are then digitized, recorded, combined with others, and processed and analysed by computers. As a result, images may be produced – perhaps in ‘false colours’ to indicate radio waves or other radiation, or to display still more indirectly inferred attributes such as temperature or composition. In many cases, no image of the distant object is ever produced, only lists of numbers, or graphs and diagrams, and only the outcome of those processes affects the astronomers’ senses. Every additional layer of physical separation requires further levels of theory to relate the resulting perceptions to reality. When the astron- omer Jocelyn Bell discovered pulsars (extremely dense stars that emit regular bursts of radio waves), this is what she was looking at: Radio-telescope output from the first known pulsar Only through a sophisticated chain of theoretical interpretation could she ‘see’, by looking at that shaky line of ink on paper, a powerful, pulsating object in deep space, and recognize that it was of a hitherto unknown type. The better we come to understand phenomena remote from our everyday experience, the longer those chains of interpretation become, and every additional link necessitates more theory. A single unexpected 38 Closer to Reality or misunderstood phenomenon anywhere in the chain can, and often does, render the resulting sensory experience arbitrarily misleading. Yet, over time, the conclusions that science has drawn have become ever truer to reality. Its quest for good explanations corrects the errors, allows for the biases and misleading perspectives, and fills in the gaps. This is what we can achieve when, as Feynman said, we keep learning more about how not to fool ourselves. Telescopes contain automatic tracking mechanisms that continuously realign them so as to compensate for the effect of the Earth’s motion; in some, computers continuously change the shape of the mirror so as to compensate for the shimmering of the Earth’s atmosphere. And so, observed through such a telescope, stars do not appear to twinkle or to move across the sky as they did to generations of observers in the past. Those things are only appearance – parochial error. They have nothing to do with the reality of stars. The primary function of the telescope’s optics is to reduce the illusion that the stars are few, faint, twinkling and moving. The same is true of every feature of the telescope, and of all other scientific instruments: each layer of indirectness, through its associated theory, corrects errors, illusions, misleading perspectives and gaps. Perhaps it is the mistaken empiricist ideal of ‘pure’, theory-free observation that makes it seem odd that truly accurate observation is always so hugely indirect. But the fact is that progress requires the application of ever more knowledge in advance of our observations. So I was indeed looking at galaxies. Observing a galaxy via specks of silver is no different in that regard from observing a garden via
================================================================================of stars and planets in our night sky have no significance for human affairs. We know that we are not at the centre of the universe – it does not even have a geometrical centre. And we know that, although some of the titanic astrophysical phenomena that I have described played a significant role in our past, we have never been significant to them. We call a phenomenon significant (or fundamental) if parochial theories are inadequate to explain it, or if it appears in the explanation of many other phenomena; so it may seem that human beings and their wishes and actions are extremely insignificant in the universe at large. Anthropocentric misconceptions have also been overturned in every other fundamental area of science: our knowledge of physics is now expressed entirely in terms of entities that are as impersonal as Euclid’s points and lines, such as elementary particles, forces and spacetime – a four-dimensional continuum with three dimensions of space and one of time. Their effects on each other are explained not in terms of feelings and intentions, but through mathematical equations expressing laws of nature. In biology, it was once thought that living things must have been designed by a supernatural person, and that they must contain some special ingredient, a ‘vital principle’, to make them behave with apparent purposefulness. But biological science discovered new modes of explanation through such impersonal things as chemical reactions, genes and evolution. So we now know that living things, including humans, all consist of the same ingredients as rocks and stars, and obey the same laws, and that they were not designed by anyone. Modern science, far from explaining physical phenomena in terms of the thoughts and intentions of unseen people, considers our own thoughts and intentions to be aggregates of unseen (though not un - seeable) microscopic physical processes in our brains. So fruitful has this abandonment of anthropocentric theories been, and so important in the broader history of ideas, that anti-anthro- pocentrism has increasingly been elevated to the status of a universal principle, sometimes called the ‘Principle of Mediocrity’: there is 43 the beginning of infinity nothing significant about humans (in the cosmic scheme of things). As the physicist Stephen Hawking put it, humans are ‘just a chemical scum on the surface of a typical planet that’s in orbit round a typical star on the outskirts of a typical galaxy’. The proviso ‘in the cosmic scheme of things’ is necessary because the chemical scum evidently does have a special significance according to values that it applies to itself, such as moral values. But the Principle says that all such values are them- selves anthropocentric: they explain only the behaviour of the scum, which is itself insignificant. It is easy to mistake quirks of one’s own, familiar environment or perspective (such as the rotation of the night sky) for objective features of what one is observing, or to mistake rules of thumb (such as the prediction of daily sunrises) for universal laws. I shall refer to that sort of error as parochialism. Anthropocentric errors are examples of parochialism, but not all parochialism is anthropocentric. For instance, the prediction that the seasons are in phase all over the world is a parochial error but not an anthropocentric one: it does not involve explaining seasons in terms of people. Another influential idea about the human condition is sometimes given the dramatic name Spaceship Earth. Imagine a ‘generation ship’ – a spaceship on a journey so long that many generations of passengers live out their lives in transit. This has been proposed as a means of colonizing other star systems. In the Spaceship Earth idea, that generation ship is a metaphor for the biosphere – the system of all living things on Earth and the regions they inhabit. Its passengers represent all humans on Earth. Outside the spaceship, the universe is implacably hostile, but the interior is a vastly complex life-support system, capable of providing everything that the passengers need to thrive. Like the spaceship, the biosphere recycles all waste and, using its capacious nuclear power plant (the sun), it is completely self-sufficient. Just as the spaceship’s life-support system is designed to sustain its passengers, so the biosphere has the ‘appearance of design’: it seems highly adapted to sustaining us (claims the metaphor) because we were adapted to it by evolution. But its capacity is finite: if we overload it, either by our sheer numbers or by adopting lifestyles too different from 44 The Spark those that we evolved to live (the ones that it is ‘designed’ to support), it will break down. And, like the passengers on that spaceship, we get no second chances: if our lifestyle becomes too careless or profligate and we ruin our life-support system, we have nowhere else to go. The Spaceship Earth metaphor and the Principle of Mediocrity have both gained wide acceptance among scientifically minded people – to the extent of becoming truisms. This is despite the fact that, on the face of it, they argue in somewhat opposite directions: the Principle of Mediocrity stresses how typical the Earth and its chemical scum are (in the sense of being unremarkable), while Spaceship Earth stresses how untypical they are (in the sense of being uniquely suited to each other). But when the two ideas are interpreted in broad, philosophical ways, as they usually are, they can easily converge. Both see themselves as correcting much the same parochial misconceptions, namely that our experience of life on Earth is representative of the universe, and that the Earth is vast, fixed and permanent. They both stress instead that it is tiny and ephemeral. Both oppose arrogance: the Principle of Mediocrity opposes the pre-Enlightenment arrogance of believing ourselves significant in the world; the Spaceship Earth metaphor opposes the Enlightenment arrogance of aspiring to control the world. Both have a moral element: we should not consider ourselves signifi- cant, they assert; we should not expect the world to submit indefinitely to our depredations. Thus
================================================================================through knowledge of things like tools, farming and hygiene. The Earth did provide the raw materials for our survival – just as the sun has provided the energy, and supernovae provided the elements, and so on. But a heap of raw materials is not the same thing as a life-support system. It takes knowledge to convert the one into the other, and biological evolution never provided us with enough knowledge to survive, let alone to thrive. In this respect we differ from almost all other species. They do have all the knowledge that they need, genetically encoded in their brains. And that knowledge was indeed provided for them by evolution – and so, in the relevant sense, ‘by the biosphere’. So their home environments do have the appearance of having been designed as life-support systems for them, albeit only in the desperately limited sense that I have described. But the biosphere no more provides humans with a life-support system than it provides us with radio telescopes. So the biosphere is incapable of supporting human life. From the outset, it was only human knowledge that made the planet even marginally habitable by humans, and the enormously increased capacity of our life-support system since then (in terms both of numbers and of security and quality of life) has been entirely due to the creation of 50 The Spark human knowledge. To the extent that we are on a ‘spaceship’, we have never been merely its passengers, nor (as is often said) its stewards, nor even its maintenance crew: we are its designers and builders. Before the designs created by humans, it was not a vehicle, but only a heap of dangerous raw materials. The ‘passengers’ metaphor is a misconception in another sense too. It implies that there was a time when humans lived unproblematically: when they were provided for, like pas sengers, without themselves having to solve a stream of problems in order to survive and to thrive. But in fact, even with the benefit of their cultural knowledge, our ancestors continually faced desperate problems, such as where the next meal was coming from, and typically they barely solved these problems or they died. There are very few fossils of old people. The moral component of the Spaceship Earth metaphor is therefore somewhat paradoxical. It casts humans as ungrateful for gifts which, in reality, they never received. And it casts all other species in morally positive roles in the spaceship’s life-support system, with humans as the only negative actors. But humans are part of the biosphere, and the supposedly immoral behaviour is identical to what all other species do when times are good – except that humans alone try to mitigate the effect of that response on their descendants and on other species. The Principle of Mediocrity is paradoxical too. Since it singles out anthropocentrism for special opprobrium among all forms of parochial misconception, it is itself anthropocentric. Also, it claims that all value judgements are anthropocentric, yet it itself is often expressed in value- laden terminology, such as ‘arrogance’, ‘just scum’ and the very word ‘mediocrity’. With respect to whose values are those disparagements to be understood? Why is arrogance even relevant as a criticism? Also, even if holding an arrogant opinion is morally wrong, morality is supposed to refer only to the internal organization of chemical scum. So how can it tell us anything about how the world beyond the scum is organized, as the Principle of Mediocrity purports to do? In any case, it was not arrogance that made people adopt anthro- pocentric explanations. It was merely a parochial error, and quite a reasonable one originally. Nor was it arrogance that prevented people from realizing their mistake for so long: they didn’t realize anything, because they did not know how to seek better explanations. In a sense 51 the beginning of infinity their whole problem was that they were not arrogant enough: they assumed far too easily that the world was fundamentally incompre- hensible to them. The misconception that there was once an unproblematic era for humans is present in ancient myths of a past Golden Age, and of a Garden of Eden. The theological notions of grace (unearned benefit from God) and Providence (which is God regarded as the provider of human needs) are also related to this. In order to connect the supposed unproblematic past with their own less-than-pleasant experiences, the authors of such myths had to include some past transition, such as a Fall from Grace when Providence reduced its level of support. In the Spaceship Earth metaphor, the Fall from Grace is usually deemed to be imminent or under way. The Principle of Mediocrity contains a similar misconception. Consider the following argument, which is due to the evolutionary biologist Richard Dawkins: Human attributes, like those of all other organisms, evolved under natural selection in an ancestral environment. That is why our senses are adapted to detecting things like the colours and smell of fruit, or the sound of a predator: being able to detect such things gave our ancestors a better chance of surviving to have offspring. But, for the same reason, Dawkins points out, evolution did not waste our resources on detecting phenomena that were never relevant to our survival. We cannot, for instance, distinguish between the colours of most stars with the naked eye. Our night vision is poor and monochromatic because not enough of our ancestors died of that limitation to create evolutionary pressure for anything better. So Dawkins argues – and here he is invoking the Principle of Mediocrity – that there is no reason to expect our brains to be any different from our eyes in this regard: they evolved to cope with the narrow class of phenomena that commonly occur in the bio - sphere, on approximately human scales of size, time, energy and so on. Most phenomena in the universe happen far above or below those scales. Some would kill us instantly; others could never affect anything in
================================================================================genes, but on whether we could discover how to build robots, or gloves, with two thumbs per hand, or alter ourselves to have a second thumb. If it depends on having more memory capacity, or speed, than a human brain, then the outcome would depend on whether we could build computers to do the job. Again, such things are already commonplace in technology. The astrophysicist Martin Rees has speculated that somewhere in the universe ‘there could be life and intelligence out there in forms we can’t conceive. Just as a chimpanzee can’t understand quantum theory, it could be there are aspects of reality that are beyond the capacity of our brains.’ But that cannot be so. For if the ‘capacity’ in question is mere computational speed and amount of memory, then we can understand the aspects in question with the help of computers – just as we have understood the world for centuries with the help of pencil and paper. As Einstein remarked, ‘My pencil and I are more clever than I.’ In terms of computational repertoire, our computers – and brains – are already universal (see Chapter 6). But if the claim is that we may be qualitatively unable to understand what some other forms of intelligence can – if our disability cannot be remedied by mere auto- mation – then this is just another claim that the world is not explicable. Indeed, it is tantamount to an appeal to the supernatural, with all the arbitrariness that is inherent in such appeals, for if we wanted to incorporate into our world view an imaginary realm explicable only to superhumans, we need never have bothered to abandon the myths of Persephone and her fellow deities. So human reach is essentially the same as the reach of explanatory knowledge itself. An environment is within human reach if it is possible to create an open-ended stream of explanatory knowledge there. That means that if knowledge of a suitable kind were instantiated in such 60 The Spark an environment in suitable physical objects, it would cause itself to survive and would then continue to increase indefinitely. Can there really be such an environment? This is essentially the question that I asked at the end of the last chapter – can this creativity continue indefinitely? – and it is the question to which the Spaceship Earth metaphor assumes a negative answer. The issue comes down to this: if such an environment can exist, what are the minimal physical features that it must have? Access to matter is one. For example, the trick of extracting oxygen from moon rocks depends on having compounds of oxygen available. With more advanced technology, one could manufacture oxygen by transmutation; but, no matter how advanced one’s technology is, one still needs raw materials of some sort. And, although mass can be recycled, creating an open-ended stream of knowledge depends on having an ongoing supply of it, both to make up for inevitable inefficiencies and to make the additional memory capacity to store new knowledge as it is created. Also, many of the necessary transformations require energy: some- thing must power conjectures and scientific experiments and all those manufacturing processes; and, again, the laws of physics forbid the creation of energy from nothing. So access to an energy supply is also a necessity. To some extent, energy and mass can be transformed into each other. For instance, transmuting hydrogen into any other element releases energy through nuclear fusion. Energy can also be converted into mass by various subatomic processes (but I cannot imagine naturally occurring circumstances in which those would be the best way of obtaining matter). In addition to matter and energy, there is one other essential require- ment, namely evidence: the information needed to test scientific theories. The Earth’s surface is rich in evidence. We happened to get round to testing Newton’s laws in the seventeenth century, and Einstein’s in the twentieth, but the evidence with which we did that – light from the sky – had been deluging the surface of the Earth for billions of years before that, and will continue to do so for billions more. Even today we have barely begun to examine that evidence: on any clear night, the chances are that your roof will be struck by evidence falling from the sky which, if you only knew what to look for and how, would win you a Nobel prize. In chemistry, every stable element that exists 61 the beginning of infinity anywhere is also present on or just below the Earth’s surface. In biology, copious evidence of the nature of life is ubiquitous in the biosphere – and within arm’s reach, in our own DNA. As far as we know, all the fundamental constants of nature can be measured here, and every fundamental law can be tested here. Everything needed for the open-ended creation of knowledge is here in abundance, in the Earth’s biosphere. And the same is true of the moon. It has essentially the same resources of mass, energy and evidence as the Earth has. Parochial details differ, but the fact that humans living on the moon will have to make their own air is no more significant than the fact that laboratories on Earth have to make their own vacuum. Both tasks can be automated so as to require arbitrarily little human effort or attention. Likewise, because humans are universal constructors, every problem of finding or trans- form i ng resources can be no more than a transient factor limiting the creation of knowledge in a given environment. And therefore matter, energy and evidence are the only requirements that an environment needs to have in order to be a venue for open-ended knowledge creation. Though any particular problem is a transient factor, the condition of having to solve problems in order to survive and continue to create knowledge is permanent. I have mentioned that there has never been an unproblematic time for humans; that applies as much to the
================================================================================other biochemical molecules could be synthesized and experimented on. And, although 67 the beginning of infinity biology field trips would be difficult (because the closest natural eco - system would be millions of light years away), arbitrary life forms could be created and studied in artificial ecosystems, or in virtual-reality simulations of them. As for astronomy – the sky there is pitch black to the human eye, but to an observer with a telescope, even one of present-day design, it would be packed with galaxies. A somewhat bigger telescope could see stars in those galaxies in sufficient detail to test most of our present-day theories of astrophysics and cosmology. Even aside from those billion tonnes of matter, the cube is not empty. It is full of faint light, and the amount of evidence in that light is staggering: enough to construct a map of every star, planet and moon in all the nearest galaxies to a resolution of about ten kilometres. To extract that evidence in full, the telescope would need to use something like a mirror of the same width as the cube itself, which would require at least as much matter as building a planet. But even that would not be beyond the bounds of possibility, given the level of technology we are considering. To gather that much matter, those intergalactic scientists would merely have to trawl out to a distance of a few thousand cube-widths – still a piffling distance by intergalactic stand- ards. But even with a mere million-tonne telescope they could do a lot of astronomy. The fact that planets with tilted axes have annual seasons would be plain to see. They could detect life if it was present on any of the planets, via the composition of its atmosphere. With more subtle measurements they could test theories about the nature and history of life – or intelligence – on the planet. At any instant, a typical cube contains evidence, at that level of detail, about more than a trillion stars and their planets, simultaneously. And that is only one instant. Additional evidence of all those kinds is pouring into the cube all the time, so astronomers there could track changes in the sky just as we do. And visible light is only one band of the electromagnetic spectrum. The cube is receiving evidence in every other band too – gamma rays, X-rays, all the way down to the micro- wave background radiation and radio waves, as well as a few cosmic- ray particles. In short, nearly all the channels by which we on Earth currently receive evidence about any of the fundamental sciences are available in intergalactic space too. And they carry much the same content: not only is the universe full 68 The Spark of evidence, it is full of the same evidence everywhere. All people in the universe, once they have understood enough to free themselves from parochial obstacles, face essentially the same opportunities.This is an underlying unity in the physical world more significant than all the dissimilarities I have described between our environment and a typical one: the fundamental laws of nature are so uniform, and evidence about them so ubiquitous, and the connections between understanding and control so intimate, that, whether we are on our parochial home planet or a hundred million light years away in the intergalactic plasma, we can do the same science and make the same progress. So a typical location in the universe is amenable to the open-ended creation of knowledge. And therefore so are almost all other kinds of environment, since they have more matter, more energy and easier access to evidence than intergalactic space. The thought experiment considered almost the worst possible case. Perhaps the laws of physics do not allow knowledge-creation inside, say, the jet of a quasar. Or perhaps they do. But either way, in the universe at large, knowledge- friendliness is the rule, not the exception. That is to say, the rule is person-friendliness to people who have the relevant knowledge. Death is the rule for those who do not. These are the same rules that prevailed in the Great Rift Valley from whence we came, and have prevailed ever since. Oddly enough, that quixotic space station in our thought experiment is none other than the ‘generation ship’ in the Spaceship Earth metaphor – except that we have removed the unrealistic assumption that the inhabitants never improve it. Hence presumably they have long since solved the problem of how to avoid dying, and so ‘generations’ are no longer essential to the way their ship works. In any case, with hindsight, a generation ship was a poor choice for dramatizing the claim that the human condition is fragile and dependent on support from an unaltered biosphere, for that claim is contradicted by the very possibility of such a spaceship. If it is possible to live indefinitely in a spaceship in space, then it would be much more possible to use the same technology to live on the surface of the Earth – and to make continuing progress which would make it ever easier. It would make little practical difference whether the biosphere had been ruined or not. Whether or not it could 69 the beginning of infinity support any other species, it could certainly accommodate people – including humans – if they had the right knowledge. Now I can turn to the significance of knowledge – and therefore of people – in the cosmic scheme of things. Many things are more obviously significant than people. Space and time are significant because they appear in almost all explanations of other physical phenomena. Similarly, electrons and atoms are signifi- cant. Humans seem to have no place in that exalted company. Our history and politics, our science, art and philosophy, our aspirations and moral values – all these are tiny side effects of a supernova ex - plosion a few billion years ago, which could be extinguished tomorrow by another such explosion. Supernovae, too, are
================================================================================moderately significant in the cosmic scheme of things. But it seems that one can explain everything about supernovae, and almost everything else, without ever mentioning people or knowledge at all. However, that is merely another parochial error, due to our current, untypical, vantage point in an Enlightenment that is mere centuries old. In the longer run, humans may colonize other solar systems and, by increasing their knowledge, control ever more powerful physical processes. If people ever choose to live near a star that is capable of exploding, they may well wish to prevent such an explosion – probably by removing some of the material from the star. Such a project would use many orders of magnitude more energy than humans currently control, and more advanced technology as well. But it is a fundament- ally simple task, not requiring any steps that are even close to limits imposed by the laws of physics. So, with the right knowledge, it could be achieved. Indeed, for all we know, engineers elsewhere in the universe are already achieving it routinely. And consequently it is not true that the attributes of supernovae in general are independent of the presence or absence of people, or of what those people know and intend. More generally, if we want to predict what a star will do, we first have to guess whether there are any people near it, and, if so, what knowledge they may have and what they may want to achieve. Outside our parochial perspective, astrophysics is incomplete without a theory of people, just as it is incomplete without a theory of gravity or nuclear reactions. Note that this conclusion does not depend on the assumption that humans, or anyone, will colonize the galaxy and take control of 70 The Spark any supernovae: the assumption that they will not is equally a theory about the future behaviour of knowledge. Knowledge is a significant phenomenon in the universe, because to make almost any prediction about astrophysics one must take a position about what types of knowledge will or will not be present near the phenomena in question. So all explanations of what is out there in the physical world mention knowledge and people, if only implicitly. But knowledge is more significant even than that. Consider any physical object – for instance, a solar system, or a microscopic chip of silicon – and then consider all the transformations that it is physically possible for it to undergo. For instance, the silicon chip might be melted and solidify in a different shape, or be transformed into a chip with different functionality. The solar system might be devastated when its star becomes a supernova, or life might evolve on one of its planets, or it might be transformed, using transmutation and other futuristic technologies, into microprocessors. In all cases, the class of transform- ations that could happen spontaneously – in the absence of knowledge – is negligibly small compared with the class that could be effected artificially by intelligent beings who wanted those transformations to happen. So the explanations of almost all physically possible phenomena are about how knowledge would be applied to bring these phenomena about. If you want to explain how an object might possibly reach a temperature of ten degrees or a million, you can refer to spontaneous processes and can avoid mentioning people explicitly (even though most processes at those temperatures can be brought about only by people). But if you want to explain how an object might possibly cool down to a millionth of a degree above absolute zero, you cannot avoid explaining in detail what people would do. And that is still only the least of it. In your mind’s eye, continue your journey from that point in intergalactic space to another, at least ten times as far away. Our destination this time is inside one of the jets of a quasar. What would it be like in one of those jets? Language is barely capable of expressing it: it would be rather like facing a supernova explosion at point-blank range, but for millions of years at a time. The survival time for a human body would be measured in picoseconds. As I said, it is unclear whether the laws of physics permit any knowledge to grow there, let alone a life-support system for humans. It is about 71 the beginning of infinity as different from our ancestral environment as it could possibly be. The laws of physics that explain it bear no resemblance to any rules of thumb that were ever in our ancestors’ genes or in their culture. Yet human brains today know in considerable detail what is happening there. Somehow that jet happens in such a way that billions of years later, on the other side of the universe, a chemical scum can know and predict what the jet will do, and can understand why. That means that one physical system – say, an astrophysicist’s brain – contains an accurate working model of the other, the jet. Not just a superficial image (though it contains that as well), but an explanatory theory that embodies the same mathematical relationships and causal structure. That is scientific knowledge. Furthermore, the faithfulness with which the one structure resembles the other is steadily increasing. That constitutes the creation of knowledge. Here we have physical objects very unlike each other, and whose behaviour is dominated by different laws of physics, embodying the same mathematical and causal structures – and doing so ever more accurately over time. Of all the physical processes that can occur in nature, only the creation of knowledge exhibits that underlying unity. In Arecibo, Puerto Rico, there is a giant radio telescope, one of whose many uses is in the Search For Extraterrestrial Intelligence (SETI). In an office in a building near the telescope there is a small domestic refrigerator. Inside that refrigerator is a bottle of champagne, sealed by a cork. Consider that cork. It is going to be removed from the bottle
================================================================================genes that spread best through the population. Evolution can even favour genes that are not just suboptimal, but wholly harmful to the species and all its individuals. A famous example is the peacock’s large, colourful tail, which is believed to diminish the bird’s viability by making it harder to evade predators, and to have no useful function at all. Genes for prominent tails dominate simply because peahens tend to choose prominent-tailed males as mates. Why was there selection pressure in favour of such preferences? One reason is that, when females mated with prominent-tailed males, their male offspring, having more prominent tails, found more mates. Another may be that an individual able to grow a large, colourful tail is more 91 the beginning of infinity likely to be healthy. In any case, the net effect of all the selection pressures was to spread genes for large, colourful tails, and genes for preferring such tails, through the population. The species and the individuals just had to suffer the consequences. If the best-spreading genes impose sufficiently large disadvantages on the species, the species becomes extinct. Nothing in biological evolution prevents that. It has presumably happened many times in the history of life on Earth, to species less lucky than the peacock. Dawkins named his tour-de-force account of neo-Darwinism The Selfish Gene because he wanted to stress that evolution does not especially promote the ‘welfare’ of species or individual organisms. But, as he also explained, it does not promote the ‘welfare’ of genes either: it adapts them not for survival in larger numbers, nor indeed for survival at all, but only for spreading through the population at the expense of rival genes, particularly slight variants of themselves. Is it sheer luck, then, that most genes do usually confer some, albeit less than optimal, functional benefits on their species, and on their individual holders? No. Organisms are the slaves, or tools, that genes use to achieve their ‘purpose’ of spreading themselves through the population. (That is the ‘purpose’ that Paley and even Darwin never guessed.) Genes gain advantages over each other in part by keeping their slaves alive and healthy, just as human slave owners did. Slave owners were not working for the benefit of their workforces, nor for the benefit of individual slaves: it was solely to achieve their own objectives that they fed and housed their slaves, and indeed forced them to reproduce. Genes do much the same thing. In addition, there is the phenomenon of reach: when the knowledge in a gene happens to have reach, it will help the individual to help itself in a wider range of circumstances, and by more, than the spreading of the gene strictly requires. That is why mules stay alive even though they are sterile. So it is not surprising that genes usually confer some benefits on their species and its members, and do often succeed in increasing their own absolute numbers. Nor should it be surprising that they sometimes do the opposite. But what genes are adapted to – what they do better than almost any variant of themselves – has nothing to do with the species or the individuals or even their own survival in the long run. It is getting themselves replicated more than rival genes. 92 Creation Neo-Darwinism and knowledge Neo-Darwinism does not refer, at its fundamental level, to anything biological. It is based on the idea of a replicator (anything that contributes causally to its own copying).* For instance, a gene conferring the ability to digest a certain type of food causes the organism to remain healthy in some situations where it would otherwise weaken or die. Hence it increases the organism’s chances of having offspring in the future, and those offspring would inherit, and spread, copies of the gene. Ideas can be replicators too. For example, a good joke is a replicator: when lodged in a person’s mind, it has a tendency to cause that person to tell it to other people, thus copying it into their minds. Dawkins coined the term memes (rhymes with ‘dreams’) for ideas that are replicators. Most ideas are not replicators: they do not cause us to convey them to other people. Nearly all long-lasting ideas, however, such as languages, scientific theories and religious beliefs, and the ineffable states of mind that constitute cultures such as being British, or the skill of performing classical music, are memes (or ‘memeplexes’ – collections of interacting memes). I shall say more about memes in Chapter 15. The most general way of stating the central assertion of the neo- Darwinian theory of evolution is that a population of replicators subject to variation (for instance by imperfect copying) will be taken over by those variants that are better than their rivals at causing themselves to be replicated. This is a surprisingly deep truth which is commonly criticized either for being too obvious to be worth stating or for being false. The reason, I think, is that, although it is self-evidently true, it is not self-evidently the explanation of specific adaptations. Our intuition prefers explanations in terms of function or purpose: what does a gene do for its holder, or for its species? But we have just seen that the genes generally do not optimize such functionality. So the knowledge embodied in genes is knowledge of how to get themselves replicated at the expense of their rivals. Genes often do this by imparting useful functionality to their organism, and in those cases *This terminology differs slightly from that of Dawkins. Anything that is copied, for whatever reason, he calls a replicator. What I call a replicator he calls an ‘active replicator’. 93 the beginning of infinity their knowledge incidentally includes knowledge about that functionality. Functionality, in turn, is achieved by encoding, into genes, regularities in the environment and sometimes even rule-of-thumb approximations to laws of nature, in which case the genes are incidentally encoding that knowledge too. But the core of the explanation for the presence of a gene is
================================================================================Fine-tuning The physicist Brandon Carter calculated in 1974 that if the strength of the interaction between charged particles were a few per cent smaller, no planets would ever have formed and the only condensed objects in the universe would be stars; and if it were a few per cent greater, then no stars would ever explode, and so no elements other than hydrogen and helium would exist outside them. In either case there would be no complex chemistry and hence presumably no life. Another example: if the initial expansion rate of the universe at the Big Bang had been slightly higher, no stars would have formed and there would be nothing in the universe but hydrogen – at an extremely low and ever-decreasing density. If it had been slightly lower, the 96 Creation universe would have recollapsed soon after the Big Bang. Similar results have been since obtained for other constants of physics that are not determined by any known theory. For most, if not all of them, it seems that if they had been slightly different, there would have been no possibility for life to exist. This is a remarkable fact which has even been cited as evidence that those constants were intentionally fine-tuned, i.e. designed, by a super- natural being. This is a new version of creationism, and of the design argument, now based on the appearance of design in the laws of physics. (Ironically, given the history of this controversy, the new argument is that the laws of physics must have been designed to create a biosphere by Darwinian evolution.) It even persuaded the philosopher Antony Flew – formerly an enthusiastic advocate of atheism – of the existence of a supernatural designer. But it should not have. As I shall explain in a moment, it is not even clear that this fine-tuning constitutes an appearance of design in Paley’s sense; but, even if it does, that does not alter the fact that invoking the supernatural makes for a bad explanation. And, in any case, arguing for supernatural explanations on the grounds that a current scientific explanation is flawed or lacking is just a mistake. As we carved in stone in Chapter 3, problems are inevitable – there are always unsolved problems. But they get solved. Science continues to make progress even, or especially, after making great discoveries, because the discoveries themselves reveal further problems. Therefore the existence of an unsolved problem in physics is no more evidence for a supernatural explanation than the existence of an unsolved crime is evidence that a ghost committed it. A simple objection to the idea that fine-tuning requires an explanation at all is that we have no good explanation implying that planets are essential to the formation of life, or that chemistry is. The physicist Robert Forward wrote a superb science-fiction story, Dragon’s Egg, based on the premise that information could be stored and processed – and life and intelligence could evolve – through the interactions between neutrons on the surface of a neutron star (a star that has collapsed gravitationally to a diameter of only a few kilometres, making it so dense that most of its matter has been transmuted into neutrons). It is not known whether this hypothetical neutron analogue of chemistry exists – nor whether it could exist if the laws of physics were slightly 97 the beginning of infinity different. Nor do we have any idea what other sorts of environment permitting the emergence of life would exist under those variant laws. (The idea that similar laws of physics can be expected to give rise to similar environments is undermined by the very existence of fine-tuning.) Nevertheless, regardless of whether the fine-tuning constitutes an appearance of design or not, it does constitute a legitimate and significant scientific problem, for the following reason. If the truth is that the constants of nature are not fine-tuned to produce life after all, because most slight variations in them do still permit life and intelligence to evolve somehow, though in dramatically different types of environment, then this would be an unexplained regularity in nature and hence a problem for science to address. If the laws of physics are fine-tuned, as they seem to be, then there are two possibilities: either those laws are the only ones to be instantiated in reality (as universes) or there are other regions of reality – parallel universes* – with different laws. In the former case, we must expect there to be an explanation of why the laws are as they are. It would either refer to the existence of life or not. If it did, that would take us back to Paley’s problem: it would mean that the laws had the ‘appearance of design’ for creating life, but had not evolved. Or the explanation would not refer to the existence of life, in which case it would leave unexplained why, if the laws are as they are for non-life- related reasons, they are fine-tuned to create life. If there are many parallel universes, each with its own laws of physics, most of which do not permit life, then the idea would be that the observed fine-tuning is only a matter of parochial perspective. It is only in the universes that contain astrophysicists that anyone ever wonders why the constants seem fine-tuned. This type of explanation is known as ‘anthropic reasoning’. It is said to follow from a principle known as the ‘weak anthropic principle’, though really no principle is required: it is just logic. (The qualifier ‘weak’ is there because several other anthropic principles have been proposed, which are more than just logic, but they need not concern us here.) *These are not the ‘parallel universes’ of the quantum multiverse, which I shall describe in Chapter 11. Those universes all obey the same laws of physics and are in constant slight interaction with each other. They are also much less speculative. 98 Creation However, on closer examination, anthropic arguments never quite finish the explanatory job.
================================================================================sort of explanation is essential in understanding certain phenomena. In his book I am a Strange Loop (2007) he imagines a special-purpose computer built of millions of dominoes. They are set up – as dominoes often are for fun – standing on end, close together, so that if one of them is knocked over it strikes its neighbour and so a whole stretch of dominoes falls, one after another. But Hofstadter’s dominoes are spring- loaded in such a way that, whenever one is knocked over, it pops back up after a fixed time. Hence, when a domino falls, a wave or ‘signal’ of falling dominoes propagates along the stretch in the direction in which it fell until it reaches either a dead end or a currently fallen domino. By arranging these dominoes in a network with looping, bifurcating and rejoining stretches, one can make these signals combine and interact in a sufficiently rich repertoire of ways to make the whole construction into a computer: a signal travelling down a stretch can be interpreted as a binary ‘1’, and the lack of a signal as a binary ‘0’, and the interactions between such signals can implement a repertoire of operations – such as ‘and’, ‘or’ and ‘not’ – out of which arbitrary computations can be composed. One domino is designated as the ‘on switch’: when it is knocked over, the domino computer begins to execute the program that is instantiated in its loops and stretches. The program in Hofstadter’s thought experiment computes whether a given number is a prime or not. One inputs that number by placing a stretch of exactly that many dominos at a specified position, before tripping the ‘on switch’. Else- where in the network, a particular domino will deliver the output of the computation: it will fall only if a divisor is found, indicating that the input was not a prime. Hofstadter sets the input to the number 641, which is a prime, and trips the ‘on switch’. Flurries of motion begin to sweep back and forth across the network. All 641 of the input dominos soon fall as the 115 the beginning of infinity computation ‘reads’ its input – and snap back up and participate in further intricate patterns. It is a lengthy process, because this is a rather inefficient way to perform computations – but it does the job. Now Hofstadter imagines that an observer who does not know the purpose of the domino network watches the dominoes performing and notices that one particular domino remains resolutely standing, never affected by any of the waves of downs and ups sweeping by. The observer points at [that domino] and asks with curiosity, ‘How come that domino there is never falling?’ We know that it is the output domino, but the observer does not. Hofstadter continues: Let me contrast two different types of answer that someone might give. The first type of answer – myopic to the point of silliness – would be, ‘Because its predecessor never falls, you dummy!’ Or, if it has two or more neighbours, ‘Because none of its neighbours ever fall.’ To be sure, this is correct as far as it goes, but it doesn’t go very far. It just passes the buck to a different domino. In fact one could keep passing the buck from domino to domino, to provide ever more detailed answers that were ‘silly, but correct as far as they go’. Eventually, after one had passed the buck billions of times (many more times than there are dominoes, because the program ‘loops’), one would arrive at that first domino – the ‘on switch’. At that point, the reductive (to high-level physics) explanation would be, in summary, ‘That domino did not fall because none of the patterns of motion initiated by knocking over the “on switch” ever include it.’ But we knew that already. We can reach that conclusion – as we just have – without going through that laborious process. And it is undeniably true. But it is not the explanation we were looking for because it is addressing a different question – predictive rather than explanatory – namely, if the first domino falls, will the output domino ever fall? And it is asking at the wrong level of emergence. What we asked was: why does it not fall? To answer that, Hofstadter then adopts 116 The Reality of Abstractions a different mode of explanation, at the right level of emergence: The second type of answer would be, ‘Because 641 is prime.’ Now this answer, while just as correct (indeed, in some sense it is far more on the mark), has the curious property of not talking about anything physical at all. Not only has the focus moved upwards to collective properties . . . these properties somehow transcend the physical and have to do with pure abstractions, such as primality. Hofstadter concludes, ‘The point of this example is that 641’s primality is the best explanation, perhaps even the only explanation, for why certain dominoes did fall and certain others did not fall.’ Just to correct that slightly: the physics-based explanation is true as well, and the physics of the dominoes is also essential to explaining why prime numbers are relevant to that particular arrangement of them. But Hofstadter’s argument does show that primality must be part of any full explanation of why the dominos did or did not fall. Hence it is a refutation of reductionism in regard to abstractions. For the theory of prime numbers is not part of physics. It refers not to physical objects, but to abstract entities – such as numbers, of which there is an infinite set. Unfortunately, Hofstadter goes on to disown his own argument and to embrace reductionism. Why? His book is primarily about one particular emergent phenomenon, the mind – or, as he puts it, the ‘I’. He asks whether the mind can consistently be thought of as affecting the body – causing it to do one thing rather than
================================================================================another, given the all-embracing nature of the laws of physics. This is known as the mind–body problem. For instance, we often explain our actions in terms of choosing one action rather than another, but our bodies, including our brains, are completely controlled by the laws of physics, leaving no physical variable free for an ‘I’ to affect in order to make such a choice. Following the philosopher Daniel Dennett, Hofstadter eventually concludes that the ‘I’ is an illusion. Minds, he concludes, can’t ‘push material stuff around’, bec ause ‘physical law alone would suffice to determine [its] behaviour’. Hence his reductionism. But, first of all, physical laws can’t push anything either. They only explain and predict. And they are not our only explanations. The theory 117 the beginning of infinity that the domino stands ‘because 641 is a prime (and because the domino network instantiates a primality-testing algorithm)’ is an exceedingly good explanation. What is wrong with it? It does not contradict the laws of physics. It explains more than any explanation purely in terms of those laws. And no known variant of it can do the same job. Second, that reductionist argument would equally deny that an atom can ‘push’ (in the sense of ‘cause to move’) another atom, since the initial state of the universe, together with the laws of motion, has already determined the state at every other time. Third, the very idea of a cause is emergent and abstract. It is mentioned nowhere in the laws of motion of elementary particles, and, as the philosopher David Hume pointed out, we cannot perceive causation, only a succession of events. Also, the laws of motion are ‘conservative’ – that is to say, they do not lose information. That means that, just as they determine the final state of any motion given the initial state, they also determine the initial state given the final state, and the state at any time from the state at any other time. So, at that level of explanation, cause and effect are interchangeable – and are not what we mean when we say that a program causes a computer to win at chess, or that a domino remained standing because 641 is a prime. There is no inconsistency in having multiple explanations of the same phenomenon, at different levels of emergence. Regarding micro- physical explanations as more fundamental than emergent ones is arbitrary and fallacious. There is no escape from Hofstadter’s 641 argument, and no reason to want one. The world may or may not be as we wish it to be, and to reject good explanations on that account is to imprison oneself in parochial error. So the answer ‘Because 641 is a prime’ does explain the immunity of that domino. The theory of prime numbers on which that answer depends is not a law of physics, nor an approximation to one. It is about abstractions, and infinite sets of them at that (such as the set of ‘natural numbers’ 1, 2, 3, . . . , where the ellipsis ‘ . . . ’ denotes continuation ad infinitum). It is no mystery how we can have knowledge of infinitely large things, like the set of all natural numbers. That is just a matter of reach. Versions of number theory that confined themselves to ‘small natural numbers’ would have to be so full of arbitrary qualifiers, 118 The Reality of Abstractions workarounds and unanswered questions that they would be very bad explanations until they were generalized to the case that makes sense without such ad-hoc restrictions: the infinite case. I shall discuss various sorts of infinity in Chapter 8. When we use theories about emergent physical quantities to explain the behaviour of water in a kettle, we are using an abstraction – an ‘idealized’ model of the kettle that ignores most of its details – as an approximation to a real physical system. But when we use a computer to investigate prime numbers, we are doing the reverse: we are using the physical computer as an approximation to an abstract one which perfectly models prime numbers. Unlike any real computer, the latter never goes wrong, requires no maintenance, and has unlimited memory and unlimited time to run its program. Our own brains are, likewise, computers which we can use to learn about things beyond the physical world, including pure mathematical abstractions. This ability to understand abstractions is an emergent property of people which greatly puzzled the ancient Athenian philo- sopher Plato. He noticed that the theorems of geometry – such as Pythagoras’ theorem – are about entities that are never experienced: perfectly straight lines with no thickness, intersecting each other on a perfect plane to make a perfect triangle. These are not possible objects of any observation. And yet people knew about them – and not just superficially: at the time, such knowledge was the deepest knowledge, of anything, that human beings had ever had. Where did it come from? Plato concluded that it – and all human knowledge – must come from the supernatural. He was right that it could not have come from observation. But then it could not have even if people had been able to observe perfect triangles (as arguably they could today, using virtual reality). As I explained in Chapter 1, empiricism has multiple fatal flaws. But it is no mystery where our knowledge of abstractions comes from: it comes from conjecture, like all our knowledge, and through criticism and seeking good explanations. It is only empiricism that made it seem plausible that knowledge outside science is inaccessible; and it is only the justified-true-belief misconception that makes such knowledge seem less ‘justified’ than scientific theories. As I explained in Chapter 1, even in science, almost all rejected 119 the beginning of infinity theories are rejected for being bad explanations, without ever being tested. Experimental testing is only one of many methods of criticism used in science, and the Enlightenment has made progress by bringing those other methods to
================================================================================bear in non-scientific fields too. The basic reason that such progress is possible is that good explanations about philo sophical issues are as hard to find as in science – and criticism is correspondingly effective. Moreover, experience does play a role in philosophy – only not the role of experimental testing that it plays in science. Primarily, it provides philosophical problems. There would have been no philosophy of science if the issue of how we can acquire knowledge of the physical world had been unproblematic. There would be no such thing as political philosophy if there had not first been a problem of how to run societies. (To avoid misunderstanding, let me stress that experience provides problems only by bringing already-existing ideas into conflict. It does not, of course, provide theories.) In the case of moral philosophy, the empiricist and justificationist misconceptions are often expressed in the maxim that ‘you can’t derive an ought from an is’ (a paraphrase of a remark by the Enlightenment philosopher David Hume). It means that moral theories cannot be deduced from factual knowledge. This has become conventional wis - dom, and has resulted in a kind of dogmatic despair about morality: ‘you can’t derive an ought from an is, therefore morality cannot be justified by reason’. That leaves only two options: either to embrace unreason or to try living without ever making a moral judgement. Both are liable to lead to morally wrong choices, just as embracing unreason or never attempting to explain the physical world leads to factually false theories (and not just ignorance). Certainly you can’t derive an ought from an is, but you can’t derive a factual theory from an is either. That is not what science does. The growth of knowledge does not consist of finding ways to justify one’s beliefs. It consists of finding good explanations. And, although factual evidence and moral maxims are logically independent, factual and moral explanations are not. Thus factual knowledge can be useful in criticizing moral explanations. For example, in the nineteenth century, if an American slave had written a bestselling book, that event would not logically have ruled 120 The Reality of Abstractions out the proposition ‘Negroes are intended by Providence to be slaves.’ No experience could, because that is a philosophical theory. But it might have ruined the explanation through which many people understood that proposition. And if, as a result, such people had found themselves unable to explain to their own satisfaction why it would be Providential if that author were to be forced back into slavery, then they might have questioned the account that they had formerly accepted of what a black person really is, and what a person in general is – and then a good person, a good society, and so on. Conversely, advocates of highly immoral doctrines almost invariably believe associated factual falsehoods as well. For instance, ever since the attack on the United States on 11 September 2001, millions of people worldwide have believed it was carried out by the US government, or the Israeli secret service. Those are purely factual misconceptions, yet they bear the imprint of moral wrongness just as clearly as a fossil – made of purely inorganic material – bears the imprint of ancient life. And the link, in both cases, is explanation. To concoct a moral explanation for why Westerners deserve to be killed indiscriminately, one needs to explain factually that the West is not what it pretends to be – and that requires uncritical acceptance of conspiracy theories, denials of history, and so on. Quite generally, in order to understand the moral landscape in terms of a given set of values, one needs to understand some facts as being a certain way too. And the converse is also true: for example, as the philosopher Jacob Bronowski pointed out, success at making factual, scientific discoveries entails a commitment to all sorts of values that are necessary for making progress. The individual scientist has to value truth, and good explanations, and be open to ideas and to change. The scientific community, and to some extent the civilization as a whole, has to value tolerance, integrity and openness of debate. We should not be surprised at these connections. The truth has structural unity as well as logical consistency, and I guess that no true explanation is entirely disconnected from any other. Since the universe is explicable, it must be that morally right values are connected in this way with true factual theories, and morally wrong values with false theories. Moral philosophy is basically about the problem of what to do next 121 the beginning of infinity – and, more generally, what sort of life to lead, and what sort of world to want. Some philosophers confine the term ‘moral’ to problems about how one should treat other people. But such problems are continuous with problems of individuals choosing what sort of life to lead, which is why I adopt the more inclusive definition. Terminology aside, if you were suddenly the last human on Earth, you would be wondering what sort of life to want. Deciding ‘I should do whatever pleases me most’ would give you very little clue, because what pleases you depends on your moral judgement of what constitutes a good life, not vice versa. This also illustrates the emptiness of reductionism in philosophy. For if I ask you for advice about what objectives to pursue in life, it is no good telling me to do what the laws of physics mandate. I shall do that in any case. Nor is it any good telling me to do what I prefer, because I don’t know what I prefer to do until I have decided what sort of life I want to lead or how I should want the world to be. Since our preferences are shaped in this way, at least in part, by our moral explanations, it does not make sense to define right and wrong entirely in terms of their
================================================================================later crossed one out for each goat that returned, then one would have retrieved all the goats when one had crossed out all the marks. That is a universal system of tallying. But, like levels of emergence, there is a hierarchy of universality. The next level above tallying is counting, which involves numerals. When tallying goats one is merely thinking ‘another, and another, and another’; but when counting them one is thinking ‘forty, forty-one, forty-two . . . ’ It is only with hindsight that we can regard tally marks as a system of numerals, known as the ‘unary’ system. As such, it is an impractical system. For instance, even the simplest operations on numbers rep- resented by tally marks, such as comparing them, doing arithmetic, and even just copying them, involves repeating the entire tallying process. If you had forty goats, and sold twenty, and had tally-mark records of both those numbers, you would still have to perform twenty individual deletion operations to bring your record up to date. Similarly, checking whether two fairly close numerals were the same would involve tallying them against each other. So people began to improve the system. The earliest improvement may have been simply to group the tally marks – for instance, writing ⎥⎥⎥⎥ ⎥⎥⎥⎥ instead of ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥. This made arithmetic and comparison easier, since one could tally whole groups and see at a glance that ⎥⎥⎥⎥ ⎥⎥⎥⎥ is different from ⎥⎥⎥⎥ ⎥⎥⎥⎥ ⎥. Later, such groups were themselves represented by shorthand symbols: the ancient Roman system used symbols like (cid:1), (cid:2), (cid:3), (cid:2), (cid:4), (cid:5), and (cid:4)(cid:5) to represent one, five, ten, fifty, one hundred, five hundred, and one thousand. (So they were not quite the same as the ‘Roman numerals’ we use today.) So this was another story of incremental improvements intended to solve specific, parochial problems. And, again, it seems that no one aspired to anything more. Even though adding simple rules could make 128 The Jump to Universality the system much more powerful, and even though the Romans did occasionally add some such rules, they did this without ever aiming for, or achieving, universality. For some centuries, the rules of their system were: – Placing symbols side by side means adding them together. (This rule was inherited from the tally-mark system.) – Symbols must be written in order of decreasing value from left to right; and – Adjacent symbols must be replaced by the symbol for their combined value whenever possible. (The subtractive rule in today’s ‘Roman numerals’, where (cid:1)(cid:2) represents four, was introduced later.) The second and third rules ensure that each number has only one representation, which makes comparison much easier. Without them, (cid:3)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:3) and (cid:2)(cid:3)(cid:2)(cid:3)(cid:2)(cid:3)(cid:2)(cid:3)(cid:2) would both be valid numerals, and one could not tell at a glance that they represent the same number. By exploiting the universal laws of addition, those rules gave the system some important reach beyond tallying – such as the ability to perform arithmetic. For example, consider the numbers seven ((cid:2)(cid:1)(cid:1)) and eight ((cid:2)(cid:1)(cid:1)(cid:1)). The rules say that placing them side by side – (cid:2)(cid:1)(cid:1)(cid:2)(cid:1)(cid:1)(cid:1) – is the same as adding them. Then they tell us to rearrange the symbols in order of decreasing value: (cid:2)(cid:2)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1). Then they tell us to replace the two (cid:2)’s by (cid:3), and the five (cid:1)’s by (cid:2). The result is (cid:3)(cid:2), which is the representation of fifteen. Something new has happened here, which is more than just a matter of shorthand: an abstract truth has been discovered, and proved, about seven, eight and fifteen without anyone having counted or tallied anything. Numbers have been manipulated in their own right, via their numerals. I mean it literally when I say that it was the system of numerals that performed arithmetic. The human users of the system did of course physically enact those transformations. But to do that, they first had to encode the system’s rules somewhere in their brains, and then they had to execute them as a computer executes its program. And it is the program that instructs its computer what to do, not vice versa. Hence the process that we call ‘using Roman numerals to do arithmetic’ also consists of the Roman-numeral system using us to do arithmetic. 129 the beginning of infinity It was only by causing people to do this that the Roman-numeral system survived – that is to say, caused itself to be copied from generation to generation of Romans: they found it useful, so they passed it on to their offspring. As I have said, knowledge is information which, when it is physically embodied in a suitable environment, tends to cause itself to remain so. To speak of the Roman-numeral system as controlling us in order to get itself replicated and preserved may sound like relegating humans to the status of slaves. But that would be a misconception. People consist of abstract information, including the distinctive ideas, theories, intentions, feelings and other states of mind that characterize an ‘I’. To object to being ‘controlled’ by Roman numerals when we find them helpful is like protesting at being controlled by one’s own intentions. By that argument, it is slavery to escape from slavery. But in fact when I obey the program that constitutes me (or when I obey the laws of physics), ‘obey’ means something different from what a slave does. The two meanings explain events at different levels of emergence. Contrary to what is sometimes said, there were also fairly efficient ways of multiplying and dividing Roman numerals. So a ship with (cid:3)(cid:3) crates, each containing jars in a (cid:2)-by-(cid:2)(cid:1)(cid:1) grid, could be known to hold (cid:5)(cid:4)(cid:4) jars altogether without anyone having performed the lengthy count that was implicit in that numeral. And one could tell at a glance that (cid:5)(cid:4)(cid:4) was less than (cid:5)(cid:4)(cid:4)(cid:1). Thus, manipulating numbers independently of tallying or counting opened up applications such as calculating prices, wages, taxes, interest rates and so on. It was also a conceptual advance that opened the door to future progress.
================================================================================However, in regard to these more sophisticated applications, the system was not universal. Since there was no higher-valued symbol than (cid:4)(cid:5) (one thousand), the numerals from two thousand onwards all began with a string of (cid:4)(cid:5)’s, which therefore became nothing more than tally marks for thousands. The more of them there were in a numeral, the more one would have to fall back on tallying (examining many instances of the symbol one by one) in order to do arithmetic. Just as one could upgrade the vocabulary of an ancient writing system by adding pictograms, so one could add symbols to a system of numerals to increase its range. And this was done. But the resulting system would still always have a highest-valued symbol, and hence 130 The Jump to Universality would not be universal for doing arithmetic without tallying. The only way to emancipate arithmetic from tallying is with rules of universal reach. As with alphabets, a small set of basic rules and symbols is sufficient. The universal system in general use today has ten symbols, the digits 0 to 9, and its universality is due to a rule that the value of a digit depends on its position in the number. For instance, the digit 2 means two when written by itself, but means two hundred in the numeral 204. Such ‘positional’ systems require ‘placeholders’, such as the digit 0 in 204, whose only function is to place the 2 into the position where it means two hundred. This system originated in India, but it is not known when. It might have been as late as the ninth century, since before that only a few ambiguous documents seem to show it in use. At any rate, its tremen- dous potential in science, mathematics, engineering and trade was not widely realized. At approximately that time it was embraced by Arab scholars, yet was not generally used in the Arab world until a thousand years later. This curious lack of enthusiasm for universality was repeated in medieval Europe: a few scholars adopted Indian numerals from the Arabs in the tenth century (resulting in the misnomer ‘Arabic numerals’), but again these numerals did not come into everyday use for centuries. As early as 1900 bce the ancient Babylonians had invented what was in effect a universal system of numerals, but they too may not have cared about its universality – nor even been aware of it. It was a positional system, but very cumbersome compared with the Indian one. It had 59 ‘digits’, each of which was itself written as a numeral in a Roman-numeral-like system. So using it for arithmetic with numbers occurring in everyday life was actually more complicated than using Roman numerals. It also had no symbol for zero, so it used spaces as placeholders. It had no way of representing trailing zeros, and no equivalent of the decimal point (as if, in our system, the numbers 200, 20, 2, 0.2 and so on were all written as 2, and were distinguished only by context). All this suggests that universality was not the system’s main design objective, and that it was not greatly valued when it was achieved. Perhaps an insight into this recurring oddity is provided by a re - markable episode in the third century bce involving the ancient Greek 131 the beginning of infinity scientist and mathematician Archimedes. His research in astronomy and pure mathematics led him to a need to do arithmetic with some rather large numbers, so he had to invent his own system of numerals. His starting point was a Greek system with which he was familiar, similar to the Roman one but with a highest-valued symbol Μ for 10,000 (one myriad). The range of the system had already been ex - tended with the rule that digits written above an Μ would be multiplied by a myriad. For instance, the symbol for twenty was κ and the symbol for four was δ, so they could write twenty-four myriad (240,000) as Μκδ. If only they had allowed that rule to generate multi-tier numerals, so κδ that MΜ would mean twenty-four myriad myriad, the system would have been universal. But apparently they never did. Even more surprisingly, nor did Archimedes. His system used a different idea, similar to modern ‘scientific notation’ (in which, say, two million is written 2 × 106), except that instead of powers of ten it used powers of a myriad myriad. But, again, he then required the exponent (the power to which the myriad myriad was raised) to be an existing Greek numeral – that is to say, it could not easily exceed a myriad myriad or so. Hence this construction petered out after the number that we call 10800,000,000. If only he had not imposed that additional rule, he would have had a universal system, albeit an unnecessarily awkward one. Even today, only mathematicians ever need numbers above 10800,000,000, and only rarely at that. But that cannot be why Archimedes imposed the restriction, for he did not stop there. Exploring the concept of numbers further, he set up yet another extension, this time amounting to an even more unwieldy system with base 10800,000,000. Yet, once again, he allowed this number to be raised only to powers not exceeding 800,000,000, thus imposing an arbitrary limit somewhere in excess of 106.4 × 1017. Why? Today it seems very perverse of Archimedes to have placed limits on which symbols could be used at which positions in his numerals. There is no mathematical justification for them. But, if Archimedes had been willing to allow his rules to be applied without arbitrary limits, he could have invented a much better universal system just by removing the arbitrary limits from the existing Greek system. A few years later the mathematician Apollonius invented yet another 132 The Jump to Universality system of numerals which fell short of universality for the same reason. It is as though everyone in the ancient world was avoiding universality on purpose.
================================================================================other staff assigned to their welfare. However, they are not allowed to ask those staff to do their work for them. That is because, if they all did this, the hotel would grind to a halt. Infinity is not magic. It has logical rules: that is the whole point of the Infinity Hotel thought experiment. The fallacious idea of delegating all one’s work to other staff in 173 the beginning of infinity higher-numbered rooms is called an infinite regress. It is one of the things that one cannot validly do with infinity. There is an old joke about the heckler who interrupts an astrophysics lecture to insist that the Earth is flat and supported on the back of elephants standing on a giant turtle. ‘What supports the turtle?’ asks the lecturer. ‘Another turtle.’ ‘What supports that turtle?’ ‘You can’t fool me,’ replies the heckler triumphantly: ‘it’s turtles from there on down.’ That theory is a bad explanation not because it fails to explain everything (no theory does), but because what it leaves unexplained is effectively the same as what it purports to explain in the first place. (The theory that the designer of the biosphere was designed by another designer, and so on ad infinitum, is another example of an infinite regress.) One day in Infinity Hotel, a guest’s pet puppy happens to climb into a trash bag. The owner does not notice, and passes the bag, with the puppy, to the next room. Within two minutes the puppy is nowhere. The distraught owner phones the front desk. The receptionist announces over the public- address system, ‘We apologize for the inconvenience, but an item of value has been inadvertently thrown away. Will all guests please undo all the trash-moving actions that they have just performed, in reverse order, starting as soon as you receive a trash bag from the next-higher-numbered room.’ But to no avail. None of the guests return any bags, because their fellow guests in the higher- numbered rooms are not returning any either. It was no exaggeration to say that the bags are nowhere. They have not been stuffed into a mythical ‘room number infinity’. They no longer exist; nor does the puppy. No one has done anything to the puppy except move it to another numbered room, within the hotel. Yet it is not in any room. It is not anywhere in the hotel, or anywhere else. In a finite hotel, if you move an object from room to room, in however complicated a pattern, it will end up in one of those rooms. Not so with an infinite number of rooms. Every individual action that the guests performed was both harmless to the puppy and 174 A Window on Infinity perfectly reversible. Yet, taken together, those actions annihilated the puppy and cannot be reversed. Reversing them cannot work, because, if it did, there would be no explanation for why a puppy arrived at its owner’s room and not a kitten. If a puppy did arrive, the explanation would have to be that a puppy was passed down from the next-higher-numbered room – and so on. But that whole infinite sequence of explanations never gets round to explaining ‘why a puppy?’ It is an infinite regress. What if, one day, a puppy did just arrive at room 1, having been passed down through all the rooms? That is not logically impossible: it would merely lack an explanation. In physics, the ‘nowhere’ from which such a puppy would have come is called a ‘naked singularity’. Naked singularities appear in some speculative theories in physics, but such theories are rightly criticized on the grounds that they cannot make predictions. As Hawking once put it, ‘Television sets could come out [of a naked singularity].’ It would be different if there were a law of nature determining what comes out – for in that case there would be no infinite regress and the singularity would not be ‘naked’. The Big Bang may have been a singularity of that relatively benign type. I said that the rooms are identical, but they do differ in one respect: their room numbers. So, given the types of tasks that the management request from time to time, the low-numbered rooms are the most desirable. For instance, the guest in room 1 has the unique privilege of never having to deal with anyone else’s trash. Moving to room 1 feels like winning first prize in a lottery. Moving to room 2 feels only slightly less so. But every guest has a room number that is unusually close to the beginning. So every guest in the hotel is more privileged than almost all other guests. The clichéd politician’s promise to favour everyone can be honoured in Infinity Hotel. Every room is at the beginning of infinity. That is one of the attributes of the unbounded growth of knowledge too: we are only just scratching the surface, and shall never be doing anything else. So there is no such thing as a typical room number at Infinity Hotel. Every room number is untypically close to the beginning. The intuitive idea that there must be ‘typical’ or ‘average’ members of any set of values is false for infinite sets. The same is true of the intuitive ideas of ‘rare’ and ‘common’. We might think that half of all natural numbers 175 the beginning of infinity are odd, and half even – so that odd and even numbers are equally common among the natural numbers. But consider the following rearrangement: 1 2 4 3 6 8 5 10 12 7 14 16 … A rearrangement of the natural numbers that makes it look as though one-third of them are odd That makes it look as though the odd numbers are only half as common as even ones. Similarly, we could make it look as though the odd numbers were one in a million or any other proportion. So the intuitive notion of a proportion of the members of a set
================================================================================185 the beginning of infinity At the end of five minutes, the management would know the truth of the prime-pairs conjecture. So, there is nothing mathematically special about the undecidable questions, the non-computable functions, the unprovable propositions. They are distinguished by physics only. Different physical laws would make different things infinite, different things computable, different truths – both mathematical and scientific – knowable. It is only the laws of physics that determine which abstract entities and relationships are modelled by physical objects such as mathematicians’ brains, computers and sheets of paper. Some mathematicians wondered, at the time of Hilbert’s challenge, whether finiteness was really an essential feature of a proof. (They meant mathematically essential.) After all, infinity makes sense math- ematically, so why not infinite proofs? Hilbert, though he was a great defender of Cantor’s theory, ridiculed the idea. Both he and his critics were thereby making the same mistake as Zeno: they were all assuming that some class of abstract entities can prove things, and that math- ematical reasoning could determine what that class is. But if the laws of physics were in fact different from what we currently think they are, then so might be the set of mathematical truths that we would then be able to prove, and so might the operations that would be available to prove them with. The laws of physics as we know them happen to afford a privileged status to such operations as not, and and or, acting on individual bits of information (binary digits, or logical true/false values). That is why those operations seem natural, elementary and finite to us – and why bits do. If the laws of physics were like, say, those of Infinity Hotel, then there would be additional privileged operations, acting on infinite sets of bits. With some other laws of physics, the operations not, and and or would be non-computable, while some of our non-computable functions would seem natural, elementary and finite. That brings me to another distinction that depends on the laws of physics: simple versus complex. Brains are physical objects. Thoughts are computations, of the types permitted under the laws of physics. Some explanations can be grasped easily and quickly – like ‘If Socrates was a man and Plato was a man then they were both men.’ This is easy because it can be stated in a short sentence and relies on the properties 186 A Window on Infinity of an elementary operation (namely and). Other explanations are inherently hard to grasp, because their shortest form is still long and depends on many such operations. But whether the form of an ex planation is long or short, and whether it requires few or many elementary operations, depends entirely on the laws of physics under which it is being stated and understood. Quantum computation, which is currently believed to be the fully universal form of computation, happens to have exactly the same set of computable functions as Turing’s classical computation. But quantum computation drives a coach and horses through the classical notion of a ‘simple’ or ‘elementary’ operation. It makes some intuitively very complex things simple. Moreover, the elementary information- storing entity in quantum computation, the ‘qubit’ (quantum bit) is quite hard to explain in non-quantum terminology. Meanwhile the bit is a fairly complicated object from the perspective of quantum physics. Some people object that quantum computation therefore isn’t ‘real’ computation: it is just physics, just engineering. To them, those logical possibilities about exotic laws of physics enabling exotic forms of computation do not address the issue of what a proof ‘really’ is. Their objection would go something like this: admittedly, under suitable laws of physics we would be able to compute non-Turing-computable functions, but that would not be computation. We would be able to establish the truth or falsity of Turing-undecidable propositions, but that ‘establishing’ would not be proving, because then our knowledge of whether the proposition was true or false would for ever depend on our knowledge of what the laws of physics are. If we discovered one day that the real laws of physics were different, we might have to change our minds about the proof too, and its conclusion. And so it would not be a real proof: real proof is independent of physics. Here is that same misconception again (as well as some authority- seeking justificationism). Our knowledge of whether a proposition is true or false always depends on knowledge about how physical objects behave. If we changed our minds about what a computer, or a brain, has been doing – for instance, if we decided that our own memory was faulty about which steps we had checked in a proof – then we would be forced to change our opinion about whether we had proved 187 the beginning of infinity some thing or not. It would be no different if we changed our minds about what the laws of physics made the computer do. Whether a mathematical proposition is true or not is indeed inde- pend ent of physics. But the proof of such a proposition is a matter of physics only. There is no such thing as abstractly proving some- thing, just as there is no such thing as abstractly knowing something. Mathematical truth is absolutely necessary and transcendent, but all knowledge is generated by physical processes, and its scope and limitations are conditioned by the laws of nature. One can define a class of abstract entities and call them ‘proofs’ (or computations), just as one can define abstract entities and call them triangles and have them obey Euclidean geometry. But you cannot infer anything from that theory of ‘triangles’ about what angle you will turn through if you walk around a closed path consisting of three straight lines. Nor can those ‘proofs’ do the job of verifying mathematical statements. A mathematical ‘theory of proofs’ has no bearing on which truths can or cannot be proved in reality, or be known in reality; and similarly a theory of
================================================================================universality is all about computers inside our physical 190 A Window on Infinity world being related to each other under the universal laws of physics to which we (thereby) have access. How do all those drastic limitations on what can be known and what can be achieved by mathematics and by computation, including the existence of undecidable questions in mathematics, square with the maxim that problems are soluble? Problems are conflicts between ideas. Most mathematical questions that exist abstractly never appear as the subject of such a conflict: they are never the subject of curiosity, never the focus of conflicting mis - conceptions about some attribute of the world of abstractions. In short, most of them are uninteresting. Moreover, recall that finding proofs is not the purpose of math- ematics: it is merely one of the methods of mathematics. The purpose is to understand, and the overall method, as in all fields, is to make conjectures and to criticize them according to how good they are as explanations. One does not understand a mathematical proposition merely by proving it true. This is why there are such things as math- ematics lectures rather than just lists of proofs. And, conversely, the lack of a proof does not necessarily prevent a proposition from being understood. On the contrary, the usual order of events is for the mathematician first to understand something about the abstraction in question and then to use that understanding to conjecture how true propositions about the abstraction might be proved, and then to prove them. A mathematical theorem can be proved, yet remain for ever un - interesting. And an unproved mathematical conjecture can be fruitful in providing explanations even if it remains unproved for centuries, or even if it is unprovable. One example is the conjecture known in the jargon of computer science as ‘P ≠ NP’. It is, roughly speaking, that there exist classes of mathematical questions whose answers can be verified efficiently once one has them but cannot be computed efficiently in the first place by a universal (classical) computer. (‘Efficient’ computation has a technical definition that roughly approximates what we mean by the phrase in practice.) Almost all researchers in computing theory are sure that the conjecture is true (which is further refutation of the idea that mathematical knowledge consists only of proofs). That is 191 the beginning of infinity because, although no proof is known, there are fairly good explanations of why we should expect it to be true, and none to the contrary. (And so the same is thought to hold for quantum computers.) Moreover, a vast amount of mathematical knowledge that is both useful and interesting has been built on the conjecture. It includes theorems of the form ‘if the conjecture is true then this interesting consequence follows.’ And there are fewer, but still interesting, theorems about what would follow if it were false. A mathematician studying an undecidable question may prove that it is undecidable (and explain why). From the mathematician’s point of view, that is a success. Though it does not answer the mathematical question, it solves the mathematician’s problem. Even working on a mathematical problem without any of those kinds of success is still not the same as failing to create knowledge. Whenever one tries and fails to solve a mathematical problem one has discovered a theorem – and usually also an explanation – about why that approach to solving it does not work. Hence, undecidability no more contradicts the maxim that problems are soluble than does the fact that there are truths about the physical world that we shall never know. I expect that one day we shall have the technology to measure the number of grains of sand on Earth exactly, but I doubt that we shall ever know what the exact number was in Archimedes’ time. Indeed, I have already mentioned more drastic limitations on what can be known and achieved. There are the direct limitations imposed by the universal laws of physics – we cannot exceed the speed of light, and so on. Then there are the limitations of epis- temology: we cannot create knowledge other than by the fallible method of conjecture and criticism; errors are inevitable, and only error- correcting processes can succeed or continue for long. None of this contradicts the maxim, because none of those limitations need ever cause an unresolvable conflict of explanations. Hence I conjecture that, in mathematics as well as in science and philosophy, if the question is interesting, then the problem is soluble. Fallibilism tells us that we can be mistaken about what is interesting. And so, three corollaries follow from this conjecture. The first is that inherently insoluble problems are inherently uninteresting. The second is that, in the long run, the distinction between what is interesting and 192 A Window on Infinity what is boring is not a matter of subjective taste but an objective fact. And the third corollary is that the interesting problem of why every problem that is interesting is also soluble is itself soluble. At present we do not know why the laws of physics seem fine-tuned; we do not know why various forms of universality exist (though we do know of many connections between them); we do not know why the world is explicable. But eventually we shall. And when we do, there will be infinitely more left to explain. The most important of all limitations on knowledge-creation is that we cannot prophesy: we cannot predict the content of ideas yet to be created, or their effects. This limitation is not only consistent with the unlimited growth of knowledge, it is entailed by it, as I shall explain in the next chapter. That problems are soluble does not mean that we already know their solutions, or can generate them to order. That would be akin to creationism. The biologist Peter Medawar described science as ‘the art of the soluble’, but the same applies to all forms of knowledge. All kinds of
================================================================================the unknowable, but they did not originally refer especially to the future, as they do today. Originally, ‘optimism’ was the doctrine that the world – past, present and future – is as good as it could possibly be. The term was first used to describe an argument of Leibniz (1646–1716) that God, being ‘perfect’, would have created nothing less than ‘the best of all possible worlds’. Leibniz believed that this idea solved the ‘problem of evil’, which I mentioned in Chapter 4: he proposed that all apparent evils in the world are outweighed by good consequences that are too remote to be known. Similarly, all apparently good events that fail to 199 the beginning of infinity happen – including all improvements that humans are unsuccessful in achieving – fail because they would have had bad consequences that would have outweighed the good. Since consequences are determined by the laws of physics, the larger part of Leibniz’s claim must be that the laws of physics are the best possible too. Alternative laws that made scientific progress easier, or made disease an impossible phenomenon, or made even one disease slightly less unpleasant – in short, any alternative that would seem to be an improvement upon our actual history with all its plagues, tortures, tyrannies and natural disasters – would in fact have been even worse on balance, according to Leibniz. That theory is a spectacularly bad explanation. Not only can any observed sequence of events be explained as ‘best’ by that method, an alternative Leibniz could equally well have claimed that we live in the worst of all possible worlds, and that every good event is necessary in order to prevent something even better from happening. Indeed, some philosophers, such as Arthur Schopenhauer, have claimed just that. Their stance is called philosophical ‘pessimism’. Or one could claim that the world is exactly halfway between the best possible and the worst possible – and so on. Notice that, despite their superficial differ- ences, all those theories have something important in common: if any of them were true, rational thought would have almost no power to discover true explanations. For, since we can always imagine states of affairs that seem better than what we observe, we would always be mistaken that they were better, no matter how good our explanations were. So, in such a world, the true explanations of events are never even imaginable. For instance, in Leibniz’s ‘optimistic’ world, whenever we try to solve a problem and fail, it is because we have been thwarted by an unimaginably vast intelligence that determined that it was best for us to fail. And, still worse, whenever someone rejects reason and decides instead to rely on bad explanations or logical fallacies – or, for that matter, on pure malevolence – they still achieve, in every case, a better outcome on balance than the most rational and benevolent thought possibly could have. This does not describe an explicable world. And that would be very bad news for us, its inhabitants. Both the original ‘optimism’ and the original ‘pessimism’ are close to pure pessimism as I shall define it. 200 Optimism In everyday usage, a common saying is that ‘an optimist calls a glass half full while a pessimist calls it half empty’. But those attitudes are not what I am referring to either: they are matters not of philosophy but of psychology – more ‘spin’ than substance. The terms can also refer to moods, such as cheerfulness or depression, but, again, moods do not necessitate any particular stance about the future: the statesman Winston Churchill suffered from intense depression, yet his outlook on the future of civilization, and his specific expectations as wartime leader, were unusually positive. Conversely the economist Thomas Malthus, a notorious prophet of doom (of whom more below), is said to have been a serene and happy fellow, who often had his companions at the dinner table in gales of laughter. Blind optimism is a stance towards the future. It consists of proceed- ing as if one knows that the bad outcomes will not happen. The opposite approach, blind pessimism, often called the precautionary principle, seeks to ward off disaster by avoiding everything not known to be safe. No one seriously advocates either of these two as a universal policy, but their assumptions and their arguments are common, and often creep into people’s planning. Blind optimism is also known as ‘overconfidence’ or ‘recklessness’. An often cited example, perhaps unfairly, is the judgement of the builders of the ocean liner Titanic that it was ‘practically unsinkable’. The largest ship of its day, it sank on its maiden voyage in 1912. Designed to survive every foreseeable disaster, it collided with an iceberg in a manner that had not been foreseen. A blind pessimist argues that there is an inherent asymmetry between good and bad consequences: a successful maiden voyage cannot possibly do as much good as a disastrous one can do harm. As Rees points out, a single catastrophic consequence of an otherwise beneficial innovation could put an end to human progress for ever. So the blindly pessimistic approach to building ocean liners is to stick with existing designs and refrain from attempting any records. But blind pessimism is a blindly optimistic doctrine. It assumes that unforeseen disastrous consequences cannot follow from existing know- ledge too (or, rather, from existing ignorance). Not all shipwrecks happen to record-breaking ships. Not all unforeseen physical disasters need be caused by physics experiments or new technology. But one thing we do know is that protecting ourselves from any disaster, 201 the beginning of infinity foreseeable or not, or recovering from it once it has happened, requires knowledge; and knowledge has to be created. The harm that can flow from any innovation that does not destroy the growth of knowledge is always finite; the good can be unlimited. There would be no existing ship designs to stick with, nor records to stay within, if no one had ever violated the
================================================================================precautionary principle. Because pessimism needs to counter that argument in order to be at all persuasive, a recurring theme in pessimistic theories throughout history has been that an exceptionally dangerous moment is imminent. Our Final Century makes the case that the period since the mid twentieth century has been the first in which technology has been capable of destroying civilization. But that is not so. Many civilizations in history were destroyed by the simple technologies of fire and the sword. Indeed, of all civilizations in history, the overwhelming major- ity have been destroyed, some intentionally, some as a result of plague or natural disaster. Virtually all of them could have avoided the catastro phes that destroyed them if only they had possessed a little additional knowledge, such as improved agricultural or military technology, better hygiene, or better political or economic institutions. Very few, if any, could have been saved by greater caution about innovation. In fact most had enthusiastically implemented the pre - cautionary principle. More generally, what they lacked was a certain combination of abstract knowledge and knowledge embodied in technological arte- facts, namely sufficient wealth. Let me define that in a non-parochial way as the repertoire of physical transformations that they would be capable of causing. An example of a blindly pessimistic policy is that of trying to make our planet as unobtrusive as possible in the galaxy, for fear of contact with extraterrestrial civilizations. Stephen Hawking recently advised this, in his television series Into the Universe. He argued, ‘If [extra- terrestrials] ever visit us, I think the outcome would be much as when Christopher Columbus first landed in America, which didn’t turn out very well for the Native Americans.’ He warned that there might be nomadic, space-dwelling civilizations who would strip the Earth of its resources, or imperialist civilizations who would colonize it. The science-fiction author Greg Bear has written some exciting novels based 202 Optimism on the premise that the galaxy is full of civilizations that are either predators or prey, and in both cases are hiding. This would solve the mystery of Fermi’s problem. But it is implausible as a serious explan- ation. For one thing, it depends on civilizations becoming convinced of the existence of predator civilizations in space, and totally re - organizing themselves in order to hide from them, before being noticed – which means before they have even invented, say, radio. Hawking’s proposal also overlooks various dangers of not making our existence known to the galaxy, such as being inadvertently wiped out if benign civilizations send robots to our solar system, perhaps to mine what they consider an uninhabited system. And it rests on other misconceptions in addition to that classic flaw of blind pessimism. One is the Spaceship Earth idea on a larger scale: the assumption that progress in a hypothetical rapacious civilization is limited by raw materials rather than by knowledge. What exactly would it come to steal? Gold? Oil? Perhaps our planet’s water? Surely not, since any civilization capable of transporting itself here, or raw materials back across galactic distances, must already have cheap transmutation and hence does not care about the chemical composition of its raw materials. So essentially the only resource of use to it in our solar system would be the sheer mass of matter in the sun. But matter is available in every star. Perhaps it is collecting entire stars wholesale in order to make a giant black hole as part of some titanic engineering project. But in that case it would cost it virtually nothing to omit inhabited solar systems (which are presumably a small minority, otherwise it is pointless for us to hide in any case); so would it casually wipe out billions of people? Would we seem like insects to it? This can seem plausible only if one forgets that there can be only one type of person: universal explainers and constructors. The idea that there could be beings that are to us as we are to animals is a belief in the supernatural. Moreover, there is only one way of making progress: conjecture and criticism. And the only moral values that permit sustained progress are the objective values that the Enlightenment has begun to discover. No doubt the extraterrestrials’ morality is different from ours; but that will not be because it resembles that of the conquistadors. Nor would we be in serious danger of culture shock from contact with an advanced civilization: it will know how to educate its own children (or AIs), so 203 the beginning of infinity it will know how to educate us – and, in particular, to teach us how to use its computers. A further misconception is Hawking’s analogy between our civil- ization and pre-Enlightenment civilizations: as I shall explain in Chapter 15, there is a qualitative difference between those two types of civilization. Culture shock need not be dangerous to a post- Enlightenment one. As we look back on the failed civilizations of the past, we can see that they were so poor, their technology was so feeble, and their explanations of the world so fragmentary and full of misconceptions that their caution about innovation and progress was as perverse as expecting a blindfold to be useful when navigating dangerous waters. Pessimists believe that the present state of our own civilization is an exception to that pattern. But what does the precautionary principle say about that claim? Can we be sure that our present knowledge, too, is not riddled with dangerous gaps and misconceptions? That our present wealth is not pathetically inadequate to deal with unforeseen problems? Since we cannot be sure, would not the precautionary principle require us to confine ourselves to the policy that would always have been salutary in the past – namely innovation and, in emergencies, even blind optimism about the benefits of new knowledge? Also, in the case of our civilization, the precautionary principle rules itself out. Since our civilization has not been following it, a transition to it
================================================================================parochial error. Civilizations starved, long before Malthus, because of what they thought of as the ‘natural disasters’ of drought and famine. But it was really because of what we would call poor methods of irrigation and farming – in other words, lack of knowledge. Before our ancestors learned how to make fire artificially (and many times since then too), people must have died of exposure literally on top of the means of making the fires that would have saved their lives, because they did not know how. In a parochial sense, the weather killed them; but the deeper explanation is lack of knowledge. Many of the hundreds of millions of victims of cholera throughout history must have died within sight of the hearths that could have boiled their drinking water and saved their lives; but, again, they did not know that. Quite generally, the distinction between a ‘natural’ disaster and one brought about by ignorance is parochial. Prior to every natural disaster that people once used to think of as ‘just happening’, or being ordained by gods, we now see many options that the people affected failed to take – or, rather, to create. And all those options add up to the overarching option that they failed to create, namely that of form- ing a scientific and technological civilization like ours. Traditions of criticism. An Enlightenment. If a one-kilometre asteroid had approached the Earth on a collision course at any time in human history before the early twenty-first century, it would have killed at least a substantial proportion of all humans. In that respect, as in many others, we live in an era of un - precedented safety: the twenty-first century is the first ever moment when we have known how to defend ourselves from such impacts, which occur once every 250,000 years or so. This may sound too rare to care about, but it is random. A probability of one in 250,000 of such an impact in any given year means that a typical person on Earth would have a far larger chance of dying of an asteroid impact than in an aeroplane crash. And the next such object to strike us is already out there at this moment, speeding towards us with nothing to stop it except human knowledge. Civilization is vulnerable to several other known types of disaster with similar levels of risk. For instance, ice 207 the beginning of infinity ages occur more frequently than that, and ‘mini ice ages’ much more frequently – and some climatologists believe that they can happen with only a few years’ warning. A ‘super-volcano’ such as the one lurking under Yellowstone National Park could blot out the sun for years at a time. If it happened tomorrow our species could survive, by growing food using artificial light, and civilization could recover. But many would die, and the suffering would be so tremendous that such events should merit almost as much preventative effort as an extinction. We do not know the probability of a spontaneously occurring incurable plague, but we may guess that it is unacceptably high, since pandemics such as the Black Death in the fourteenth century have already shown us the sort of thing that can happen on a timescale of centuries. Should any of those catastrophes loom, we now have at least a chance of creating the knowledge required to survive, in time. We have such a chance because we are able to solve problems. Problems are inevitable. We shall always be faced with the problem of how to plan for an unknowable future. We shall never be able to afford to sit back and hope for the best. Even if our civilization moves out into space in order to hedge its bets, as Rees and Hawking both rightly advise, a gamma-ray burst in our galactic vicinity would still wipe us all out. Such an event is thousands of times rarer than an asteroid collision, but when it does finally happen we shall have no defence against it without a great deal more scientific knowledge and an enormous increase in our wealth. But first we shall have to survive the next ice age; and, before that, other dangerous climate change (both spontaneous and human-caused), and weapons of mass destruction and pandemics and all the countless unforeseen dangers that are going to beset us. Our political institutions, ways of life, personal aspirations and morality are all forms or embodi- ments of knowledge, and all will have to be improved if civilization – and the Enlightenment in particular – is to survive every one of the risks that Rees describes and presumably many others of which we have no inkling. So – how? How can we formulate policies for the unknown? If we cannot derive them from our best existing knowledge, or from dog - matic rules of thumb like blind optimism or pessimism, where can we derive them from? Like scientific theories, policies cannot be derived 208 Optimism from anything. They are conjectures. And we should choose between them not on the basis of their origin, but according to how good they are as explanations: how hard to vary. Like the rejection of empiricism, and of the idea that knowledge is ‘justified, true belief’, understanding that political policies are conjectures entails the rejection of a previously unquestioned philosophical as - sumption. Again, Popper was a key advocate of this rejection. He wrote: The question about the sources of our knowledge . . . has always been asked in the spirit of: ‘What are the best sources of our knowledge – the most reliable ones, those which will not lead us into error, and those to which we can and must turn, in case of doubt, as the last court of appeal?’ I propose to assume, instead, that no such ideal sources exist – no more than ideal rulers – and that all ‘sources’ are liable to lead us into error at times. And I propose to replace, therefore, the
================================================================================ones that are already there. That entire stance is fallibilism in action. It assumes that rulers and policies are always going to be flawed – that problems are inevitable. But it also assumes that improving upon them is possible: problems are soluble. The ideal towards which this is working is not that nothing 211 the beginning of infinity unexpected will go wrong, but that when it does it will be an opportun- ity for further progress. Why would anyone want to make the leaders and policies that they themselves favour more vulnerable to removal? Indeed, let me first ask: why would anyone want to replace bad leaders and policies at all? That question may seem absurd, but perhaps it is absurd only from the perspective of a civilization that takes progress for granted. If we did not expect progress, why should we expect the new leader or policy, chosen by whatever method, to be any better than the old? On the contrary, we should then expect any changes on average to do as much harm as good. And then the precautionary principle advises, ‘Better the devil you know than the devil you don’t.’ There is a closed loop of ideas here: on the assumption that knowledge is not going to grow, the precautionary principle is true; and on the assumption that the precautionary principle is true, we cannot afford to allow knowledge to grow. Unless a society is expecting its own future choices to be better than its present ones, it will strive to make its present policies and institutions as immutable as possible. Therefore Popper’s criterion can be met only by societies that expect their knowledge to grow – and to grow unpredictably. And, further, they are expecting that if it did grow, that would help. This expectation is what I call optimism, and I can state it, in its most general form, thus: The Principle of Optimism All evils are caused by insufficient knowledge. Optimism is, in the first instance, a way of explaining failure, not prophesying success. It says that there is no fundamental barrier, no law of nature or supernatural decree, preventing progress. Whenever we try to improve things and fail, it is not because the spiteful (or unfathomably benevolent) gods are thwarting us or punishing us for trying, or because we have reached a limit on the capacity of reason to make improvements, or because it is best that we fail, but always because we did not know enough, in time. But optimism is also a stance towards the future, because nearly all failures, and nearly all successes, are yet to come. 212 Optimism Optimism follows from the explicability of the physical world, as I explained in Chapter 3. If something is permitted by the laws of physics, then the only thing that can prevent it from being technologically possible is not knowing how. Optimism also assumes that none of the prohibitions imposed by the laws of physics are necessarily evils. So, for instance, the lack of the impossible knowledge of prophecy is not an insuperable obstacle to progress. Nor are insoluble mathematical problems, as I explained in Chapter 8. That means that in the long run there are no insuperable evils, and in the short run the only insuperable evils are parochial ones. There can be no such thing as a disease for which it is impossible to discover a cure, other than certain types of brain damage – those that have dissipated the knowledge that constitutes the patient’s personality. For a sick person is a physical object, and the task of transforming this object into the same person in good health is one that no law of physics rules out. Hence there is a way of achieving such a transformation – that is to say, a cure. It is only a matter of knowing how. If we do not, for the moment, know how to eliminate a particular evil, or we know in theory but do not yet have enough time or resources (i.e. wealth), then, even so, it is universally true that either the laws of physics forbid eliminating it in a given time with the available resources or there is a way of eliminating it in the time and with those resources. The same must hold, equally trivially, for the evil of death – that is to say, the deaths of human beings from disease or old age. This problem has a tremendous resonance in every culture – in its literature, its values, its objectives great and small. It also has an almost unmatched repu- tation for insolubility (except among believers in the supernatural): it is taken to be the epitome of an insuperable obstacle. But there is no rational basis for that reputation. It is absurdly parochial to read some deep significance into this particular failure, among so many, of the biosphere to support human life – or of medical science through- out the ages to cure ageing. The problem of ageing is of the same general type as that of disease. Although it is a complex problem by present-day standards, the complexity is finite and confined to a relatively narrow arena whose basic principles are already fairly well understood. Meanwhile, knowledge in the relevant fields is increasing exponentially. 213 the beginning of infinity Sometimes ‘immortality’ (in this sense) is even regarded as undesir- able. For instance, there are arguments from overpopulation; but those are examples of the Malthusian prophetic fallacy: what each additional surviving person would need to survive at present-day standards of living is easily calculated; what knowledge that person would contri- bute to the solution of the resulting problems is unknowable. There are also arguments about the stultification of society caused by the entrenchment of old people in positions of power; but the traditions of criticism in our society are already well adapted to solving that sort of problem. Even today, it is common in Western countries for powerful politicians or business executives to be removed from
================================================================================